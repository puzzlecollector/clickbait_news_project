{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "# import necessary libraries for training Electra \n",
    "from transformers import * \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler \n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "import random \n",
    "import time \n",
    "import datetime \n",
    "from tqdm import tqdm \n",
    "import gc \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "# import necessary libraries for training LSTM \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, Conv2DTranspose, MaxPooling2D, AveragePooling2D, BatchNormalization, concatenate, Input, ConvLSTM2D, Reshape, Conv3D, Flatten, LSTM, GRU, Dense,Dropout, Add\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98093, 4)\n"
     ]
    }
   ],
   "source": [
    "# import dataframes from the 2018 research \n",
    "# train1 contains inconsistent news \n",
    "# train2 contains irrelevant news  \n",
    "# we are not using mismatch news yet.  \n",
    "train1 = pd.read_csv('mission1_train.csv')\n",
    "train2 = pd.read_csv('mission2_train.csv')\n",
    "\n",
    "train = pd.concat([train1,train2], axis = 0)\n",
    "train = train.dropna() \n",
    "train = train.drop(columns=['seqid'])\n",
    "\n",
    "train['title_length'] = train['title'].apply(lambda x : len(x)) \n",
    "train = train[train['title_length'] <= 120] \n",
    "train = train[train['title_length'] >= 5] \n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('mindslab_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment data using sliding window method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s): \n",
    "    FILTERS = \"([~.,!?\\\"':;(])\"\n",
    "    CHANGE_FILTER = re.compile(FILTERS)\n",
    "    return re.sub(CHANGE_FILTER, \" \", s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(s, overlap = 20, chunk_size = 50): \n",
    "    total = [] \n",
    "    partial = [] \n",
    "    if len(s.split()) // (chunk_size - overlap) > 0:  \n",
    "        n = len(s.split()) // (chunk_size - overlap) \n",
    "    else: \n",
    "        n = 1 \n",
    "    for w in range(n): \n",
    "        if w == 0: \n",
    "            partial = s.split()[:chunk_size] \n",
    "            total.append(\" \".join(partial)) \n",
    "        else:  \n",
    "            partial = s.split()[w*(chunk_size - overlap):w*(chunk_size - overlap) + chunk_size]\n",
    "            total.append(\" \".join(partial)) \n",
    "    return total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = train['content'].values\n",
    "titles = train['title'].values \n",
    "labels = train['Label'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'title':[], 'content':[], 'Label':[]} \n",
    "for i in range(len(contents)): \n",
    "    splitted = split_text(clean_text(contents[i]))\n",
    "    for text in splitted: \n",
    "        data['title'].append(titles[i]) \n",
    "        data['content'].append(text) \n",
    "        data['Label'].append(labels[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_train = pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류</td>\n",
       "      <td>박상기 법무부장관 후보자가 교통법규 위반으로 부과된 과태료를 7차례 체납하고 자동차...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류</td>\n",
       "      <td>해서 후보자 차량 압류가 오랜 기간 이뤄졌다’고 지적했다 주 의원에 따르면 박 후보...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류</td>\n",
       "      <td>2015년 6월 8일 해당 과태료를 납부했다 2011년 4월 22일 부과된 ‘속도위...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류</td>\n",
       "      <td>또 자동차세와 과태료 미납으로 차량 압류를 15차례 당했던 것으로 확인됐다 2008...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류</td>\n",
       "      <td>압류 기록은 작년 10월 6일에 있었다 박 후보자는 이에 대해 청문회에서 “저는 대...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title  \\\n",
       "0  박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류   \n",
       "1  박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류   \n",
       "2  박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류   \n",
       "3  박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류   \n",
       "4  박상기 법무장관 후보자, 자동차세·과태료 미납으로 15차례 차량 압류   \n",
       "\n",
       "                                             content  Label  \n",
       "0  박상기 법무부장관 후보자가 교통법규 위반으로 부과된 과태료를 7차례 체납하고 자동차...    0.0  \n",
       "1  해서 후보자 차량 압류가 오랜 기간 이뤄졌다’고 지적했다 주 의원에 따르면 박 후보...    0.0  \n",
       "2  2015년 6월 8일 해당 과태료를 납부했다 2011년 4월 22일 부과된 ‘속도위...    0.0  \n",
       "3  또 자동차세와 과태료 미납으로 차량 압류를 15차례 당했던 것으로 확인됐다 2008...    0.0  \n",
       "4  압류 기록은 작년 10월 6일에 있었다 박 후보자는 이에 대해 청문회에서 “저는 대...    0.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def electra_tokenizer_simple(sent1, sent2, MAX_LEN):  \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent1, \n",
    "        text_pair = sent2,  \n",
    "        add_special_tokens = True, # add [CLS] and [SEP]\n",
    "        pad_to_max_length = False, \n",
    "        return_attention_mask = True # constructing attention_masks \n",
    "    )  \n",
    "    \n",
    "    input_id = encoded_dict['input_ids'] \n",
    "    attention_mask = encoded_dict['attention_mask'] # differentiate padding from non padding \n",
    "    token_type_id = encoded_dict['token_type_ids'] # differentiate two sentences    \n",
    "    \n",
    "    if len(input_id) > 512: \n",
    "        input_id = input_id[:129] + input_id[-383:] \n",
    "        attention_mask = attention_mask[:129] + attention_mask[-383:]  \n",
    "        token_type_id = token_type_id[:129] + token_type_id[-383:]   \n",
    "    elif len(input_id) < 512: \n",
    "        input_id = input_id + [0]*(512 - len(input_id)) \n",
    "        attention_mask = attention_mask + [0]*(512 - len(attention_mask))\n",
    "        token_type_id = token_type_id + [0]*(512 - len(token_type_id))  \n",
    "        \n",
    "    return np.asarray(input_id), np.asarray(attention_mask), np.asarray(token_type_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 datapoints\n",
      "Processed 2000 datapoints\n",
      "Processed 3000 datapoints\n",
      "Processed 4000 datapoints\n",
      "Processed 5000 datapoints\n",
      "Processed 6000 datapoints\n",
      "Processed 7000 datapoints\n",
      "Processed 8000 datapoints\n",
      "Processed 9000 datapoints\n",
      "Processed 10000 datapoints\n",
      "Processed 11000 datapoints\n",
      "Processed 12000 datapoints\n",
      "Processed 13000 datapoints\n",
      "Processed 14000 datapoints\n",
      "Processed 15000 datapoints\n",
      "Processed 16000 datapoints\n",
      "Processed 17000 datapoints\n",
      "Processed 18000 datapoints\n",
      "Processed 19000 datapoints\n",
      "Processed 20000 datapoints\n",
      "Processed 21000 datapoints\n",
      "Processed 22000 datapoints\n",
      "Processed 23000 datapoints\n",
      "Processed 24000 datapoints\n",
      "Processed 25000 datapoints\n",
      "Processed 26000 datapoints\n",
      "Processed 27000 datapoints\n",
      "Processed 28000 datapoints\n",
      "Processed 29000 datapoints\n",
      "Processed 30000 datapoints\n",
      "Processed 31000 datapoints\n",
      "Processed 32000 datapoints\n",
      "Processed 33000 datapoints\n",
      "Processed 34000 datapoints\n",
      "Processed 35000 datapoints\n",
      "Processed 36000 datapoints\n",
      "Processed 37000 datapoints\n",
      "Processed 38000 datapoints\n",
      "Processed 39000 datapoints\n",
      "Processed 40000 datapoints\n",
      "Processed 41000 datapoints\n",
      "Processed 42000 datapoints\n",
      "Processed 43000 datapoints\n",
      "Processed 44000 datapoints\n",
      "Processed 45000 datapoints\n",
      "Processed 46000 datapoints\n",
      "Processed 47000 datapoints\n",
      "Processed 48000 datapoints\n",
      "Processed 49000 datapoints\n",
      "Processed 50000 datapoints\n",
      "Processed 51000 datapoints\n",
      "Processed 52000 datapoints\n",
      "Processed 53000 datapoints\n",
      "Processed 54000 datapoints\n",
      "Processed 55000 datapoints\n",
      "Processed 56000 datapoints\n",
      "Processed 57000 datapoints\n",
      "Processed 58000 datapoints\n",
      "Processed 59000 datapoints\n",
      "Processed 60000 datapoints\n",
      "Processed 61000 datapoints\n",
      "Processed 62000 datapoints\n",
      "Processed 63000 datapoints\n",
      "Processed 64000 datapoints\n",
      "Processed 65000 datapoints\n",
      "Processed 66000 datapoints\n",
      "Processed 67000 datapoints\n",
      "Processed 68000 datapoints\n",
      "Processed 69000 datapoints\n",
      "Processed 70000 datapoints\n",
      "Processed 71000 datapoints\n",
      "Processed 72000 datapoints\n",
      "Processed 73000 datapoints\n",
      "Processed 74000 datapoints\n",
      "Processed 75000 datapoints\n",
      "Processed 76000 datapoints\n",
      "Processed 77000 datapoints\n",
      "Processed 78000 datapoints\n",
      "Processed 79000 datapoints\n",
      "Processed 80000 datapoints\n",
      "Processed 81000 datapoints\n",
      "Processed 82000 datapoints\n",
      "Processed 83000 datapoints\n",
      "Processed 84000 datapoints\n",
      "Processed 85000 datapoints\n",
      "Processed 86000 datapoints\n",
      "Processed 87000 datapoints\n",
      "Processed 88000 datapoints\n",
      "Processed 89000 datapoints\n",
      "Processed 90000 datapoints\n",
      "Processed 91000 datapoints\n",
      "Processed 92000 datapoints\n",
      "Processed 93000 datapoints\n",
      "Processed 94000 datapoints\n",
      "Processed 95000 datapoints\n",
      "Processed 96000 datapoints\n",
      "Processed 97000 datapoints\n",
      "Processed 98000 datapoints\n",
      "Processed 99000 datapoints\n",
      "Processed 100000 datapoints\n",
      "Processed 101000 datapoints\n",
      "Processed 102000 datapoints\n",
      "Processed 103000 datapoints\n",
      "Processed 104000 datapoints\n",
      "Processed 105000 datapoints\n",
      "Processed 106000 datapoints\n",
      "Processed 107000 datapoints\n",
      "Processed 108000 datapoints\n",
      "Processed 109000 datapoints\n",
      "Processed 110000 datapoints\n",
      "Processed 111000 datapoints\n",
      "Processed 112000 datapoints\n",
      "Processed 113000 datapoints\n",
      "Processed 114000 datapoints\n",
      "Processed 115000 datapoints\n",
      "Processed 116000 datapoints\n",
      "Processed 117000 datapoints\n",
      "Processed 118000 datapoints\n",
      "Processed 119000 datapoints\n",
      "Processed 120000 datapoints\n",
      "Processed 121000 datapoints\n",
      "Processed 122000 datapoints\n",
      "Processed 123000 datapoints\n",
      "Processed 124000 datapoints\n",
      "Processed 125000 datapoints\n",
      "Processed 126000 datapoints\n",
      "Processed 127000 datapoints\n",
      "Processed 128000 datapoints\n",
      "Processed 129000 datapoints\n",
      "Processed 130000 datapoints\n",
      "Processed 131000 datapoints\n",
      "Processed 132000 datapoints\n",
      "Processed 133000 datapoints\n",
      "Processed 134000 datapoints\n",
      "Processed 135000 datapoints\n",
      "Processed 136000 datapoints\n",
      "Processed 137000 datapoints\n",
      "Processed 138000 datapoints\n",
      "Processed 139000 datapoints\n",
      "Processed 140000 datapoints\n",
      "Processed 141000 datapoints\n",
      "Processed 142000 datapoints\n",
      "Processed 143000 datapoints\n",
      "Processed 144000 datapoints\n",
      "Processed 145000 datapoints\n",
      "Processed 146000 datapoints\n",
      "Processed 147000 datapoints\n",
      "Processed 148000 datapoints\n",
      "Processed 149000 datapoints\n",
      "Processed 150000 datapoints\n",
      "Processed 151000 datapoints\n",
      "Processed 152000 datapoints\n",
      "Processed 153000 datapoints\n",
      "Processed 154000 datapoints\n",
      "Processed 155000 datapoints\n",
      "Processed 156000 datapoints\n",
      "Processed 157000 datapoints\n",
      "Processed 158000 datapoints\n",
      "Processed 159000 datapoints\n",
      "Processed 160000 datapoints\n",
      "Processed 161000 datapoints\n",
      "Processed 162000 datapoints\n",
      "Processed 163000 datapoints\n",
      "Processed 164000 datapoints\n",
      "Processed 165000 datapoints\n",
      "Processed 166000 datapoints\n",
      "Processed 167000 datapoints\n",
      "Processed 168000 datapoints\n",
      "Processed 169000 datapoints\n",
      "Processed 170000 datapoints\n",
      "Processed 171000 datapoints\n",
      "Processed 172000 datapoints\n",
      "Processed 173000 datapoints\n",
      "Processed 174000 datapoints\n",
      "Processed 175000 datapoints\n",
      "Processed 176000 datapoints\n",
      "Processed 177000 datapoints\n",
      "Processed 178000 datapoints\n",
      "Processed 179000 datapoints\n",
      "Processed 180000 datapoints\n",
      "Processed 181000 datapoints\n",
      "Processed 182000 datapoints\n",
      "Processed 183000 datapoints\n",
      "Processed 184000 datapoints\n",
      "Processed 185000 datapoints\n",
      "Processed 186000 datapoints\n",
      "Processed 187000 datapoints\n",
      "Processed 188000 datapoints\n",
      "Processed 189000 datapoints\n",
      "Processed 190000 datapoints\n",
      "Processed 191000 datapoints\n",
      "Processed 192000 datapoints\n",
      "Processed 193000 datapoints\n",
      "Processed 194000 datapoints\n",
      "Processed 195000 datapoints\n",
      "Processed 196000 datapoints\n",
      "Processed 197000 datapoints\n",
      "Processed 198000 datapoints\n",
      "Processed 199000 datapoints\n",
      "Processed 200000 datapoints\n",
      "Processed 201000 datapoints\n",
      "Processed 202000 datapoints\n",
      "Processed 203000 datapoints\n",
      "Processed 204000 datapoints\n",
      "Processed 205000 datapoints\n",
      "Processed 206000 datapoints\n",
      "Processed 207000 datapoints\n",
      "Processed 208000 datapoints\n",
      "Processed 209000 datapoints\n",
      "Processed 210000 datapoints\n",
      "Processed 211000 datapoints\n",
      "Processed 212000 datapoints\n",
      "Processed 213000 datapoints\n",
      "Processed 214000 datapoints\n",
      "Processed 215000 datapoints\n",
      "Processed 216000 datapoints\n",
      "Processed 217000 datapoints\n",
      "Processed 218000 datapoints\n",
      "Processed 219000 datapoints\n",
      "Processed 220000 datapoints\n",
      "Processed 221000 datapoints\n",
      "Processed 222000 datapoints\n",
      "Processed 223000 datapoints\n",
      "Processed 224000 datapoints\n",
      "Processed 225000 datapoints\n",
      "Processed 226000 datapoints\n",
      "Processed 227000 datapoints\n",
      "Processed 228000 datapoints\n",
      "Processed 229000 datapoints\n",
      "Processed 230000 datapoints\n",
      "Processed 231000 datapoints\n",
      "Processed 232000 datapoints\n",
      "Processed 233000 datapoints\n",
      "Processed 234000 datapoints\n",
      "Processed 235000 datapoints\n",
      "Processed 236000 datapoints\n",
      "Processed 237000 datapoints\n",
      "Processed 238000 datapoints\n",
      "Processed 239000 datapoints\n",
      "Processed 240000 datapoints\n",
      "Processed 241000 datapoints\n",
      "Processed 242000 datapoints\n",
      "Processed 243000 datapoints\n",
      "Processed 244000 datapoints\n",
      "Processed 245000 datapoints\n",
      "Processed 246000 datapoints\n",
      "Processed 247000 datapoints\n",
      "Processed 248000 datapoints\n",
      "Processed 249000 datapoints\n",
      "Processed 250000 datapoints\n",
      "Processed 251000 datapoints\n",
      "Processed 252000 datapoints\n",
      "Processed 253000 datapoints\n",
      "Processed 254000 datapoints\n",
      "Processed 255000 datapoints\n",
      "Processed 256000 datapoints\n",
      "Processed 257000 datapoints\n",
      "Processed 258000 datapoints\n",
      "Processed 259000 datapoints\n",
      "Processed 260000 datapoints\n",
      "Processed 261000 datapoints\n",
      "Processed 262000 datapoints\n",
      "Processed 263000 datapoints\n",
      "Processed 264000 datapoints\n",
      "Processed 265000 datapoints\n",
      "Processed 266000 datapoints\n",
      "Processed 267000 datapoints\n",
      "Processed 268000 datapoints\n",
      "Processed 269000 datapoints\n",
      "Processed 270000 datapoints\n",
      "Processed 271000 datapoints\n",
      "Processed 272000 datapoints\n",
      "Processed 273000 datapoints\n",
      "Processed 274000 datapoints\n",
      "Processed 275000 datapoints\n",
      "Processed 276000 datapoints\n",
      "Processed 277000 datapoints\n",
      "Processed 278000 datapoints\n",
      "Processed 279000 datapoints\n",
      "Processed 280000 datapoints\n",
      "Processed 281000 datapoints\n",
      "Processed 282000 datapoints\n",
      "Processed 283000 datapoints\n",
      "Processed 284000 datapoints\n",
      "Processed 285000 datapoints\n",
      "Processed 286000 datapoints\n",
      "Processed 287000 datapoints\n",
      "Processed 288000 datapoints\n",
      "Processed 289000 datapoints\n",
      "Processed 290000 datapoints\n",
      "Processed 291000 datapoints\n",
      "Processed 292000 datapoints\n",
      "Processed 293000 datapoints\n",
      "Processed 294000 datapoints\n",
      "Processed 295000 datapoints\n",
      "Processed 296000 datapoints\n",
      "Processed 297000 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 298000 datapoints\n",
      "Processed 299000 datapoints\n",
      "Processed 300000 datapoints\n",
      "Processed 301000 datapoints\n",
      "Processed 302000 datapoints\n",
      "Processed 303000 datapoints\n",
      "Processed 304000 datapoints\n",
      "Processed 305000 datapoints\n",
      "Processed 306000 datapoints\n",
      "Processed 307000 datapoints\n",
      "Processed 308000 datapoints\n",
      "Processed 309000 datapoints\n",
      "Processed 310000 datapoints\n",
      "Processed 311000 datapoints\n",
      "Processed 312000 datapoints\n",
      "Processed 313000 datapoints\n",
      "Processed 314000 datapoints\n",
      "Processed 315000 datapoints\n",
      "Processed 316000 datapoints\n",
      "Processed 317000 datapoints\n",
      "Processed 318000 datapoints\n",
      "Processed 319000 datapoints\n",
      "Processed 320000 datapoints\n",
      "Processed 321000 datapoints\n",
      "Processed 322000 datapoints\n",
      "Processed 323000 datapoints\n",
      "Processed 324000 datapoints\n",
      "Processed 325000 datapoints\n",
      "Processed 326000 datapoints\n",
      "Processed 327000 datapoints\n",
      "Processed 328000 datapoints\n",
      "Processed 329000 datapoints\n",
      "Processed 330000 datapoints\n",
      "Processed 331000 datapoints\n",
      "Processed 332000 datapoints\n",
      "Processed 333000 datapoints\n",
      "Processed 334000 datapoints\n",
      "Processed 335000 datapoints\n",
      "Processed 336000 datapoints\n",
      "Processed 337000 datapoints\n",
      "Processed 338000 datapoints\n",
      "Processed 339000 datapoints\n",
      "Processed 340000 datapoints\n",
      "Processed 341000 datapoints\n",
      "Processed 342000 datapoints\n",
      "Processed 343000 datapoints\n",
      "Processed 344000 datapoints\n",
      "Processed 345000 datapoints\n",
      "Processed 346000 datapoints\n",
      "Processed 347000 datapoints\n",
      "Processed 348000 datapoints\n",
      "Processed 349000 datapoints\n",
      "Processed 350000 datapoints\n",
      "Processed 351000 datapoints\n",
      "Processed 352000 datapoints\n",
      "Processed 353000 datapoints\n",
      "Processed 354000 datapoints\n",
      "Processed 355000 datapoints\n",
      "Processed 356000 datapoints\n",
      "Processed 357000 datapoints\n",
      "Processed 358000 datapoints\n",
      "Processed 359000 datapoints\n",
      "Processed 360000 datapoints\n",
      "Processed 361000 datapoints\n",
      "Processed 362000 datapoints\n",
      "Processed 363000 datapoints\n",
      "Processed 364000 datapoints\n",
      "Processed 365000 datapoints\n",
      "Processed 366000 datapoints\n",
      "Processed 367000 datapoints\n",
      "Processed 368000 datapoints\n",
      "Processed 369000 datapoints\n",
      "Processed 370000 datapoints\n",
      "Processed 371000 datapoints\n",
      "Processed 372000 datapoints\n",
      "Processed 373000 datapoints\n",
      "Processed 374000 datapoints\n",
      "Processed 375000 datapoints\n",
      "Processed 376000 datapoints\n",
      "Processed 377000 datapoints\n",
      "Processed 378000 datapoints\n",
      "Processed 379000 datapoints\n",
      "Processed 380000 datapoints\n",
      "Processed 381000 datapoints\n",
      "Processed 382000 datapoints\n",
      "Processed 383000 datapoints\n",
      "Processed 384000 datapoints\n",
      "Processed 385000 datapoints\n",
      "Processed 386000 datapoints\n",
      "Processed 387000 datapoints\n",
      "Processed 388000 datapoints\n",
      "Processed 389000 datapoints\n",
      "Processed 390000 datapoints\n",
      "Processed 391000 datapoints\n",
      "Processed 392000 datapoints\n",
      "Processed 393000 datapoints\n",
      "Processed 394000 datapoints\n",
      "Processed 395000 datapoints\n",
      "Processed 396000 datapoints\n",
      "Processed 397000 datapoints\n",
      "Processed 398000 datapoints\n",
      "Processed 399000 datapoints\n",
      "Processed 400000 datapoints\n",
      "Processed 401000 datapoints\n",
      "Processed 402000 datapoints\n",
      "Processed 403000 datapoints\n",
      "Processed 404000 datapoints\n",
      "Processed 405000 datapoints\n",
      "Processed 406000 datapoints\n",
      "Processed 407000 datapoints\n",
      "Processed 408000 datapoints\n",
      "Processed 409000 datapoints\n",
      "Processed 410000 datapoints\n",
      "Processed 411000 datapoints\n",
      "Processed 412000 datapoints\n",
      "Processed 413000 datapoints\n",
      "Processed 414000 datapoints\n",
      "Processed 415000 datapoints\n",
      "Processed 416000 datapoints\n",
      "Processed 417000 datapoints\n",
      "Processed 418000 datapoints\n",
      "Processed 419000 datapoints\n",
      "Processed 420000 datapoints\n",
      "Processed 421000 datapoints\n",
      "Processed 422000 datapoints\n",
      "Processed 423000 datapoints\n",
      "Processed 424000 datapoints\n",
      "Processed 425000 datapoints\n",
      "Processed 426000 datapoints\n",
      "Processed 427000 datapoints\n",
      "Processed 428000 datapoints\n",
      "Processed 429000 datapoints\n",
      "Processed 430000 datapoints\n",
      "Processed 431000 datapoints\n",
      "Processed 432000 datapoints\n",
      "Processed 433000 datapoints\n",
      "Processed 434000 datapoints\n",
      "Processed 435000 datapoints\n",
      "Processed 436000 datapoints\n",
      "Processed 437000 datapoints\n",
      "Processed 438000 datapoints\n",
      "Processed 439000 datapoints\n",
      "Processed 440000 datapoints\n",
      "Processed 441000 datapoints\n",
      "Processed 442000 datapoints\n",
      "Processed 443000 datapoints\n",
      "Processed 444000 datapoints\n",
      "Processed 445000 datapoints\n",
      "Processed 446000 datapoints\n",
      "Processed 447000 datapoints\n",
      "Processed 448000 datapoints\n",
      "Processed 449000 datapoints\n",
      "Processed 450000 datapoints\n",
      "Processed 451000 datapoints\n",
      "Processed 452000 datapoints\n",
      "Processed 453000 datapoints\n",
      "Processed 454000 datapoints\n",
      "Processed 455000 datapoints\n",
      "Processed 456000 datapoints\n",
      "Processed 457000 datapoints\n",
      "Processed 458000 datapoints\n",
      "Processed 459000 datapoints\n",
      "Processed 460000 datapoints\n",
      "Processed 461000 datapoints\n",
      "Processed 462000 datapoints\n",
      "Processed 463000 datapoints\n",
      "Processed 464000 datapoints\n",
      "Processed 465000 datapoints\n",
      "Processed 466000 datapoints\n",
      "Processed 467000 datapoints\n",
      "Processed 468000 datapoints\n",
      "Processed 469000 datapoints\n",
      "Processed 470000 datapoints\n",
      "Processed 471000 datapoints\n",
      "Processed 472000 datapoints\n",
      "Processed 473000 datapoints\n",
      "Processed 474000 datapoints\n",
      "Processed 475000 datapoints\n",
      "Processed 476000 datapoints\n",
      "Processed 477000 datapoints\n",
      "Processed 478000 datapoints\n",
      "Processed 479000 datapoints\n",
      "Processed 480000 datapoints\n",
      "Processed 481000 datapoints\n",
      "Processed 482000 datapoints\n",
      "Processed 483000 datapoints\n",
      "Processed 484000 datapoints\n",
      "Processed 485000 datapoints\n",
      "Processed 486000 datapoints\n",
      "Processed 487000 datapoints\n",
      "Processed 488000 datapoints\n",
      "Processed 489000 datapoints\n",
      "Processed 490000 datapoints\n",
      "Processed 491000 datapoints\n",
      "Processed 492000 datapoints\n",
      "Processed 493000 datapoints\n",
      "Processed 494000 datapoints\n",
      "Processed 495000 datapoints\n",
      "Processed 496000 datapoints\n",
      "Processed 497000 datapoints\n",
      "Processed 498000 datapoints\n",
      "Processed 499000 datapoints\n",
      "Processed 500000 datapoints\n",
      "Processed 501000 datapoints\n",
      "Processed 502000 datapoints\n",
      "Processed 503000 datapoints\n",
      "Processed 504000 datapoints\n",
      "Processed 505000 datapoints\n",
      "Processed 506000 datapoints\n",
      "Processed 507000 datapoints\n",
      "Processed 508000 datapoints\n",
      "Processed 509000 datapoints\n",
      "Processed 510000 datapoints\n",
      "Processed 511000 datapoints\n",
      "Processed 512000 datapoints\n",
      "Processed 513000 datapoints\n",
      "Processed 514000 datapoints\n",
      "Processed 515000 datapoints\n",
      "Processed 516000 datapoints\n",
      "Processed 517000 datapoints\n",
      "Processed 518000 datapoints\n",
      "Processed 519000 datapoints\n",
      "Processed 520000 datapoints\n",
      "Processed 521000 datapoints\n",
      "Processed 522000 datapoints\n",
      "Processed 523000 datapoints\n",
      "Processed 524000 datapoints\n",
      "Processed 525000 datapoints\n",
      "Processed 526000 datapoints\n",
      "Processed 527000 datapoints\n",
      "Processed 528000 datapoints\n",
      "Processed 529000 datapoints\n",
      "Processed 530000 datapoints\n",
      "Processed 531000 datapoints\n",
      "Processed 532000 datapoints\n",
      "Processed 533000 datapoints\n",
      "Processed 534000 datapoints\n",
      "Processed 535000 datapoints\n",
      "Processed 536000 datapoints\n",
      "Processed 537000 datapoints\n",
      "Processed 538000 datapoints\n",
      "Processed 539000 datapoints\n",
      "Processed 540000 datapoints\n",
      "Processed 541000 datapoints\n",
      "Processed 542000 datapoints\n",
      "Processed 543000 datapoints\n",
      "Processed 544000 datapoints\n",
      "Processed 545000 datapoints\n",
      "Processed 546000 datapoints\n",
      "Processed 547000 datapoints\n",
      "Processed 548000 datapoints\n",
      "Processed 549000 datapoints\n",
      "Processed 550000 datapoints\n",
      "Processed 551000 datapoints\n",
      "Processed 552000 datapoints\n",
      "Processed 553000 datapoints\n",
      "Processed 554000 datapoints\n",
      "Processed 555000 datapoints\n",
      "Processed 556000 datapoints\n",
      "Processed 557000 datapoints\n",
      "Processed 558000 datapoints\n",
      "Processed 559000 datapoints\n",
      "Processed 560000 datapoints\n",
      "Processed 561000 datapoints\n",
      "Processed 562000 datapoints\n",
      "Processed 563000 datapoints\n",
      "Processed 564000 datapoints\n",
      "Processed 565000 datapoints\n",
      "Processed 566000 datapoints\n",
      "Processed 567000 datapoints\n",
      "Processed 568000 datapoints\n",
      "Processed 569000 datapoints\n",
      "Processed 570000 datapoints\n",
      "Processed 571000 datapoints\n",
      "Processed 572000 datapoints\n",
      "Processed 573000 datapoints\n",
      "Processed 574000 datapoints\n",
      "Processed 575000 datapoints\n",
      "Processed 576000 datapoints\n",
      "Processed 577000 datapoints\n",
      "Processed 578000 datapoints\n",
      "Processed 579000 datapoints\n",
      "Processed 580000 datapoints\n",
      "Processed 581000 datapoints\n",
      "Processed 582000 datapoints\n",
      "Processed 583000 datapoints\n",
      "Processed 584000 datapoints\n",
      "Processed 585000 datapoints\n",
      "Processed 586000 datapoints\n",
      "Processed 587000 datapoints\n",
      "Processed 588000 datapoints\n",
      "Processed 589000 datapoints\n",
      "Processed 590000 datapoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 591000 datapoints\n",
      "Processed 592000 datapoints\n",
      "Processed 593000 datapoints\n",
      "Processed 594000 datapoints\n",
      "Processed 595000 datapoints\n",
      "Processed 596000 datapoints\n",
      "Processed 597000 datapoints\n",
      "Processed 598000 datapoints\n",
      "Processed 599000 datapoints\n",
      "Processed 600000 datapoints\n",
      "Processed 601000 datapoints\n",
      "Processed 602000 datapoints\n",
      "Processed 603000 datapoints\n",
      "Processed 604000 datapoints\n",
      "Processed 605000 datapoints\n",
      "Processed 606000 datapoints\n",
      "Processed 607000 datapoints\n",
      "Processed 608000 datapoints\n",
      "Processed 609000 datapoints\n",
      "Processed 610000 datapoints\n",
      "Processed 611000 datapoints\n",
      "Processed 612000 datapoints\n",
      "Processed 613000 datapoints\n",
      "Processed 614000 datapoints\n",
      "Processed 615000 datapoints\n",
      "Processed 616000 datapoints\n",
      "Processed 617000 datapoints\n",
      "Processed 618000 datapoints\n",
      "Processed 619000 datapoints\n",
      "Processed 620000 datapoints\n",
      "Processed 621000 datapoints\n",
      "Processed 622000 datapoints\n",
      "Processed 623000 datapoints\n",
      "Processed 624000 datapoints\n",
      "Processed 625000 datapoints\n",
      "Processed 626000 datapoints\n",
      "Processed 627000 datapoints\n",
      "Processed 628000 datapoints\n",
      "Processed 629000 datapoints\n",
      "Processed 630000 datapoints\n",
      "Processed 631000 datapoints\n",
      "Processed 632000 datapoints\n",
      "Processed 633000 datapoints\n",
      "Processed 634000 datapoints\n",
      "Processed 635000 datapoints\n",
      "Processed 636000 datapoints\n",
      "Processed 637000 datapoints\n",
      "Processed 638000 datapoints\n",
      "Processed 639000 datapoints\n",
      "Processed 640000 datapoints\n",
      "Processed 641000 datapoints\n",
      "Processed 642000 datapoints\n",
      "Processed 643000 datapoints\n",
      "Processed 644000 datapoints\n",
      "Processed 645000 datapoints\n",
      "Processed 646000 datapoints\n",
      "Processed 647000 datapoints\n",
      "Processed 648000 datapoints\n",
      "Processed 649000 datapoints\n",
      "Processed 650000 datapoints\n",
      "Processed 651000 datapoints\n",
      "Processed 652000 datapoints\n",
      "Processed 653000 datapoints\n",
      "Processed 654000 datapoints\n",
      "Processed 655000 datapoints\n",
      "Processed 656000 datapoints\n",
      "Processed 657000 datapoints\n",
      "Processed 658000 datapoints\n",
      "Processed 659000 datapoints\n",
      "Processed 660000 datapoints\n",
      "Processed 661000 datapoints\n",
      "Processed 662000 datapoints\n",
      "Processed 663000 datapoints\n",
      "Processed 664000 datapoints\n",
      "Processed 665000 datapoints\n",
      "Processed 666000 datapoints\n",
      "Processed 667000 datapoints\n",
      "Processed 668000 datapoints\n",
      "Processed 669000 datapoints\n",
      "Processed 670000 datapoints\n",
      "Processed 671000 datapoints\n",
      "Processed 672000 datapoints\n",
      "Processed 673000 datapoints\n",
      "Processed 674000 datapoints\n",
      "Processed 675000 datapoints\n",
      "Processed 676000 datapoints\n",
      "Processed 677000 datapoints\n",
      "Processed 678000 datapoints\n",
      "Processed 679000 datapoints\n",
      "Processed 680000 datapoints\n",
      "Processed 681000 datapoints\n",
      "Processed 682000 datapoints\n",
      "Processed 683000 datapoints\n",
      "Processed 684000 datapoints\n",
      "Processed 685000 datapoints\n",
      "Processed 686000 datapoints\n",
      "Processed 687000 datapoints\n",
      "Processed 688000 datapoints\n",
      "Processed 689000 datapoints\n",
      "Processed 690000 datapoints\n",
      "Processed 691000 datapoints\n",
      "Processed 692000 datapoints\n",
      "Processed 693000 datapoints\n",
      "Processed 694000 datapoints\n",
      "Processed 695000 datapoints\n",
      "Processed 696000 datapoints\n",
      "Processed 697000 datapoints\n",
      "Processed 698000 datapoints\n",
      "Processed 699000 datapoints\n",
      "Processed 700000 datapoints\n",
      "Processed 701000 datapoints\n",
      "Processed 702000 datapoints\n",
      "Processed 703000 datapoints\n",
      "Processed 704000 datapoints\n",
      "Processed 705000 datapoints\n",
      "Processed 706000 datapoints\n",
      "Processed 707000 datapoints\n",
      "Processed 708000 datapoints\n",
      "Processed 709000 datapoints\n",
      "Processed 710000 datapoints\n",
      "Processed 711000 datapoints\n",
      "Processed 712000 datapoints\n",
      "Processed 713000 datapoints\n",
      "Processed 714000 datapoints\n",
      "Processed 715000 datapoints\n",
      "Processed 716000 datapoints\n",
      "Processed 717000 datapoints\n",
      "Processed 718000 datapoints\n",
      "Processed 719000 datapoints\n",
      "Processed 720000 datapoints\n",
      "Processed 721000 datapoints\n",
      "Processed 722000 datapoints\n",
      "Processed 723000 datapoints\n",
      "Processed 724000 datapoints\n",
      "Processed 725000 datapoints\n",
      "Processed 726000 datapoints\n",
      "Processed 727000 datapoints\n",
      "Processed 728000 datapoints\n",
      "Processed 729000 datapoints\n",
      "Processed 730000 datapoints\n",
      "Processed 731000 datapoints\n",
      "Processed 732000 datapoints\n",
      "Processed 733000 datapoints\n",
      "Processed 734000 datapoints\n",
      "Processed 735000 datapoints\n",
      "Processed 736000 datapoints\n",
      "Processed 737000 datapoints\n",
      "Processed 738000 datapoints\n",
      "Processed 739000 datapoints\n",
      "Processed 740000 datapoints\n",
      "Processed 741000 datapoints\n",
      "Processed 742000 datapoints\n",
      "Processed 743000 datapoints\n",
      "Processed 744000 datapoints\n",
      "Processed 745000 datapoints\n",
      "Processed 746000 datapoints\n",
      "Processed 747000 datapoints\n",
      "Processed 748000 datapoints\n",
      "Processed 749000 datapoints\n",
      "Processed 750000 datapoints\n",
      "Processed 751000 datapoints\n",
      "Processed 752000 datapoints\n",
      "Processed 753000 datapoints\n",
      "Processed 754000 datapoints\n",
      "Processed 755000 datapoints\n",
      "Processed 756000 datapoints\n",
      "Processed 757000 datapoints\n",
      "Processed 758000 datapoints\n",
      "Processed 759000 datapoints\n",
      "Processed 760000 datapoints\n",
      "Processed 761000 datapoints\n",
      "Processed 762000 datapoints\n",
      "Processed 763000 datapoints\n",
      "Processed 764000 datapoints\n",
      "Processed 765000 datapoints\n",
      "Processed 766000 datapoints\n",
      "Processed 767000 datapoints\n",
      "Processed 768000 datapoints\n",
      "Processed 769000 datapoints\n",
      "Processed 770000 datapoints\n",
      "Processed 771000 datapoints\n",
      "Processed 772000 datapoints\n",
      "Processed 773000 datapoints\n",
      "Processed 774000 datapoints\n",
      "Processed 775000 datapoints\n",
      "Processed 776000 datapoints\n",
      "Processed 777000 datapoints\n",
      "Processed 778000 datapoints\n",
      "Processed 779000 datapoints\n",
      "Processed 780000 datapoints\n",
      "Processed 781000 datapoints\n",
      "Processed 782000 datapoints\n",
      "Processed 783000 datapoints\n",
      "Processed 784000 datapoints\n",
      "Processed 785000 datapoints\n",
      "Processed 786000 datapoints\n",
      "Processed 787000 datapoints\n",
      "Processed 788000 datapoints\n",
      "Processed 789000 datapoints\n",
      "Processed 790000 datapoints\n",
      "Processed 791000 datapoints\n",
      "Processed 792000 datapoints\n",
      "Processed 793000 datapoints\n",
      "Processed 794000 datapoints\n",
      "Processed 795000 datapoints\n",
      "Processed 796000 datapoints\n",
      "Processed 797000 datapoints\n",
      "Processed 798000 datapoints\n",
      "Processed 799000 datapoints\n",
      "Processed 800000 datapoints\n",
      "Processed 801000 datapoints\n",
      "Processed 802000 datapoints\n",
      "Processed 803000 datapoints\n",
      "Processed 804000 datapoints\n",
      "Processed 805000 datapoints\n",
      "Processed 806000 datapoints\n",
      "Processed 807000 datapoints\n",
      "Processed 808000 datapoints\n",
      "Processed 809000 datapoints\n",
      "Processed 810000 datapoints\n",
      "Processed 811000 datapoints\n",
      "Processed 812000 datapoints\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 512\n",
    "input_ids = []\n",
    "attention_masks = [] \n",
    "token_type_ids = [] \n",
    "cnt = 0\n",
    "for sent1, sent2 in zip(splitted_train['title'], splitted_train['content']): \n",
    "    if cnt%1000 == 0 and cnt > 0: \n",
    "        print(\"Processed {} datapoints\".format(cnt)) \n",
    "    cnt += 1\n",
    "    try: \n",
    "        input_id, attention_mask, token_type_id = electra_tokenizer_simple(sent1, sent2, MAX_LEN)\n",
    "        ## check if the number of tokens exceed 510 (excluding [cls] and [sep]) \n",
    "        ## if so empirically select the first 129 and the last 383 tokens \n",
    "        input_ids.append(input_id) \n",
    "        attention_masks.append(attention_mask) \n",
    "        token_type_ids.append(token_type_id) \n",
    "    except Exception as e:  \n",
    "        print(e)         \n",
    "        print(sent1, sent2) \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = np.asarray(input_ids)\n",
    "attention_masks = np.asarray(attention_masks) \n",
    "token_type_ids = np.asarray(token_type_ids)\n",
    "y_train = splitted_train['Label'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, y_train, random_state = 2021, test_size = 0.1, stratify = y_train)\n",
    "\n",
    "train_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids, random_state = 2021, test_size = 0.1)\n",
    "\n",
    "train_token_type_ids, val_token_type_ids, _, _ = train_test_split(token_type_ids, input_ids, random_state = 2021, test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "train_token_type_ids = torch.tensor(train_token_type_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs = torch.tensor(val_inputs) \n",
    "val_labels = torch.tensor(val_labels) \n",
    "val_masks = torch.tensor(val_masks) \n",
    "val_token_type_ids = torch.tensor(val_token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_token_type_ids, train_labels) \n",
    "train_sampler = RandomSampler(train_data) \n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = TensorDataset(val_inputs, val_masks, val_token_type_ids, val_labels) \n",
    "val_sampler = SequentialSampler(val_data) \n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")   \n",
    "model.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed): \n",
    "    elapsed_rounded = int(round(elapsed)) \n",
    "    return str(datetime.timedelta(seconds = elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [] \n",
    "def compute_accuracy(model, dataloader, device):\n",
    "    tqdm()\n",
    "    model.eval()\n",
    "    correct_preds, num_samples = 0,0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader)):\n",
    "            b_input_ids, b_input_masks, b_token_type_ids, b_labels = tuple(t.to(device) for t in batch) \n",
    "            loss, yhat = model(input_ids=b_input_ids, attention_mask=b_input_masks, \n",
    "                               token_type_ids = b_token_type_ids, labels=b_labels.long())\n",
    "            prediction = (torch.sigmoid(yhat[:,1]) > 0.5).long() \n",
    "            predictions.append(prediction)\n",
    "            num_samples += b_labels.size(0)\n",
    "            correct_preds += (prediction==b_labels.long()).sum()\n",
    "            del b_input_ids, b_input_masks, b_token_type_ids, b_labels #memory\n",
    "        torch.cuda.empty_cache() #memory\n",
    "        gc.collect() # memory \n",
    "        return correct_preds.float()/num_samples*100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1 / 10 =====\n",
      "Training ...\n",
      "Epoch: 001/010 | Batch 001/45709 | Average Loss in last 1 iteration(s): 0.6811 | Elapsed 0:00:01\n",
      "Epoch: 001/010 | Batch 026/45709 | Average Loss in last 25 iteration(s): 0.6957 | Elapsed 0:00:27\n",
      "Epoch: 001/010 | Batch 051/45709 | Average Loss in last 25 iteration(s): 0.6914 | Elapsed 0:00:52\n",
      "Epoch: 001/010 | Batch 076/45709 | Average Loss in last 25 iteration(s): 0.6942 | Elapsed 0:01:21\n",
      "Epoch: 001/010 | Batch 101/45709 | Average Loss in last 25 iteration(s): 0.6903 | Elapsed 0:01:45\n",
      "Epoch: 001/010 | Batch 126/45709 | Average Loss in last 25 iteration(s): 0.6901 | Elapsed 0:02:11\n",
      "Epoch: 001/010 | Batch 151/45709 | Average Loss in last 25 iteration(s): 0.6810 | Elapsed 0:02:37\n",
      "Epoch: 001/010 | Batch 176/45709 | Average Loss in last 25 iteration(s): 0.6581 | Elapsed 0:03:03\n",
      "Epoch: 001/010 | Batch 201/45709 | Average Loss in last 25 iteration(s): 0.6332 | Elapsed 0:03:25\n",
      "Epoch: 001/010 | Batch 226/45709 | Average Loss in last 25 iteration(s): 0.6422 | Elapsed 0:03:52\n",
      "Epoch: 001/010 | Batch 251/45709 | Average Loss in last 25 iteration(s): 0.6002 | Elapsed 0:04:19\n",
      "Epoch: 001/010 | Batch 276/45709 | Average Loss in last 25 iteration(s): 0.5956 | Elapsed 0:04:45\n",
      "Epoch: 001/010 | Batch 301/45709 | Average Loss in last 25 iteration(s): 0.6263 | Elapsed 0:05:12\n",
      "Epoch: 001/010 | Batch 326/45709 | Average Loss in last 25 iteration(s): 0.6094 | Elapsed 0:05:36\n",
      "Epoch: 001/010 | Batch 351/45709 | Average Loss in last 25 iteration(s): 0.5573 | Elapsed 0:05:59\n",
      "Epoch: 001/010 | Batch 376/45709 | Average Loss in last 25 iteration(s): 0.6115 | Elapsed 0:06:26\n",
      "Epoch: 001/010 | Batch 401/45709 | Average Loss in last 25 iteration(s): 0.5833 | Elapsed 0:06:54\n",
      "Epoch: 001/010 | Batch 426/45709 | Average Loss in last 25 iteration(s): 0.5661 | Elapsed 0:07:19\n",
      "Epoch: 001/010 | Batch 451/45709 | Average Loss in last 25 iteration(s): 0.5988 | Elapsed 0:07:46\n",
      "Epoch: 001/010 | Batch 476/45709 | Average Loss in last 25 iteration(s): 0.5492 | Elapsed 0:08:11\n",
      "Epoch: 001/010 | Batch 501/45709 | Average Loss in last 25 iteration(s): 0.5512 | Elapsed 0:08:34\n",
      "Epoch: 001/010 | Batch 526/45709 | Average Loss in last 25 iteration(s): 0.5686 | Elapsed 0:08:58\n",
      "Epoch: 001/010 | Batch 551/45709 | Average Loss in last 25 iteration(s): 0.5874 | Elapsed 0:09:27\n",
      "Epoch: 001/010 | Batch 576/45709 | Average Loss in last 25 iteration(s): 0.5572 | Elapsed 0:09:53\n",
      "Epoch: 001/010 | Batch 601/45709 | Average Loss in last 25 iteration(s): 0.5712 | Elapsed 0:10:20\n",
      "Epoch: 001/010 | Batch 626/45709 | Average Loss in last 25 iteration(s): 0.5702 | Elapsed 0:10:45\n",
      "Epoch: 001/010 | Batch 651/45709 | Average Loss in last 25 iteration(s): 0.5414 | Elapsed 0:11:09\n",
      "Epoch: 001/010 | Batch 676/45709 | Average Loss in last 25 iteration(s): 0.5379 | Elapsed 0:11:33\n",
      "Epoch: 001/010 | Batch 701/45709 | Average Loss in last 25 iteration(s): 0.5363 | Elapsed 0:12:01\n",
      "Epoch: 001/010 | Batch 726/45709 | Average Loss in last 25 iteration(s): 0.5537 | Elapsed 0:12:27\n",
      "Epoch: 001/010 | Batch 751/45709 | Average Loss in last 25 iteration(s): 0.5467 | Elapsed 0:12:54\n",
      "Epoch: 001/010 | Batch 776/45709 | Average Loss in last 25 iteration(s): 0.5102 | Elapsed 0:13:20\n",
      "Epoch: 001/010 | Batch 801/45709 | Average Loss in last 25 iteration(s): 0.5662 | Elapsed 0:13:44\n",
      "Epoch: 001/010 | Batch 826/45709 | Average Loss in last 25 iteration(s): 0.4904 | Elapsed 0:14:06\n",
      "Epoch: 001/010 | Batch 851/45709 | Average Loss in last 25 iteration(s): 0.5189 | Elapsed 0:14:36\n",
      "Epoch: 001/010 | Batch 876/45709 | Average Loss in last 25 iteration(s): 0.5382 | Elapsed 0:15:01\n",
      "Epoch: 001/010 | Batch 901/45709 | Average Loss in last 25 iteration(s): 0.5219 | Elapsed 0:15:27\n",
      "Epoch: 001/010 | Batch 926/45709 | Average Loss in last 25 iteration(s): 0.5075 | Elapsed 0:15:53\n",
      "Epoch: 001/010 | Batch 951/45709 | Average Loss in last 25 iteration(s): 0.4740 | Elapsed 0:16:19\n",
      "Epoch: 001/010 | Batch 976/45709 | Average Loss in last 25 iteration(s): 0.5543 | Elapsed 0:16:41\n",
      "Epoch: 001/010 | Batch 1001/45709 | Average Loss in last 25 iteration(s): 0.5240 | Elapsed 0:17:07\n",
      "Epoch: 001/010 | Batch 1026/45709 | Average Loss in last 25 iteration(s): 0.5084 | Elapsed 0:17:34\n",
      "Epoch: 001/010 | Batch 1051/45709 | Average Loss in last 25 iteration(s): 0.5265 | Elapsed 0:17:59\n",
      "Epoch: 001/010 | Batch 1076/45709 | Average Loss in last 25 iteration(s): 0.4853 | Elapsed 0:18:25\n",
      "Epoch: 001/010 | Batch 1101/45709 | Average Loss in last 25 iteration(s): 0.5282 | Elapsed 0:18:51\n",
      "Epoch: 001/010 | Batch 1126/45709 | Average Loss in last 25 iteration(s): 0.5474 | Elapsed 0:19:17\n",
      "Epoch: 001/010 | Batch 1151/45709 | Average Loss in last 25 iteration(s): 0.5520 | Elapsed 0:19:40\n",
      "Epoch: 001/010 | Batch 1176/45709 | Average Loss in last 25 iteration(s): 0.4988 | Elapsed 0:20:07\n",
      "Epoch: 001/010 | Batch 1201/45709 | Average Loss in last 25 iteration(s): 0.4947 | Elapsed 0:20:34\n",
      "Epoch: 001/010 | Batch 1226/45709 | Average Loss in last 25 iteration(s): 0.5041 | Elapsed 0:21:01\n",
      "Epoch: 001/010 | Batch 1251/45709 | Average Loss in last 25 iteration(s): 0.4719 | Elapsed 0:21:30\n",
      "Epoch: 001/010 | Batch 1276/45709 | Average Loss in last 25 iteration(s): 0.4941 | Elapsed 0:21:55\n",
      "Epoch: 001/010 | Batch 1301/45709 | Average Loss in last 25 iteration(s): 0.4783 | Elapsed 0:22:18\n",
      "Epoch: 001/010 | Batch 1326/45709 | Average Loss in last 25 iteration(s): 0.4683 | Elapsed 0:22:49\n",
      "Epoch: 001/010 | Batch 1351/45709 | Average Loss in last 25 iteration(s): 0.4754 | Elapsed 0:23:14\n",
      "Epoch: 001/010 | Batch 1376/45709 | Average Loss in last 25 iteration(s): 0.5097 | Elapsed 0:23:40\n",
      "Epoch: 001/010 | Batch 1401/45709 | Average Loss in last 25 iteration(s): 0.4899 | Elapsed 0:24:06\n",
      "Epoch: 001/010 | Batch 1426/45709 | Average Loss in last 25 iteration(s): 0.4832 | Elapsed 0:24:32\n",
      "Epoch: 001/010 | Batch 1451/45709 | Average Loss in last 25 iteration(s): 0.4936 | Elapsed 0:24:54\n",
      "Epoch: 001/010 | Batch 1476/45709 | Average Loss in last 25 iteration(s): 0.5252 | Elapsed 0:25:23\n",
      "Epoch: 001/010 | Batch 1501/45709 | Average Loss in last 25 iteration(s): 0.4744 | Elapsed 0:25:51\n",
      "Epoch: 001/010 | Batch 1526/45709 | Average Loss in last 25 iteration(s): 0.5517 | Elapsed 0:26:16\n",
      "Epoch: 001/010 | Batch 1551/45709 | Average Loss in last 25 iteration(s): 0.4797 | Elapsed 0:26:41\n",
      "Epoch: 001/010 | Batch 1576/45709 | Average Loss in last 25 iteration(s): 0.4677 | Elapsed 0:27:08\n",
      "Epoch: 001/010 | Batch 1601/45709 | Average Loss in last 25 iteration(s): 0.4993 | Elapsed 0:27:30\n",
      "Epoch: 001/010 | Batch 1626/45709 | Average Loss in last 25 iteration(s): 0.4829 | Elapsed 0:27:58\n",
      "Epoch: 001/010 | Batch 1651/45709 | Average Loss in last 25 iteration(s): 0.4867 | Elapsed 0:28:27\n",
      "Epoch: 001/010 | Batch 1676/45709 | Average Loss in last 25 iteration(s): 0.4802 | Elapsed 0:28:52\n",
      "Epoch: 001/010 | Batch 1701/45709 | Average Loss in last 25 iteration(s): 0.4718 | Elapsed 0:29:19\n",
      "Epoch: 001/010 | Batch 1726/45709 | Average Loss in last 25 iteration(s): 0.4833 | Elapsed 0:29:44\n",
      "Epoch: 001/010 | Batch 1751/45709 | Average Loss in last 25 iteration(s): 0.5241 | Elapsed 0:30:06\n",
      "Epoch: 001/010 | Batch 1776/45709 | Average Loss in last 25 iteration(s): 0.5118 | Elapsed 0:30:34\n",
      "Epoch: 001/010 | Batch 1801/45709 | Average Loss in last 25 iteration(s): 0.5100 | Elapsed 0:31:03\n",
      "Epoch: 001/010 | Batch 1826/45709 | Average Loss in last 25 iteration(s): 0.4859 | Elapsed 0:31:28\n",
      "Epoch: 001/010 | Batch 1851/45709 | Average Loss in last 25 iteration(s): 0.4783 | Elapsed 0:31:53\n",
      "Epoch: 001/010 | Batch 1876/45709 | Average Loss in last 25 iteration(s): 0.4848 | Elapsed 0:32:21\n",
      "Epoch: 001/010 | Batch 1901/45709 | Average Loss in last 25 iteration(s): 0.5349 | Elapsed 0:32:44\n",
      "Epoch: 001/010 | Batch 1926/45709 | Average Loss in last 25 iteration(s): 0.5331 | Elapsed 0:33:14\n",
      "Epoch: 001/010 | Batch 1951/45709 | Average Loss in last 25 iteration(s): 0.4221 | Elapsed 0:33:41\n",
      "Epoch: 001/010 | Batch 1976/45709 | Average Loss in last 25 iteration(s): 0.4897 | Elapsed 0:34:07\n",
      "Epoch: 001/010 | Batch 2001/45709 | Average Loss in last 25 iteration(s): 0.5209 | Elapsed 0:34:34\n",
      "Epoch: 001/010 | Batch 2026/45709 | Average Loss in last 25 iteration(s): 0.4814 | Elapsed 0:34:58\n",
      "Epoch: 001/010 | Batch 2051/45709 | Average Loss in last 25 iteration(s): 0.4694 | Elapsed 0:35:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 2076/45709 | Average Loss in last 25 iteration(s): 0.4215 | Elapsed 0:35:49\n",
      "Epoch: 001/010 | Batch 2101/45709 | Average Loss in last 25 iteration(s): 0.4809 | Elapsed 0:36:13\n",
      "Epoch: 001/010 | Batch 2126/45709 | Average Loss in last 25 iteration(s): 0.4456 | Elapsed 0:36:40\n",
      "Epoch: 001/010 | Batch 2151/45709 | Average Loss in last 25 iteration(s): 0.4777 | Elapsed 0:37:06\n",
      "Epoch: 001/010 | Batch 2176/45709 | Average Loss in last 25 iteration(s): 0.4547 | Elapsed 0:37:32\n",
      "Epoch: 001/010 | Batch 2201/45709 | Average Loss in last 25 iteration(s): 0.4735 | Elapsed 0:37:55\n",
      "Epoch: 001/010 | Batch 2226/45709 | Average Loss in last 25 iteration(s): 0.4646 | Elapsed 0:38:23\n",
      "Epoch: 001/010 | Batch 2251/45709 | Average Loss in last 25 iteration(s): 0.4722 | Elapsed 0:38:50\n",
      "Epoch: 001/010 | Batch 2276/45709 | Average Loss in last 25 iteration(s): 0.4739 | Elapsed 0:39:17\n",
      "Epoch: 001/010 | Batch 2301/45709 | Average Loss in last 25 iteration(s): 0.4378 | Elapsed 0:39:43\n",
      "Epoch: 001/010 | Batch 2326/45709 | Average Loss in last 25 iteration(s): 0.4621 | Elapsed 0:40:07\n",
      "Epoch: 001/010 | Batch 2351/45709 | Average Loss in last 25 iteration(s): 0.4710 | Elapsed 0:40:31\n",
      "Epoch: 001/010 | Batch 2376/45709 | Average Loss in last 25 iteration(s): 0.4730 | Elapsed 0:40:55\n",
      "Epoch: 001/010 | Batch 2401/45709 | Average Loss in last 25 iteration(s): 0.5046 | Elapsed 0:41:23\n",
      "Epoch: 001/010 | Batch 2426/45709 | Average Loss in last 25 iteration(s): 0.4651 | Elapsed 0:41:49\n",
      "Epoch: 001/010 | Batch 2451/45709 | Average Loss in last 25 iteration(s): 0.5221 | Elapsed 0:42:14\n",
      "Epoch: 001/010 | Batch 2476/45709 | Average Loss in last 25 iteration(s): 0.4788 | Elapsed 0:42:39\n",
      "Epoch: 001/010 | Batch 2501/45709 | Average Loss in last 25 iteration(s): 0.4918 | Elapsed 0:43:06\n",
      "Epoch: 001/010 | Batch 2526/45709 | Average Loss in last 25 iteration(s): 0.4878 | Elapsed 0:43:29\n",
      "Epoch: 001/010 | Batch 2551/45709 | Average Loss in last 25 iteration(s): 0.4792 | Elapsed 0:43:56\n",
      "Epoch: 001/010 | Batch 2576/45709 | Average Loss in last 25 iteration(s): 0.4222 | Elapsed 0:44:21\n",
      "Epoch: 001/010 | Batch 2601/45709 | Average Loss in last 25 iteration(s): 0.5018 | Elapsed 0:44:49\n",
      "Epoch: 001/010 | Batch 2626/45709 | Average Loss in last 25 iteration(s): 0.4726 | Elapsed 0:45:14\n",
      "Epoch: 001/010 | Batch 2651/45709 | Average Loss in last 25 iteration(s): 0.3981 | Elapsed 0:45:40\n",
      "Epoch: 001/010 | Batch 2676/45709 | Average Loss in last 25 iteration(s): 0.4438 | Elapsed 0:46:05\n",
      "Epoch: 001/010 | Batch 2701/45709 | Average Loss in last 25 iteration(s): 0.4586 | Elapsed 0:46:27\n",
      "Epoch: 001/010 | Batch 2726/45709 | Average Loss in last 25 iteration(s): 0.4158 | Elapsed 0:46:55\n",
      "Epoch: 001/010 | Batch 2751/45709 | Average Loss in last 25 iteration(s): 0.4535 | Elapsed 0:47:23\n",
      "Epoch: 001/010 | Batch 2776/45709 | Average Loss in last 25 iteration(s): 0.4353 | Elapsed 0:47:50\n",
      "Epoch: 001/010 | Batch 2801/45709 | Average Loss in last 25 iteration(s): 0.4667 | Elapsed 0:48:17\n",
      "Epoch: 001/010 | Batch 2826/45709 | Average Loss in last 25 iteration(s): 0.4939 | Elapsed 0:48:42\n",
      "Epoch: 001/010 | Batch 2851/45709 | Average Loss in last 25 iteration(s): 0.4263 | Elapsed 0:49:06\n",
      "Epoch: 001/010 | Batch 2876/45709 | Average Loss in last 25 iteration(s): 0.5056 | Elapsed 0:49:34\n",
      "Epoch: 001/010 | Batch 2901/45709 | Average Loss in last 25 iteration(s): 0.4994 | Elapsed 0:50:00\n",
      "Epoch: 001/010 | Batch 2926/45709 | Average Loss in last 25 iteration(s): 0.4408 | Elapsed 0:50:25\n",
      "Epoch: 001/010 | Batch 2951/45709 | Average Loss in last 25 iteration(s): 0.4351 | Elapsed 0:50:50\n",
      "Epoch: 001/010 | Batch 2976/45709 | Average Loss in last 25 iteration(s): 0.4556 | Elapsed 0:51:17\n",
      "Epoch: 001/010 | Batch 3001/45709 | Average Loss in last 25 iteration(s): 0.5031 | Elapsed 0:51:41\n",
      "Epoch: 001/010 | Batch 3026/45709 | Average Loss in last 25 iteration(s): 0.4418 | Elapsed 0:52:07\n",
      "Epoch: 001/010 | Batch 3051/45709 | Average Loss in last 25 iteration(s): 0.3884 | Elapsed 0:52:34\n",
      "Epoch: 001/010 | Batch 3076/45709 | Average Loss in last 25 iteration(s): 0.4228 | Elapsed 0:53:02\n",
      "Epoch: 001/010 | Batch 3101/45709 | Average Loss in last 25 iteration(s): 0.4605 | Elapsed 0:53:28\n",
      "Epoch: 001/010 | Batch 3126/45709 | Average Loss in last 25 iteration(s): 0.4398 | Elapsed 0:53:55\n",
      "Epoch: 001/010 | Batch 3151/45709 | Average Loss in last 25 iteration(s): 0.4685 | Elapsed 0:54:18\n",
      "Epoch: 001/010 | Batch 3176/45709 | Average Loss in last 25 iteration(s): 0.4562 | Elapsed 0:54:44\n",
      "Epoch: 001/010 | Batch 3201/45709 | Average Loss in last 25 iteration(s): 0.4266 | Elapsed 0:55:05\n",
      "Epoch: 001/010 | Batch 3226/45709 | Average Loss in last 25 iteration(s): 0.4283 | Elapsed 0:55:32\n",
      "Epoch: 001/010 | Batch 3251/45709 | Average Loss in last 25 iteration(s): 0.4517 | Elapsed 0:55:57\n",
      "Epoch: 001/010 | Batch 3276/45709 | Average Loss in last 25 iteration(s): 0.4706 | Elapsed 0:56:23\n",
      "Epoch: 001/010 | Batch 3301/45709 | Average Loss in last 25 iteration(s): 0.4339 | Elapsed 0:56:49\n",
      "Epoch: 001/010 | Batch 3326/45709 | Average Loss in last 25 iteration(s): 0.4069 | Elapsed 0:57:10\n",
      "Epoch: 001/010 | Batch 3351/45709 | Average Loss in last 25 iteration(s): 0.4558 | Elapsed 0:57:37\n",
      "Epoch: 001/010 | Batch 3376/45709 | Average Loss in last 25 iteration(s): 0.4715 | Elapsed 0:58:03\n",
      "Epoch: 001/010 | Batch 3401/45709 | Average Loss in last 25 iteration(s): 0.3810 | Elapsed 0:58:27\n",
      "Epoch: 001/010 | Batch 3426/45709 | Average Loss in last 25 iteration(s): 0.4268 | Elapsed 0:58:53\n",
      "Epoch: 001/010 | Batch 3451/45709 | Average Loss in last 25 iteration(s): 0.4564 | Elapsed 0:59:19\n",
      "Epoch: 001/010 | Batch 3476/45709 | Average Loss in last 25 iteration(s): 0.4478 | Elapsed 0:59:45\n",
      "Epoch: 001/010 | Batch 3501/45709 | Average Loss in last 25 iteration(s): 0.3943 | Elapsed 1:00:07\n",
      "Epoch: 001/010 | Batch 3526/45709 | Average Loss in last 25 iteration(s): 0.4533 | Elapsed 1:00:36\n",
      "Epoch: 001/010 | Batch 3551/45709 | Average Loss in last 25 iteration(s): 0.4102 | Elapsed 1:01:02\n",
      "Epoch: 001/010 | Batch 3576/45709 | Average Loss in last 25 iteration(s): 0.4171 | Elapsed 1:01:30\n",
      "Epoch: 001/010 | Batch 3601/45709 | Average Loss in last 25 iteration(s): 0.4921 | Elapsed 1:01:56\n",
      "Epoch: 001/010 | Batch 3626/45709 | Average Loss in last 25 iteration(s): 0.4036 | Elapsed 1:02:22\n",
      "Epoch: 001/010 | Batch 3651/45709 | Average Loss in last 25 iteration(s): 0.4075 | Elapsed 1:02:45\n",
      "Epoch: 001/010 | Batch 3676/45709 | Average Loss in last 25 iteration(s): 0.3978 | Elapsed 1:03:12\n",
      "Epoch: 001/010 | Batch 3701/45709 | Average Loss in last 25 iteration(s): 0.4259 | Elapsed 1:03:38\n",
      "Epoch: 001/010 | Batch 3726/45709 | Average Loss in last 25 iteration(s): 0.4680 | Elapsed 1:04:07\n",
      "Epoch: 001/010 | Batch 3751/45709 | Average Loss in last 25 iteration(s): 0.3705 | Elapsed 1:04:27\n",
      "Epoch: 001/010 | Batch 3776/45709 | Average Loss in last 25 iteration(s): 0.3442 | Elapsed 1:04:54\n",
      "Epoch: 001/010 | Batch 3801/45709 | Average Loss in last 25 iteration(s): 0.5275 | Elapsed 1:05:19\n",
      "Epoch: 001/010 | Batch 3826/45709 | Average Loss in last 25 iteration(s): 0.4369 | Elapsed 1:05:43\n",
      "Epoch: 001/010 | Batch 3851/45709 | Average Loss in last 25 iteration(s): 0.4389 | Elapsed 1:06:08\n",
      "Epoch: 001/010 | Batch 3876/45709 | Average Loss in last 25 iteration(s): 0.4180 | Elapsed 1:06:36\n",
      "Epoch: 001/010 | Batch 3901/45709 | Average Loss in last 25 iteration(s): 0.4324 | Elapsed 1:07:02\n",
      "Epoch: 001/010 | Batch 3926/45709 | Average Loss in last 25 iteration(s): 0.3591 | Elapsed 1:07:26\n",
      "Epoch: 001/010 | Batch 3951/45709 | Average Loss in last 25 iteration(s): 0.4295 | Elapsed 1:07:52\n",
      "Epoch: 001/010 | Batch 3976/45709 | Average Loss in last 25 iteration(s): 0.4512 | Elapsed 1:08:15\n",
      "Epoch: 001/010 | Batch 4001/45709 | Average Loss in last 25 iteration(s): 0.4680 | Elapsed 1:08:42\n",
      "Epoch: 001/010 | Batch 4026/45709 | Average Loss in last 25 iteration(s): 0.4217 | Elapsed 1:09:10\n",
      "Epoch: 001/010 | Batch 4051/45709 | Average Loss in last 25 iteration(s): 0.3978 | Elapsed 1:09:35\n",
      "Epoch: 001/010 | Batch 4076/45709 | Average Loss in last 25 iteration(s): 0.3998 | Elapsed 1:10:01\n",
      "Epoch: 001/010 | Batch 4101/45709 | Average Loss in last 25 iteration(s): 0.4371 | Elapsed 1:10:27\n",
      "Epoch: 001/010 | Batch 4126/45709 | Average Loss in last 25 iteration(s): 0.3990 | Elapsed 1:10:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 4151/45709 | Average Loss in last 25 iteration(s): 0.4340 | Elapsed 1:11:14\n",
      "Epoch: 001/010 | Batch 4176/45709 | Average Loss in last 25 iteration(s): 0.4702 | Elapsed 1:11:44\n",
      "Epoch: 001/010 | Batch 4201/45709 | Average Loss in last 25 iteration(s): 0.4192 | Elapsed 1:12:08\n",
      "Epoch: 001/010 | Batch 4226/45709 | Average Loss in last 25 iteration(s): 0.4261 | Elapsed 1:12:35\n",
      "Epoch: 001/010 | Batch 4251/45709 | Average Loss in last 25 iteration(s): 0.4647 | Elapsed 1:13:00\n",
      "Epoch: 001/010 | Batch 4276/45709 | Average Loss in last 25 iteration(s): 0.4102 | Elapsed 1:13:26\n",
      "Epoch: 001/010 | Batch 4301/45709 | Average Loss in last 25 iteration(s): 0.4497 | Elapsed 1:13:48\n",
      "Epoch: 001/010 | Batch 4326/45709 | Average Loss in last 25 iteration(s): 0.4548 | Elapsed 1:14:14\n",
      "Epoch: 001/010 | Batch 4351/45709 | Average Loss in last 25 iteration(s): 0.4321 | Elapsed 1:14:43\n",
      "Epoch: 001/010 | Batch 4376/45709 | Average Loss in last 25 iteration(s): 0.3959 | Elapsed 1:15:08\n",
      "Epoch: 001/010 | Batch 4401/45709 | Average Loss in last 25 iteration(s): 0.4044 | Elapsed 1:15:34\n",
      "Epoch: 001/010 | Batch 4426/45709 | Average Loss in last 25 iteration(s): 0.3829 | Elapsed 1:16:00\n",
      "Epoch: 001/010 | Batch 4451/45709 | Average Loss in last 25 iteration(s): 0.3982 | Elapsed 1:16:25\n",
      "Epoch: 001/010 | Batch 4476/45709 | Average Loss in last 25 iteration(s): 0.3793 | Elapsed 1:16:48\n",
      "Epoch: 001/010 | Batch 4501/45709 | Average Loss in last 25 iteration(s): 0.4850 | Elapsed 1:17:15\n",
      "Epoch: 001/010 | Batch 4526/45709 | Average Loss in last 25 iteration(s): 0.4548 | Elapsed 1:17:41\n",
      "Epoch: 001/010 | Batch 4551/45709 | Average Loss in last 25 iteration(s): 0.3940 | Elapsed 1:18:08\n",
      "Epoch: 001/010 | Batch 4576/45709 | Average Loss in last 25 iteration(s): 0.4177 | Elapsed 1:18:35\n",
      "Epoch: 001/010 | Batch 4601/45709 | Average Loss in last 25 iteration(s): 0.3886 | Elapsed 1:19:02\n",
      "Epoch: 001/010 | Batch 4626/45709 | Average Loss in last 25 iteration(s): 0.3957 | Elapsed 1:19:25\n",
      "Epoch: 001/010 | Batch 4651/45709 | Average Loss in last 25 iteration(s): 0.3602 | Elapsed 1:19:52\n",
      "Epoch: 001/010 | Batch 4676/45709 | Average Loss in last 25 iteration(s): 0.4290 | Elapsed 1:20:20\n",
      "Epoch: 001/010 | Batch 4701/45709 | Average Loss in last 25 iteration(s): 0.3735 | Elapsed 1:20:46\n",
      "Epoch: 001/010 | Batch 4726/45709 | Average Loss in last 25 iteration(s): 0.3715 | Elapsed 1:21:13\n",
      "Epoch: 001/010 | Batch 4751/45709 | Average Loss in last 25 iteration(s): 0.4242 | Elapsed 1:21:43\n",
      "Epoch: 001/010 | Batch 4776/45709 | Average Loss in last 25 iteration(s): 0.4015 | Elapsed 1:22:05\n",
      "Epoch: 001/010 | Batch 4801/45709 | Average Loss in last 25 iteration(s): 0.3761 | Elapsed 1:22:32\n",
      "Epoch: 001/010 | Batch 4826/45709 | Average Loss in last 25 iteration(s): 0.3872 | Elapsed 1:22:59\n",
      "Epoch: 001/010 | Batch 4851/45709 | Average Loss in last 25 iteration(s): 0.4126 | Elapsed 1:23:26\n",
      "Epoch: 001/010 | Batch 4876/45709 | Average Loss in last 25 iteration(s): 0.3406 | Elapsed 1:23:52\n",
      "Epoch: 001/010 | Batch 4901/45709 | Average Loss in last 25 iteration(s): 0.4328 | Elapsed 1:24:19\n",
      "Epoch: 001/010 | Batch 4926/45709 | Average Loss in last 25 iteration(s): 0.3754 | Elapsed 1:24:40\n",
      "Epoch: 001/010 | Batch 4951/45709 | Average Loss in last 25 iteration(s): 0.4301 | Elapsed 1:25:06\n",
      "Epoch: 001/010 | Batch 4976/45709 | Average Loss in last 25 iteration(s): 0.3902 | Elapsed 1:25:33\n",
      "Epoch: 001/010 | Batch 5001/45709 | Average Loss in last 25 iteration(s): 0.3988 | Elapsed 1:25:59\n",
      "Epoch: 001/010 | Batch 5026/45709 | Average Loss in last 25 iteration(s): 0.3664 | Elapsed 1:26:25\n",
      "Epoch: 001/010 | Batch 5051/45709 | Average Loss in last 25 iteration(s): 0.4041 | Elapsed 1:26:53\n",
      "Epoch: 001/010 | Batch 5076/45709 | Average Loss in last 25 iteration(s): 0.4140 | Elapsed 1:27:19\n",
      "Epoch: 001/010 | Batch 5101/45709 | Average Loss in last 25 iteration(s): 0.4289 | Elapsed 1:27:44\n",
      "Epoch: 001/010 | Batch 5126/45709 | Average Loss in last 25 iteration(s): 0.3826 | Elapsed 1:28:05\n",
      "Epoch: 001/010 | Batch 5151/45709 | Average Loss in last 25 iteration(s): 0.4307 | Elapsed 1:28:36\n",
      "Epoch: 001/010 | Batch 5176/45709 | Average Loss in last 25 iteration(s): 0.4018 | Elapsed 1:29:06\n",
      "Epoch: 001/010 | Batch 5201/45709 | Average Loss in last 25 iteration(s): 0.3845 | Elapsed 1:29:30\n",
      "Epoch: 001/010 | Batch 5226/45709 | Average Loss in last 25 iteration(s): 0.4511 | Elapsed 1:29:55\n",
      "Epoch: 001/010 | Batch 5251/45709 | Average Loss in last 25 iteration(s): 0.4408 | Elapsed 1:30:21\n",
      "Epoch: 001/010 | Batch 5276/45709 | Average Loss in last 25 iteration(s): 0.4191 | Elapsed 1:30:49\n",
      "Epoch: 001/010 | Batch 5301/45709 | Average Loss in last 25 iteration(s): 0.4100 | Elapsed 1:31:17\n",
      "Epoch: 001/010 | Batch 5326/45709 | Average Loss in last 25 iteration(s): 0.3898 | Elapsed 1:31:44\n",
      "Epoch: 001/010 | Batch 5351/45709 | Average Loss in last 25 iteration(s): 0.4210 | Elapsed 1:32:10\n",
      "Epoch: 001/010 | Batch 5376/45709 | Average Loss in last 25 iteration(s): 0.3850 | Elapsed 1:32:32\n",
      "Epoch: 001/010 | Batch 5401/45709 | Average Loss in last 25 iteration(s): 0.4055 | Elapsed 1:32:52\n",
      "Epoch: 001/010 | Batch 5426/45709 | Average Loss in last 25 iteration(s): 0.3596 | Elapsed 1:33:18\n",
      "Epoch: 001/010 | Batch 5451/45709 | Average Loss in last 25 iteration(s): 0.4241 | Elapsed 1:33:50\n",
      "Epoch: 001/010 | Batch 5476/45709 | Average Loss in last 25 iteration(s): 0.3737 | Elapsed 1:34:18\n",
      "Epoch: 001/010 | Batch 5501/45709 | Average Loss in last 25 iteration(s): 0.3946 | Elapsed 1:34:43\n",
      "Epoch: 001/010 | Batch 5526/45709 | Average Loss in last 25 iteration(s): 0.3743 | Elapsed 1:35:07\n",
      "Epoch: 001/010 | Batch 5551/45709 | Average Loss in last 25 iteration(s): 0.4114 | Elapsed 1:35:28\n",
      "Epoch: 001/010 | Batch 5576/45709 | Average Loss in last 25 iteration(s): 0.3853 | Elapsed 1:35:53\n",
      "Epoch: 001/010 | Batch 5601/45709 | Average Loss in last 25 iteration(s): 0.3882 | Elapsed 1:36:24\n",
      "Epoch: 001/010 | Batch 5626/45709 | Average Loss in last 25 iteration(s): 0.4154 | Elapsed 1:36:50\n",
      "Epoch: 001/010 | Batch 5651/45709 | Average Loss in last 25 iteration(s): 0.3793 | Elapsed 1:37:15\n",
      "Epoch: 001/010 | Batch 5676/45709 | Average Loss in last 25 iteration(s): 0.3987 | Elapsed 1:37:40\n",
      "Epoch: 001/010 | Batch 5701/45709 | Average Loss in last 25 iteration(s): 0.3883 | Elapsed 1:38:02\n",
      "Epoch: 001/010 | Batch 5726/45709 | Average Loss in last 25 iteration(s): 0.4146 | Elapsed 1:38:28\n",
      "Epoch: 001/010 | Batch 5751/45709 | Average Loss in last 25 iteration(s): 0.3851 | Elapsed 1:38:57\n",
      "Epoch: 001/010 | Batch 5776/45709 | Average Loss in last 25 iteration(s): 0.4011 | Elapsed 1:39:23\n",
      "Epoch: 001/010 | Batch 5801/45709 | Average Loss in last 25 iteration(s): 0.4312 | Elapsed 1:39:50\n",
      "Epoch: 001/010 | Batch 5826/45709 | Average Loss in last 25 iteration(s): 0.4399 | Elapsed 1:40:16\n",
      "Epoch: 001/010 | Batch 5851/45709 | Average Loss in last 25 iteration(s): 0.3948 | Elapsed 1:40:38\n",
      "Epoch: 001/010 | Batch 5876/45709 | Average Loss in last 25 iteration(s): 0.4075 | Elapsed 1:41:01\n",
      "Epoch: 001/010 | Batch 5901/45709 | Average Loss in last 25 iteration(s): 0.4317 | Elapsed 1:41:30\n",
      "Epoch: 001/010 | Batch 5926/45709 | Average Loss in last 25 iteration(s): 0.3798 | Elapsed 1:41:57\n",
      "Epoch: 001/010 | Batch 5951/45709 | Average Loss in last 25 iteration(s): 0.3717 | Elapsed 1:42:22\n",
      "Epoch: 001/010 | Batch 5976/45709 | Average Loss in last 25 iteration(s): 0.4174 | Elapsed 1:42:47\n",
      "Epoch: 001/010 | Batch 6001/45709 | Average Loss in last 25 iteration(s): 0.3940 | Elapsed 1:43:14\n",
      "Epoch: 001/010 | Batch 6026/45709 | Average Loss in last 25 iteration(s): 0.3521 | Elapsed 1:43:37\n",
      "Epoch: 001/010 | Batch 6051/45709 | Average Loss in last 25 iteration(s): 0.3759 | Elapsed 1:44:01\n",
      "Epoch: 001/010 | Batch 6076/45709 | Average Loss in last 25 iteration(s): 0.4115 | Elapsed 1:44:30\n",
      "Epoch: 001/010 | Batch 6101/45709 | Average Loss in last 25 iteration(s): 0.4055 | Elapsed 1:44:56\n",
      "Epoch: 001/010 | Batch 6126/45709 | Average Loss in last 25 iteration(s): 0.4397 | Elapsed 1:45:23\n",
      "Epoch: 001/010 | Batch 6151/45709 | Average Loss in last 25 iteration(s): 0.3830 | Elapsed 1:45:49\n",
      "Epoch: 001/010 | Batch 6176/45709 | Average Loss in last 25 iteration(s): 0.3998 | Elapsed 1:46:13\n",
      "Epoch: 001/010 | Batch 6201/45709 | Average Loss in last 25 iteration(s): 0.3760 | Elapsed 1:46:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 6226/45709 | Average Loss in last 25 iteration(s): 0.3738 | Elapsed 1:47:06\n",
      "Epoch: 001/010 | Batch 6251/45709 | Average Loss in last 25 iteration(s): 0.4278 | Elapsed 1:47:32\n",
      "Epoch: 001/010 | Batch 6276/45709 | Average Loss in last 25 iteration(s): 0.3936 | Elapsed 1:48:00\n",
      "Epoch: 001/010 | Batch 6301/45709 | Average Loss in last 25 iteration(s): 0.4023 | Elapsed 1:48:25\n",
      "Epoch: 001/010 | Batch 6326/45709 | Average Loss in last 25 iteration(s): 0.3347 | Elapsed 1:48:50\n",
      "Epoch: 001/010 | Batch 6351/45709 | Average Loss in last 25 iteration(s): 0.3689 | Elapsed 1:49:13\n",
      "Epoch: 001/010 | Batch 6376/45709 | Average Loss in last 25 iteration(s): 0.3909 | Elapsed 1:49:42\n",
      "Epoch: 001/010 | Batch 6401/45709 | Average Loss in last 25 iteration(s): 0.4338 | Elapsed 1:50:09\n",
      "Epoch: 001/010 | Batch 6426/45709 | Average Loss in last 25 iteration(s): 0.3315 | Elapsed 1:50:35\n",
      "Epoch: 001/010 | Batch 6451/45709 | Average Loss in last 25 iteration(s): 0.3833 | Elapsed 1:51:02\n",
      "Epoch: 001/010 | Batch 6476/45709 | Average Loss in last 25 iteration(s): 0.3729 | Elapsed 1:51:27\n",
      "Epoch: 001/010 | Batch 6501/45709 | Average Loss in last 25 iteration(s): 0.3957 | Elapsed 1:51:51\n",
      "Epoch: 001/010 | Batch 6526/45709 | Average Loss in last 25 iteration(s): 0.3821 | Elapsed 1:52:20\n",
      "Epoch: 001/010 | Batch 6551/45709 | Average Loss in last 25 iteration(s): 0.3960 | Elapsed 1:52:47\n",
      "Epoch: 001/010 | Batch 6576/45709 | Average Loss in last 25 iteration(s): 0.3838 | Elapsed 1:53:13\n",
      "Epoch: 001/010 | Batch 6601/45709 | Average Loss in last 25 iteration(s): 0.3881 | Elapsed 1:53:40\n",
      "Epoch: 001/010 | Batch 6626/45709 | Average Loss in last 25 iteration(s): 0.3938 | Elapsed 1:54:05\n",
      "Epoch: 001/010 | Batch 6651/45709 | Average Loss in last 25 iteration(s): 0.4023 | Elapsed 1:54:29\n",
      "Epoch: 001/010 | Batch 6676/45709 | Average Loss in last 25 iteration(s): 0.3263 | Elapsed 1:54:56\n",
      "Epoch: 001/010 | Batch 6701/45709 | Average Loss in last 25 iteration(s): 0.3803 | Elapsed 1:55:23\n",
      "Epoch: 001/010 | Batch 6726/45709 | Average Loss in last 25 iteration(s): 0.4055 | Elapsed 1:55:51\n",
      "Epoch: 001/010 | Batch 6751/45709 | Average Loss in last 25 iteration(s): 0.3305 | Elapsed 1:56:16\n",
      "Epoch: 001/010 | Batch 6776/45709 | Average Loss in last 25 iteration(s): 0.3984 | Elapsed 1:56:40\n",
      "Epoch: 001/010 | Batch 6801/45709 | Average Loss in last 25 iteration(s): 0.3739 | Elapsed 1:57:03\n",
      "Epoch: 001/010 | Batch 6826/45709 | Average Loss in last 25 iteration(s): 0.3668 | Elapsed 1:57:32\n",
      "Epoch: 001/010 | Batch 6851/45709 | Average Loss in last 25 iteration(s): 0.3934 | Elapsed 1:57:59\n",
      "Epoch: 001/010 | Batch 6876/45709 | Average Loss in last 25 iteration(s): 0.3496 | Elapsed 1:58:25\n",
      "Epoch: 001/010 | Batch 6901/45709 | Average Loss in last 25 iteration(s): 0.3659 | Elapsed 1:58:51\n",
      "Epoch: 001/010 | Batch 6926/45709 | Average Loss in last 25 iteration(s): 0.3983 | Elapsed 1:59:16\n",
      "Epoch: 001/010 | Batch 6951/45709 | Average Loss in last 25 iteration(s): 0.4312 | Elapsed 1:59:40\n",
      "Epoch: 001/010 | Batch 6976/45709 | Average Loss in last 25 iteration(s): 0.3418 | Elapsed 2:00:03\n",
      "Epoch: 001/010 | Batch 7001/45709 | Average Loss in last 25 iteration(s): 0.4164 | Elapsed 2:00:29\n",
      "Epoch: 001/010 | Batch 7026/45709 | Average Loss in last 25 iteration(s): 0.3547 | Elapsed 2:00:56\n",
      "Epoch: 001/010 | Batch 7051/45709 | Average Loss in last 25 iteration(s): 0.3326 | Elapsed 2:01:23\n",
      "Epoch: 001/010 | Batch 7076/45709 | Average Loss in last 25 iteration(s): 0.3203 | Elapsed 2:01:49\n",
      "Epoch: 001/010 | Batch 7101/45709 | Average Loss in last 25 iteration(s): 0.3618 | Elapsed 2:02:16\n",
      "Epoch: 001/010 | Batch 7126/45709 | Average Loss in last 25 iteration(s): 0.3959 | Elapsed 2:02:38\n",
      "Epoch: 001/010 | Batch 7151/45709 | Average Loss in last 25 iteration(s): 0.3930 | Elapsed 2:03:02\n",
      "Epoch: 001/010 | Batch 7176/45709 | Average Loss in last 25 iteration(s): 0.3689 | Elapsed 2:03:30\n",
      "Epoch: 001/010 | Batch 7201/45709 | Average Loss in last 25 iteration(s): 0.3811 | Elapsed 2:03:57\n",
      "Epoch: 001/010 | Batch 7226/45709 | Average Loss in last 25 iteration(s): 0.3135 | Elapsed 2:04:24\n",
      "Epoch: 001/010 | Batch 7251/45709 | Average Loss in last 25 iteration(s): 0.3927 | Elapsed 2:04:50\n",
      "Epoch: 001/010 | Batch 7276/45709 | Average Loss in last 25 iteration(s): 0.3615 | Elapsed 2:05:15\n",
      "Epoch: 001/010 | Batch 7301/45709 | Average Loss in last 25 iteration(s): 0.3374 | Elapsed 2:05:38\n",
      "Epoch: 001/010 | Batch 7326/45709 | Average Loss in last 25 iteration(s): 0.3875 | Elapsed 2:06:03\n",
      "Epoch: 001/010 | Batch 7351/45709 | Average Loss in last 25 iteration(s): 0.3414 | Elapsed 2:06:31\n",
      "Epoch: 001/010 | Batch 7376/45709 | Average Loss in last 25 iteration(s): 0.3468 | Elapsed 2:06:58\n",
      "Epoch: 001/010 | Batch 7401/45709 | Average Loss in last 25 iteration(s): 0.3416 | Elapsed 2:07:24\n",
      "Epoch: 001/010 | Batch 7426/45709 | Average Loss in last 25 iteration(s): 0.3677 | Elapsed 2:07:51\n",
      "Epoch: 001/010 | Batch 7451/45709 | Average Loss in last 25 iteration(s): 0.3781 | Elapsed 2:08:14\n",
      "Epoch: 001/010 | Batch 7476/45709 | Average Loss in last 25 iteration(s): 0.3651 | Elapsed 2:08:40\n",
      "Epoch: 001/010 | Batch 7501/45709 | Average Loss in last 25 iteration(s): 0.3282 | Elapsed 2:09:08\n",
      "Epoch: 001/010 | Batch 7526/45709 | Average Loss in last 25 iteration(s): 0.3661 | Elapsed 2:09:34\n",
      "Epoch: 001/010 | Batch 7551/45709 | Average Loss in last 25 iteration(s): 0.3694 | Elapsed 2:10:02\n",
      "Epoch: 001/010 | Batch 7576/45709 | Average Loss in last 25 iteration(s): 0.3367 | Elapsed 2:10:27\n",
      "Epoch: 001/010 | Batch 7601/45709 | Average Loss in last 25 iteration(s): 0.3043 | Elapsed 2:10:51\n",
      "Epoch: 001/010 | Batch 7626/45709 | Average Loss in last 25 iteration(s): 0.4001 | Elapsed 2:11:18\n",
      "Epoch: 001/010 | Batch 7651/45709 | Average Loss in last 25 iteration(s): 0.4199 | Elapsed 2:11:46\n",
      "Epoch: 001/010 | Batch 7676/45709 | Average Loss in last 25 iteration(s): 0.3951 | Elapsed 2:12:11\n",
      "Epoch: 001/010 | Batch 7701/45709 | Average Loss in last 25 iteration(s): 0.3409 | Elapsed 2:12:37\n",
      "Epoch: 001/010 | Batch 7726/45709 | Average Loss in last 25 iteration(s): 0.3253 | Elapsed 2:13:04\n",
      "Epoch: 001/010 | Batch 7751/45709 | Average Loss in last 25 iteration(s): 0.3718 | Elapsed 2:13:28\n",
      "Epoch: 001/010 | Batch 7776/45709 | Average Loss in last 25 iteration(s): 0.3969 | Elapsed 2:13:54\n",
      "Epoch: 001/010 | Batch 7801/45709 | Average Loss in last 25 iteration(s): 0.3442 | Elapsed 2:14:22\n",
      "Epoch: 001/010 | Batch 7826/45709 | Average Loss in last 25 iteration(s): 0.3592 | Elapsed 2:14:50\n",
      "Epoch: 001/010 | Batch 7851/45709 | Average Loss in last 25 iteration(s): 0.3640 | Elapsed 2:15:14\n",
      "Epoch: 001/010 | Batch 7876/45709 | Average Loss in last 25 iteration(s): 0.3817 | Elapsed 2:15:40\n",
      "Epoch: 001/010 | Batch 7901/45709 | Average Loss in last 25 iteration(s): 0.3467 | Elapsed 2:16:05\n",
      "Epoch: 001/010 | Batch 7926/45709 | Average Loss in last 25 iteration(s): 0.3807 | Elapsed 2:16:28\n",
      "Epoch: 001/010 | Batch 7951/45709 | Average Loss in last 25 iteration(s): 0.3897 | Elapsed 2:16:56\n",
      "Epoch: 001/010 | Batch 7976/45709 | Average Loss in last 25 iteration(s): 0.3901 | Elapsed 2:17:24\n",
      "Epoch: 001/010 | Batch 8001/45709 | Average Loss in last 25 iteration(s): 0.3721 | Elapsed 2:17:50\n",
      "Epoch: 001/010 | Batch 8026/45709 | Average Loss in last 25 iteration(s): 0.3778 | Elapsed 2:18:16\n",
      "Epoch: 001/010 | Batch 8051/45709 | Average Loss in last 25 iteration(s): 0.4277 | Elapsed 2:18:40\n",
      "Epoch: 001/010 | Batch 8076/45709 | Average Loss in last 25 iteration(s): 0.3188 | Elapsed 2:19:03\n",
      "Epoch: 001/010 | Batch 8101/45709 | Average Loss in last 25 iteration(s): 0.3985 | Elapsed 2:19:32\n",
      "Epoch: 001/010 | Batch 8126/45709 | Average Loss in last 25 iteration(s): 0.3714 | Elapsed 2:19:59\n",
      "Epoch: 001/010 | Batch 8151/45709 | Average Loss in last 25 iteration(s): 0.3955 | Elapsed 2:20:25\n",
      "Epoch: 001/010 | Batch 8176/45709 | Average Loss in last 25 iteration(s): 0.3743 | Elapsed 2:20:53\n",
      "Epoch: 001/010 | Batch 8201/45709 | Average Loss in last 25 iteration(s): 0.3740 | Elapsed 2:21:19\n",
      "Epoch: 001/010 | Batch 8226/45709 | Average Loss in last 25 iteration(s): 0.3952 | Elapsed 2:21:43\n",
      "Epoch: 001/010 | Batch 8251/45709 | Average Loss in last 25 iteration(s): 0.3600 | Elapsed 2:22:10\n",
      "Epoch: 001/010 | Batch 8276/45709 | Average Loss in last 25 iteration(s): 0.3661 | Elapsed 2:22:38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 8301/45709 | Average Loss in last 25 iteration(s): 0.3578 | Elapsed 2:23:04\n",
      "Epoch: 001/010 | Batch 8326/45709 | Average Loss in last 25 iteration(s): 0.3059 | Elapsed 2:23:32\n",
      "Epoch: 001/010 | Batch 8351/45709 | Average Loss in last 25 iteration(s): 0.3736 | Elapsed 2:23:57\n",
      "Epoch: 001/010 | Batch 8376/45709 | Average Loss in last 25 iteration(s): 0.3586 | Elapsed 2:24:21\n",
      "Epoch: 001/010 | Batch 8401/45709 | Average Loss in last 25 iteration(s): 0.3865 | Elapsed 2:24:50\n",
      "Epoch: 001/010 | Batch 8426/45709 | Average Loss in last 25 iteration(s): 0.3553 | Elapsed 2:25:16\n",
      "Epoch: 001/010 | Batch 8451/45709 | Average Loss in last 25 iteration(s): 0.3268 | Elapsed 2:25:42\n",
      "Epoch: 001/010 | Batch 8476/45709 | Average Loss in last 25 iteration(s): 0.3819 | Elapsed 2:26:09\n",
      "Epoch: 001/010 | Batch 8501/45709 | Average Loss in last 25 iteration(s): 0.3648 | Elapsed 2:26:33\n",
      "Epoch: 001/010 | Batch 8526/45709 | Average Loss in last 25 iteration(s): 0.3608 | Elapsed 2:26:56\n",
      "Epoch: 001/010 | Batch 8551/45709 | Average Loss in last 25 iteration(s): 0.3291 | Elapsed 2:27:23\n",
      "Epoch: 001/010 | Batch 8576/45709 | Average Loss in last 25 iteration(s): 0.3866 | Elapsed 2:27:51\n",
      "Epoch: 001/010 | Batch 8601/45709 | Average Loss in last 25 iteration(s): 0.3955 | Elapsed 2:28:19\n",
      "Epoch: 001/010 | Batch 8626/45709 | Average Loss in last 25 iteration(s): 0.3316 | Elapsed 2:28:45\n",
      "Epoch: 001/010 | Batch 8651/45709 | Average Loss in last 25 iteration(s): 0.3623 | Elapsed 2:29:11\n",
      "Epoch: 001/010 | Batch 8676/45709 | Average Loss in last 25 iteration(s): 0.3871 | Elapsed 2:29:33\n",
      "Epoch: 001/010 | Batch 8701/45709 | Average Loss in last 25 iteration(s): 0.3182 | Elapsed 2:30:03\n",
      "Epoch: 001/010 | Batch 8726/45709 | Average Loss in last 25 iteration(s): 0.3424 | Elapsed 2:30:30\n",
      "Epoch: 001/010 | Batch 8751/45709 | Average Loss in last 25 iteration(s): 0.2851 | Elapsed 2:30:57\n",
      "Epoch: 001/010 | Batch 8776/45709 | Average Loss in last 25 iteration(s): 0.3281 | Elapsed 2:31:21\n",
      "Epoch: 001/010 | Batch 8801/45709 | Average Loss in last 25 iteration(s): 0.3440 | Elapsed 2:31:47\n",
      "Epoch: 001/010 | Batch 8826/45709 | Average Loss in last 25 iteration(s): 0.3469 | Elapsed 2:32:13\n",
      "Epoch: 001/010 | Batch 8851/45709 | Average Loss in last 25 iteration(s): 0.3450 | Elapsed 2:32:41\n",
      "Epoch: 001/010 | Batch 8876/45709 | Average Loss in last 25 iteration(s): 0.3773 | Elapsed 2:33:07\n",
      "Epoch: 001/010 | Batch 8901/45709 | Average Loss in last 25 iteration(s): 0.3553 | Elapsed 2:33:34\n",
      "Epoch: 001/010 | Batch 8926/45709 | Average Loss in last 25 iteration(s): 0.3592 | Elapsed 2:34:01\n",
      "Epoch: 001/010 | Batch 8951/45709 | Average Loss in last 25 iteration(s): 0.3112 | Elapsed 2:34:28\n",
      "Epoch: 001/010 | Batch 8976/45709 | Average Loss in last 25 iteration(s): 0.3195 | Elapsed 2:34:50\n",
      "Epoch: 001/010 | Batch 9001/45709 | Average Loss in last 25 iteration(s): 0.3651 | Elapsed 2:35:17\n",
      "Epoch: 001/010 | Batch 9026/45709 | Average Loss in last 25 iteration(s): 0.3291 | Elapsed 2:35:46\n",
      "Epoch: 001/010 | Batch 9051/45709 | Average Loss in last 25 iteration(s): 0.3464 | Elapsed 2:36:10\n",
      "Epoch: 001/010 | Batch 9076/45709 | Average Loss in last 25 iteration(s): 0.3061 | Elapsed 2:36:36\n",
      "Epoch: 001/010 | Batch 9101/45709 | Average Loss in last 25 iteration(s): 0.3114 | Elapsed 2:37:04\n",
      "Epoch: 001/010 | Batch 9126/45709 | Average Loss in last 25 iteration(s): 0.3993 | Elapsed 2:37:27\n",
      "Epoch: 001/010 | Batch 9151/45709 | Average Loss in last 25 iteration(s): 0.2935 | Elapsed 2:37:55\n",
      "Epoch: 001/010 | Batch 9176/45709 | Average Loss in last 25 iteration(s): 0.3668 | Elapsed 2:38:22\n",
      "Epoch: 001/010 | Batch 9201/45709 | Average Loss in last 25 iteration(s): 0.3714 | Elapsed 2:38:49\n",
      "Epoch: 001/010 | Batch 9226/45709 | Average Loss in last 25 iteration(s): 0.3568 | Elapsed 2:39:16\n",
      "Epoch: 001/010 | Batch 9251/45709 | Average Loss in last 25 iteration(s): 0.3398 | Elapsed 2:39:42\n",
      "Epoch: 001/010 | Batch 9276/45709 | Average Loss in last 25 iteration(s): 0.3056 | Elapsed 2:40:06\n",
      "Epoch: 001/010 | Batch 9301/45709 | Average Loss in last 25 iteration(s): 0.3507 | Elapsed 2:40:32\n",
      "Epoch: 001/010 | Batch 9326/45709 | Average Loss in last 25 iteration(s): 0.3537 | Elapsed 2:41:00\n",
      "Epoch: 001/010 | Batch 9351/45709 | Average Loss in last 25 iteration(s): 0.3778 | Elapsed 2:41:26\n",
      "Epoch: 001/010 | Batch 9376/45709 | Average Loss in last 25 iteration(s): 0.3712 | Elapsed 2:41:53\n",
      "Epoch: 001/010 | Batch 9401/45709 | Average Loss in last 25 iteration(s): 0.3461 | Elapsed 2:42:19\n",
      "Epoch: 001/010 | Batch 9426/45709 | Average Loss in last 25 iteration(s): 0.3190 | Elapsed 2:42:43\n",
      "Epoch: 001/010 | Batch 9451/45709 | Average Loss in last 25 iteration(s): 0.3091 | Elapsed 2:43:06\n",
      "Epoch: 001/010 | Batch 9476/45709 | Average Loss in last 25 iteration(s): 0.3588 | Elapsed 2:43:35\n",
      "Epoch: 001/010 | Batch 9501/45709 | Average Loss in last 25 iteration(s): 0.3419 | Elapsed 2:44:02\n",
      "Epoch: 001/010 | Batch 9526/45709 | Average Loss in last 25 iteration(s): 0.3208 | Elapsed 2:44:28\n",
      "Epoch: 001/010 | Batch 9551/45709 | Average Loss in last 25 iteration(s): 0.3698 | Elapsed 2:44:54\n",
      "Epoch: 001/010 | Batch 9576/45709 | Average Loss in last 25 iteration(s): 0.3483 | Elapsed 2:45:19\n",
      "Epoch: 001/010 | Batch 9601/45709 | Average Loss in last 25 iteration(s): 0.3211 | Elapsed 2:45:41\n",
      "Epoch: 001/010 | Batch 9626/45709 | Average Loss in last 25 iteration(s): 0.2698 | Elapsed 2:46:12\n",
      "Epoch: 001/010 | Batch 9651/45709 | Average Loss in last 25 iteration(s): 0.3507 | Elapsed 2:46:40\n",
      "Epoch: 001/010 | Batch 9676/45709 | Average Loss in last 25 iteration(s): 0.3800 | Elapsed 2:47:05\n",
      "Epoch: 001/010 | Batch 9701/45709 | Average Loss in last 25 iteration(s): 0.3741 | Elapsed 2:47:31\n",
      "Epoch: 001/010 | Batch 9726/45709 | Average Loss in last 25 iteration(s): 0.3329 | Elapsed 2:47:55\n",
      "Epoch: 001/010 | Batch 9751/45709 | Average Loss in last 25 iteration(s): 0.2695 | Elapsed 2:48:18\n",
      "Epoch: 001/010 | Batch 9776/45709 | Average Loss in last 25 iteration(s): 0.3425 | Elapsed 2:48:49\n",
      "Epoch: 001/010 | Batch 9801/45709 | Average Loss in last 25 iteration(s): 0.2779 | Elapsed 2:49:11\n",
      "Epoch: 001/010 | Batch 9826/45709 | Average Loss in last 25 iteration(s): 0.3156 | Elapsed 2:49:37\n",
      "Epoch: 001/010 | Batch 9851/45709 | Average Loss in last 25 iteration(s): 0.3356 | Elapsed 2:50:05\n",
      "Epoch: 001/010 | Batch 9876/45709 | Average Loss in last 25 iteration(s): 0.3458 | Elapsed 2:50:31\n",
      "Epoch: 001/010 | Batch 9901/45709 | Average Loss in last 25 iteration(s): 0.3398 | Elapsed 2:50:55\n",
      "Epoch: 001/010 | Batch 9926/45709 | Average Loss in last 25 iteration(s): 0.3187 | Elapsed 2:51:19\n",
      "Epoch: 001/010 | Batch 9951/45709 | Average Loss in last 25 iteration(s): 0.3491 | Elapsed 2:51:50\n",
      "Epoch: 001/010 | Batch 9976/45709 | Average Loss in last 25 iteration(s): 0.3439 | Elapsed 2:52:14\n",
      "Epoch: 001/010 | Batch 10001/45709 | Average Loss in last 25 iteration(s): 0.3176 | Elapsed 2:52:38\n",
      "Epoch: 001/010 | Batch 10026/45709 | Average Loss in last 25 iteration(s): 0.3001 | Elapsed 2:53:05\n",
      "Epoch: 001/010 | Batch 10051/45709 | Average Loss in last 25 iteration(s): 0.3053 | Elapsed 2:53:33\n",
      "Epoch: 001/010 | Batch 10076/45709 | Average Loss in last 25 iteration(s): 0.3591 | Elapsed 2:53:55\n",
      "Epoch: 001/010 | Batch 10101/45709 | Average Loss in last 25 iteration(s): 0.3422 | Elapsed 2:54:23\n",
      "Epoch: 001/010 | Batch 10126/45709 | Average Loss in last 25 iteration(s): 0.3611 | Elapsed 2:54:50\n",
      "Epoch: 001/010 | Batch 10151/45709 | Average Loss in last 25 iteration(s): 0.3597 | Elapsed 2:55:16\n",
      "Epoch: 001/010 | Batch 10176/45709 | Average Loss in last 25 iteration(s): 0.3595 | Elapsed 2:55:41\n",
      "Epoch: 001/010 | Batch 10201/45709 | Average Loss in last 25 iteration(s): 0.3364 | Elapsed 2:56:09\n",
      "Epoch: 001/010 | Batch 10226/45709 | Average Loss in last 25 iteration(s): 0.3378 | Elapsed 2:56:32\n",
      "Epoch: 001/010 | Batch 10251/45709 | Average Loss in last 25 iteration(s): 0.3016 | Elapsed 2:56:54\n",
      "Epoch: 001/010 | Batch 10276/45709 | Average Loss in last 25 iteration(s): 0.3354 | Elapsed 2:57:23\n",
      "Epoch: 001/010 | Batch 10301/45709 | Average Loss in last 25 iteration(s): 0.3325 | Elapsed 2:57:51\n",
      "Epoch: 001/010 | Batch 10326/45709 | Average Loss in last 25 iteration(s): 0.3305 | Elapsed 2:58:17\n",
      "Epoch: 001/010 | Batch 10351/45709 | Average Loss in last 25 iteration(s): 0.3281 | Elapsed 2:58:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 10376/45709 | Average Loss in last 25 iteration(s): 0.3225 | Elapsed 2:59:05\n",
      "Epoch: 001/010 | Batch 10401/45709 | Average Loss in last 25 iteration(s): 0.3169 | Elapsed 2:59:29\n",
      "Epoch: 001/010 | Batch 10426/45709 | Average Loss in last 25 iteration(s): 0.3184 | Elapsed 2:59:57\n",
      "Epoch: 001/010 | Batch 10451/45709 | Average Loss in last 25 iteration(s): 0.3421 | Elapsed 3:00:24\n",
      "Epoch: 001/010 | Batch 10476/45709 | Average Loss in last 25 iteration(s): 0.3503 | Elapsed 3:00:50\n",
      "Epoch: 001/010 | Batch 10501/45709 | Average Loss in last 25 iteration(s): 0.3148 | Elapsed 3:01:17\n",
      "Epoch: 001/010 | Batch 10526/45709 | Average Loss in last 25 iteration(s): 0.3587 | Elapsed 3:01:40\n",
      "Epoch: 001/010 | Batch 10551/45709 | Average Loss in last 25 iteration(s): 0.3171 | Elapsed 3:02:06\n",
      "Epoch: 001/010 | Batch 10576/45709 | Average Loss in last 25 iteration(s): 0.2832 | Elapsed 3:02:29\n",
      "Epoch: 001/010 | Batch 10601/45709 | Average Loss in last 25 iteration(s): 0.2740 | Elapsed 3:02:58\n",
      "Epoch: 001/010 | Batch 10626/45709 | Average Loss in last 25 iteration(s): 0.3172 | Elapsed 3:03:25\n",
      "Epoch: 001/010 | Batch 10651/45709 | Average Loss in last 25 iteration(s): 0.3652 | Elapsed 3:03:50\n",
      "Epoch: 001/010 | Batch 10676/45709 | Average Loss in last 25 iteration(s): 0.3787 | Elapsed 3:04:16\n",
      "Epoch: 001/010 | Batch 10701/45709 | Average Loss in last 25 iteration(s): 0.2855 | Elapsed 3:04:40\n",
      "Epoch: 001/010 | Batch 10726/45709 | Average Loss in last 25 iteration(s): 0.3033 | Elapsed 3:05:07\n",
      "Epoch: 001/010 | Batch 10751/45709 | Average Loss in last 25 iteration(s): 0.2771 | Elapsed 3:05:30\n",
      "Epoch: 001/010 | Batch 10776/45709 | Average Loss in last 25 iteration(s): 0.3095 | Elapsed 3:05:58\n",
      "Epoch: 001/010 | Batch 10801/45709 | Average Loss in last 25 iteration(s): 0.3330 | Elapsed 3:06:25\n",
      "Epoch: 001/010 | Batch 10826/45709 | Average Loss in last 25 iteration(s): 0.3823 | Elapsed 3:06:54\n",
      "Epoch: 001/010 | Batch 10851/45709 | Average Loss in last 25 iteration(s): 0.2647 | Elapsed 3:07:19\n",
      "Epoch: 001/010 | Batch 10876/45709 | Average Loss in last 25 iteration(s): 0.3158 | Elapsed 3:07:44\n",
      "Epoch: 001/010 | Batch 10901/45709 | Average Loss in last 25 iteration(s): 0.3083 | Elapsed 3:08:07\n",
      "Epoch: 001/010 | Batch 10926/45709 | Average Loss in last 25 iteration(s): 0.3910 | Elapsed 3:08:35\n",
      "Epoch: 001/010 | Batch 10951/45709 | Average Loss in last 25 iteration(s): 0.3947 | Elapsed 3:09:03\n",
      "Epoch: 001/010 | Batch 10976/45709 | Average Loss in last 25 iteration(s): 0.3706 | Elapsed 3:09:28\n",
      "Epoch: 001/010 | Batch 11001/45709 | Average Loss in last 25 iteration(s): 0.3466 | Elapsed 3:09:54\n",
      "Epoch: 001/010 | Batch 11026/45709 | Average Loss in last 25 iteration(s): 0.2919 | Elapsed 3:10:21\n",
      "Epoch: 001/010 | Batch 11051/45709 | Average Loss in last 25 iteration(s): 0.3020 | Elapsed 3:10:43\n",
      "Epoch: 001/010 | Batch 11076/45709 | Average Loss in last 25 iteration(s): 0.3238 | Elapsed 3:11:08\n",
      "Epoch: 001/010 | Batch 11101/45709 | Average Loss in last 25 iteration(s): 0.3122 | Elapsed 3:11:37\n",
      "Epoch: 001/010 | Batch 11126/45709 | Average Loss in last 25 iteration(s): 0.3393 | Elapsed 3:12:03\n",
      "Epoch: 001/010 | Batch 11151/45709 | Average Loss in last 25 iteration(s): 0.3092 | Elapsed 3:12:29\n",
      "Epoch: 001/010 | Batch 11176/45709 | Average Loss in last 25 iteration(s): 0.3320 | Elapsed 3:12:57\n",
      "Epoch: 001/010 | Batch 11201/45709 | Average Loss in last 25 iteration(s): 0.2866 | Elapsed 3:13:23\n",
      "Epoch: 001/010 | Batch 11226/45709 | Average Loss in last 25 iteration(s): 0.2709 | Elapsed 3:13:45\n",
      "Epoch: 001/010 | Batch 11251/45709 | Average Loss in last 25 iteration(s): 0.3530 | Elapsed 3:14:11\n",
      "Epoch: 001/010 | Batch 11276/45709 | Average Loss in last 25 iteration(s): 0.3551 | Elapsed 3:14:40\n",
      "Epoch: 001/010 | Batch 11301/45709 | Average Loss in last 25 iteration(s): 0.3391 | Elapsed 3:15:04\n",
      "Epoch: 001/010 | Batch 11326/45709 | Average Loss in last 25 iteration(s): 0.3167 | Elapsed 3:15:31\n",
      "Epoch: 001/010 | Batch 11351/45709 | Average Loss in last 25 iteration(s): 0.2502 | Elapsed 3:15:57\n",
      "Epoch: 001/010 | Batch 11376/45709 | Average Loss in last 25 iteration(s): 0.3931 | Elapsed 3:16:20\n",
      "Epoch: 001/010 | Batch 11401/45709 | Average Loss in last 25 iteration(s): 0.3410 | Elapsed 3:16:47\n",
      "Epoch: 001/010 | Batch 11426/45709 | Average Loss in last 25 iteration(s): 0.3302 | Elapsed 3:17:13\n",
      "Epoch: 001/010 | Batch 11451/45709 | Average Loss in last 25 iteration(s): 0.2637 | Elapsed 3:17:39\n",
      "Epoch: 001/010 | Batch 11476/45709 | Average Loss in last 25 iteration(s): 0.2497 | Elapsed 3:18:05\n",
      "Epoch: 001/010 | Batch 11501/45709 | Average Loss in last 25 iteration(s): 0.3608 | Elapsed 3:18:30\n",
      "Epoch: 001/010 | Batch 11526/45709 | Average Loss in last 25 iteration(s): 0.2849 | Elapsed 3:18:55\n",
      "Epoch: 001/010 | Batch 11551/45709 | Average Loss in last 25 iteration(s): 0.3212 | Elapsed 3:19:17\n",
      "Epoch: 001/010 | Batch 11576/45709 | Average Loss in last 25 iteration(s): 0.3502 | Elapsed 3:19:45\n",
      "Epoch: 001/010 | Batch 11601/45709 | Average Loss in last 25 iteration(s): 0.3006 | Elapsed 3:20:13\n",
      "Epoch: 001/010 | Batch 11626/45709 | Average Loss in last 25 iteration(s): 0.4090 | Elapsed 3:20:38\n",
      "Epoch: 001/010 | Batch 11651/45709 | Average Loss in last 25 iteration(s): 0.3230 | Elapsed 3:21:04\n",
      "Epoch: 001/010 | Batch 11676/45709 | Average Loss in last 25 iteration(s): 0.3334 | Elapsed 3:21:33\n",
      "Epoch: 001/010 | Batch 11701/45709 | Average Loss in last 25 iteration(s): 0.2663 | Elapsed 3:21:54\n",
      "Epoch: 001/010 | Batch 11726/45709 | Average Loss in last 25 iteration(s): 0.3269 | Elapsed 3:22:18\n",
      "Epoch: 001/010 | Batch 11751/45709 | Average Loss in last 25 iteration(s): 0.3217 | Elapsed 3:22:47\n",
      "Epoch: 001/010 | Batch 11776/45709 | Average Loss in last 25 iteration(s): 0.3258 | Elapsed 3:23:14\n",
      "Epoch: 001/010 | Batch 11801/45709 | Average Loss in last 25 iteration(s): 0.3288 | Elapsed 3:23:39\n",
      "Epoch: 001/010 | Batch 11826/45709 | Average Loss in last 25 iteration(s): 0.3543 | Elapsed 3:24:04\n",
      "Epoch: 001/010 | Batch 11851/45709 | Average Loss in last 25 iteration(s): 0.3288 | Elapsed 3:24:31\n",
      "Epoch: 001/010 | Batch 11876/45709 | Average Loss in last 25 iteration(s): 0.3032 | Elapsed 3:24:54\n",
      "Epoch: 001/010 | Batch 11901/45709 | Average Loss in last 25 iteration(s): 0.3369 | Elapsed 3:25:21\n",
      "Epoch: 001/010 | Batch 11926/45709 | Average Loss in last 25 iteration(s): 0.3144 | Elapsed 3:25:48\n",
      "Epoch: 001/010 | Batch 11951/45709 | Average Loss in last 25 iteration(s): 0.3348 | Elapsed 3:26:14\n",
      "Epoch: 001/010 | Batch 11976/45709 | Average Loss in last 25 iteration(s): 0.3185 | Elapsed 3:26:39\n",
      "Epoch: 001/010 | Batch 12001/45709 | Average Loss in last 25 iteration(s): 0.3344 | Elapsed 3:27:05\n",
      "Epoch: 001/010 | Batch 12026/45709 | Average Loss in last 25 iteration(s): 0.3490 | Elapsed 3:27:28\n",
      "Epoch: 001/010 | Batch 12051/45709 | Average Loss in last 25 iteration(s): 0.3179 | Elapsed 3:27:53\n",
      "Epoch: 001/010 | Batch 12076/45709 | Average Loss in last 25 iteration(s): 0.3131 | Elapsed 3:28:21\n",
      "Epoch: 001/010 | Batch 12101/45709 | Average Loss in last 25 iteration(s): 0.3545 | Elapsed 3:28:47\n",
      "Epoch: 001/010 | Batch 12126/45709 | Average Loss in last 25 iteration(s): 0.2988 | Elapsed 3:29:14\n",
      "Epoch: 001/010 | Batch 12151/45709 | Average Loss in last 25 iteration(s): 0.3335 | Elapsed 3:29:41\n",
      "Epoch: 001/010 | Batch 12176/45709 | Average Loss in last 25 iteration(s): 0.3047 | Elapsed 3:30:05\n",
      "Epoch: 001/010 | Batch 12201/45709 | Average Loss in last 25 iteration(s): 0.2974 | Elapsed 3:30:30\n",
      "Epoch: 001/010 | Batch 12226/45709 | Average Loss in last 25 iteration(s): 0.3262 | Elapsed 3:30:59\n",
      "Epoch: 001/010 | Batch 12251/45709 | Average Loss in last 25 iteration(s): 0.3512 | Elapsed 3:31:25\n",
      "Epoch: 001/010 | Batch 12276/45709 | Average Loss in last 25 iteration(s): 0.3367 | Elapsed 3:31:52\n",
      "Epoch: 001/010 | Batch 12301/45709 | Average Loss in last 25 iteration(s): 0.2490 | Elapsed 3:32:17\n",
      "Epoch: 001/010 | Batch 12326/45709 | Average Loss in last 25 iteration(s): 0.3037 | Elapsed 3:32:42\n",
      "Epoch: 001/010 | Batch 12351/45709 | Average Loss in last 25 iteration(s): 0.3094 | Elapsed 3:33:05\n",
      "Epoch: 001/010 | Batch 12376/45709 | Average Loss in last 25 iteration(s): 0.3334 | Elapsed 3:33:30\n",
      "Epoch: 001/010 | Batch 12401/45709 | Average Loss in last 25 iteration(s): 0.3890 | Elapsed 3:33:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 12426/45709 | Average Loss in last 25 iteration(s): 0.3537 | Elapsed 3:34:24\n",
      "Epoch: 001/010 | Batch 12451/45709 | Average Loss in last 25 iteration(s): 0.3261 | Elapsed 3:34:50\n",
      "Epoch: 001/010 | Batch 12476/45709 | Average Loss in last 25 iteration(s): 0.2642 | Elapsed 3:35:17\n",
      "Epoch: 001/010 | Batch 12501/45709 | Average Loss in last 25 iteration(s): 0.3112 | Elapsed 3:35:41\n",
      "Epoch: 001/010 | Batch 12526/45709 | Average Loss in last 25 iteration(s): 0.2937 | Elapsed 3:36:07\n",
      "Epoch: 001/010 | Batch 12551/45709 | Average Loss in last 25 iteration(s): 0.3314 | Elapsed 3:36:35\n",
      "Epoch: 001/010 | Batch 12576/45709 | Average Loss in last 25 iteration(s): 0.2693 | Elapsed 3:37:02\n",
      "Epoch: 001/010 | Batch 12601/45709 | Average Loss in last 25 iteration(s): 0.2535 | Elapsed 3:37:27\n",
      "Epoch: 001/010 | Batch 12626/45709 | Average Loss in last 25 iteration(s): 0.2963 | Elapsed 3:37:54\n",
      "Epoch: 001/010 | Batch 12651/45709 | Average Loss in last 25 iteration(s): 0.3382 | Elapsed 3:38:19\n",
      "Epoch: 001/010 | Batch 12676/45709 | Average Loss in last 25 iteration(s): 0.3007 | Elapsed 3:38:42\n",
      "Epoch: 001/010 | Batch 12701/45709 | Average Loss in last 25 iteration(s): 0.3584 | Elapsed 3:39:09\n",
      "Epoch: 001/010 | Batch 12726/45709 | Average Loss in last 25 iteration(s): 0.3119 | Elapsed 3:39:36\n",
      "Epoch: 001/010 | Batch 12751/45709 | Average Loss in last 25 iteration(s): 0.2943 | Elapsed 3:40:03\n",
      "Epoch: 001/010 | Batch 12776/45709 | Average Loss in last 25 iteration(s): 0.2789 | Elapsed 3:40:29\n",
      "Epoch: 001/010 | Batch 12801/45709 | Average Loss in last 25 iteration(s): 0.3127 | Elapsed 3:40:54\n",
      "Epoch: 001/010 | Batch 12826/45709 | Average Loss in last 25 iteration(s): 0.2891 | Elapsed 3:41:18\n",
      "Epoch: 001/010 | Batch 12851/45709 | Average Loss in last 25 iteration(s): 0.2883 | Elapsed 3:41:43\n",
      "Epoch: 001/010 | Batch 12876/45709 | Average Loss in last 25 iteration(s): 0.3350 | Elapsed 3:42:10\n",
      "Epoch: 001/010 | Batch 12901/45709 | Average Loss in last 25 iteration(s): 0.3084 | Elapsed 3:42:37\n",
      "Epoch: 001/010 | Batch 12926/45709 | Average Loss in last 25 iteration(s): 0.3167 | Elapsed 3:43:04\n",
      "Epoch: 001/010 | Batch 12951/45709 | Average Loss in last 25 iteration(s): 0.2938 | Elapsed 3:43:31\n",
      "Epoch: 001/010 | Batch 12976/45709 | Average Loss in last 25 iteration(s): 0.2716 | Elapsed 3:43:55\n",
      "Epoch: 001/010 | Batch 13001/45709 | Average Loss in last 25 iteration(s): 0.3530 | Elapsed 3:44:18\n",
      "Epoch: 001/010 | Batch 13026/45709 | Average Loss in last 25 iteration(s): 0.2998 | Elapsed 3:44:45\n",
      "Epoch: 001/010 | Batch 13051/45709 | Average Loss in last 25 iteration(s): 0.2622 | Elapsed 3:45:13\n",
      "Epoch: 001/010 | Batch 13076/45709 | Average Loss in last 25 iteration(s): 0.3466 | Elapsed 3:45:40\n",
      "Epoch: 001/010 | Batch 13101/45709 | Average Loss in last 25 iteration(s): 0.2974 | Elapsed 3:46:06\n",
      "Epoch: 001/010 | Batch 13126/45709 | Average Loss in last 25 iteration(s): 0.3119 | Elapsed 3:46:32\n",
      "Epoch: 001/010 | Batch 13151/45709 | Average Loss in last 25 iteration(s): 0.3315 | Elapsed 3:46:54\n",
      "Epoch: 001/010 | Batch 13176/45709 | Average Loss in last 25 iteration(s): 0.3125 | Elapsed 3:47:20\n",
      "Epoch: 001/010 | Batch 13201/45709 | Average Loss in last 25 iteration(s): 0.2978 | Elapsed 3:47:47\n",
      "Epoch: 001/010 | Batch 13226/45709 | Average Loss in last 25 iteration(s): 0.2413 | Elapsed 3:48:13\n",
      "Epoch: 001/010 | Batch 13251/45709 | Average Loss in last 25 iteration(s): 0.2869 | Elapsed 3:48:40\n",
      "Epoch: 001/010 | Batch 13276/45709 | Average Loss in last 25 iteration(s): 0.2891 | Elapsed 3:49:06\n",
      "Epoch: 001/010 | Batch 13301/45709 | Average Loss in last 25 iteration(s): 0.2795 | Elapsed 3:49:29\n",
      "Epoch: 001/010 | Batch 13326/45709 | Average Loss in last 25 iteration(s): 0.2853 | Elapsed 3:49:52\n",
      "Epoch: 001/010 | Batch 13351/45709 | Average Loss in last 25 iteration(s): 0.2721 | Elapsed 3:50:20\n",
      "Epoch: 001/010 | Batch 13376/45709 | Average Loss in last 25 iteration(s): 0.3202 | Elapsed 3:50:47\n",
      "Epoch: 001/010 | Batch 13401/45709 | Average Loss in last 25 iteration(s): 0.3167 | Elapsed 3:51:13\n",
      "Epoch: 001/010 | Batch 13426/45709 | Average Loss in last 25 iteration(s): 0.2422 | Elapsed 3:51:41\n",
      "Epoch: 001/010 | Batch 13451/45709 | Average Loss in last 25 iteration(s): 0.2349 | Elapsed 3:52:07\n",
      "Epoch: 001/010 | Batch 13476/45709 | Average Loss in last 25 iteration(s): 0.3293 | Elapsed 3:52:31\n",
      "Epoch: 001/010 | Batch 13501/45709 | Average Loss in last 25 iteration(s): 0.2940 | Elapsed 3:52:58\n",
      "Epoch: 001/010 | Batch 13526/45709 | Average Loss in last 25 iteration(s): 0.2933 | Elapsed 3:53:25\n",
      "Epoch: 001/010 | Batch 13551/45709 | Average Loss in last 25 iteration(s): 0.2710 | Elapsed 3:53:51\n",
      "Epoch: 001/010 | Batch 13576/45709 | Average Loss in last 25 iteration(s): 0.2576 | Elapsed 3:54:20\n",
      "Epoch: 001/010 | Batch 13601/45709 | Average Loss in last 25 iteration(s): 0.2790 | Elapsed 3:54:45\n",
      "Epoch: 001/010 | Batch 13626/45709 | Average Loss in last 25 iteration(s): 0.3296 | Elapsed 3:55:08\n",
      "Epoch: 001/010 | Batch 13651/45709 | Average Loss in last 25 iteration(s): 0.2951 | Elapsed 3:55:36\n",
      "Epoch: 001/010 | Batch 13676/45709 | Average Loss in last 25 iteration(s): 0.3241 | Elapsed 3:56:03\n",
      "Epoch: 001/010 | Batch 13701/45709 | Average Loss in last 25 iteration(s): 0.3660 | Elapsed 3:56:28\n",
      "Epoch: 001/010 | Batch 13726/45709 | Average Loss in last 25 iteration(s): 0.3069 | Elapsed 3:56:56\n",
      "Epoch: 001/010 | Batch 13751/45709 | Average Loss in last 25 iteration(s): 0.3446 | Elapsed 3:57:22\n",
      "Epoch: 001/010 | Batch 13776/45709 | Average Loss in last 25 iteration(s): 0.2867 | Elapsed 3:57:44\n",
      "Epoch: 001/010 | Batch 13801/45709 | Average Loss in last 25 iteration(s): 0.3267 | Elapsed 3:58:11\n",
      "Epoch: 001/010 | Batch 13826/45709 | Average Loss in last 25 iteration(s): 0.2897 | Elapsed 3:58:39\n",
      "Epoch: 001/010 | Batch 13851/45709 | Average Loss in last 25 iteration(s): 0.3608 | Elapsed 3:59:06\n",
      "Epoch: 001/010 | Batch 13876/45709 | Average Loss in last 25 iteration(s): 0.2554 | Elapsed 3:59:32\n",
      "Epoch: 001/010 | Batch 13901/45709 | Average Loss in last 25 iteration(s): 0.2662 | Elapsed 3:59:57\n",
      "Epoch: 001/010 | Batch 13926/45709 | Average Loss in last 25 iteration(s): 0.2936 | Elapsed 4:00:21\n",
      "Epoch: 001/010 | Batch 13951/45709 | Average Loss in last 25 iteration(s): 0.3031 | Elapsed 4:00:46\n",
      "Epoch: 001/010 | Batch 13976/45709 | Average Loss in last 25 iteration(s): 0.3145 | Elapsed 4:01:14\n",
      "Epoch: 001/010 | Batch 14001/45709 | Average Loss in last 25 iteration(s): 0.2729 | Elapsed 4:01:40\n",
      "Epoch: 001/010 | Batch 14026/45709 | Average Loss in last 25 iteration(s): 0.3494 | Elapsed 4:02:07\n",
      "Epoch: 001/010 | Batch 14051/45709 | Average Loss in last 25 iteration(s): 0.2917 | Elapsed 4:02:32\n",
      "Epoch: 001/010 | Batch 14076/45709 | Average Loss in last 25 iteration(s): 0.2640 | Elapsed 4:02:57\n",
      "Epoch: 001/010 | Batch 14101/45709 | Average Loss in last 25 iteration(s): 0.3026 | Elapsed 4:03:21\n",
      "Epoch: 001/010 | Batch 14126/45709 | Average Loss in last 25 iteration(s): 0.2740 | Elapsed 4:03:51\n",
      "Epoch: 001/010 | Batch 14151/45709 | Average Loss in last 25 iteration(s): 0.2718 | Elapsed 4:04:16\n",
      "Epoch: 001/010 | Batch 14176/45709 | Average Loss in last 25 iteration(s): 0.2947 | Elapsed 4:04:42\n",
      "Epoch: 001/010 | Batch 14201/45709 | Average Loss in last 25 iteration(s): 0.3217 | Elapsed 4:05:08\n",
      "Epoch: 001/010 | Batch 14226/45709 | Average Loss in last 25 iteration(s): 0.2430 | Elapsed 4:05:33\n",
      "Epoch: 001/010 | Batch 14251/45709 | Average Loss in last 25 iteration(s): 0.3070 | Elapsed 4:05:56\n",
      "Epoch: 001/010 | Batch 14276/45709 | Average Loss in last 25 iteration(s): 0.3311 | Elapsed 4:06:25\n",
      "Epoch: 001/010 | Batch 14301/45709 | Average Loss in last 25 iteration(s): 0.3381 | Elapsed 4:06:52\n",
      "Epoch: 001/010 | Batch 14326/45709 | Average Loss in last 25 iteration(s): 0.2856 | Elapsed 4:07:18\n",
      "Epoch: 001/010 | Batch 14351/45709 | Average Loss in last 25 iteration(s): 0.2453 | Elapsed 4:07:45\n",
      "Epoch: 001/010 | Batch 14376/45709 | Average Loss in last 25 iteration(s): 0.2562 | Elapsed 4:08:10\n",
      "Epoch: 001/010 | Batch 14401/45709 | Average Loss in last 25 iteration(s): 0.2858 | Elapsed 4:08:34\n",
      "Epoch: 001/010 | Batch 14426/45709 | Average Loss in last 25 iteration(s): 0.3085 | Elapsed 4:08:59\n",
      "Epoch: 001/010 | Batch 14451/45709 | Average Loss in last 25 iteration(s): 0.3221 | Elapsed 4:09:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 14476/45709 | Average Loss in last 25 iteration(s): 0.2320 | Elapsed 4:09:54\n",
      "Epoch: 001/010 | Batch 14501/45709 | Average Loss in last 25 iteration(s): 0.2508 | Elapsed 4:10:21\n",
      "Epoch: 001/010 | Batch 14526/45709 | Average Loss in last 25 iteration(s): 0.2756 | Elapsed 4:10:46\n",
      "Epoch: 001/010 | Batch 14551/45709 | Average Loss in last 25 iteration(s): 0.2625 | Elapsed 4:11:10\n",
      "Epoch: 001/010 | Batch 14576/45709 | Average Loss in last 25 iteration(s): 0.3123 | Elapsed 4:11:36\n",
      "Epoch: 001/010 | Batch 14601/45709 | Average Loss in last 25 iteration(s): 0.3045 | Elapsed 4:12:04\n",
      "Epoch: 001/010 | Batch 14626/45709 | Average Loss in last 25 iteration(s): 0.3034 | Elapsed 4:12:30\n",
      "Epoch: 001/010 | Batch 14651/45709 | Average Loss in last 25 iteration(s): 0.3010 | Elapsed 4:12:56\n",
      "Epoch: 001/010 | Batch 14676/45709 | Average Loss in last 25 iteration(s): 0.3165 | Elapsed 4:13:24\n",
      "Epoch: 001/010 | Batch 14701/45709 | Average Loss in last 25 iteration(s): 0.3040 | Elapsed 4:13:48\n",
      "Epoch: 001/010 | Batch 14726/45709 | Average Loss in last 25 iteration(s): 0.2648 | Elapsed 4:14:11\n",
      "Epoch: 001/010 | Batch 14751/45709 | Average Loss in last 25 iteration(s): 0.2429 | Elapsed 4:14:39\n",
      "Epoch: 001/010 | Batch 14776/45709 | Average Loss in last 25 iteration(s): 0.2779 | Elapsed 4:15:05\n",
      "Epoch: 001/010 | Batch 14801/45709 | Average Loss in last 25 iteration(s): 0.2599 | Elapsed 4:15:30\n",
      "Epoch: 001/010 | Batch 14826/45709 | Average Loss in last 25 iteration(s): 0.3579 | Elapsed 4:15:57\n",
      "Epoch: 001/010 | Batch 14851/45709 | Average Loss in last 25 iteration(s): 0.2363 | Elapsed 4:16:23\n",
      "Epoch: 001/010 | Batch 14876/45709 | Average Loss in last 25 iteration(s): 0.3341 | Elapsed 4:16:46\n",
      "Epoch: 001/010 | Batch 14901/45709 | Average Loss in last 25 iteration(s): 0.2721 | Elapsed 4:17:12\n",
      "Epoch: 001/010 | Batch 14926/45709 | Average Loss in last 25 iteration(s): 0.3193 | Elapsed 4:17:38\n",
      "Epoch: 001/010 | Batch 14951/45709 | Average Loss in last 25 iteration(s): 0.2642 | Elapsed 4:18:04\n",
      "Epoch: 001/010 | Batch 14976/45709 | Average Loss in last 25 iteration(s): 0.2778 | Elapsed 4:18:30\n",
      "Epoch: 001/010 | Batch 15001/45709 | Average Loss in last 25 iteration(s): 0.2832 | Elapsed 4:18:56\n",
      "Epoch: 001/010 | Batch 15026/45709 | Average Loss in last 25 iteration(s): 0.2569 | Elapsed 4:19:20\n",
      "Epoch: 001/010 | Batch 15051/45709 | Average Loss in last 25 iteration(s): 0.2846 | Elapsed 4:19:44\n",
      "Epoch: 001/010 | Batch 15076/45709 | Average Loss in last 25 iteration(s): 0.2809 | Elapsed 4:20:09\n",
      "Epoch: 001/010 | Batch 15101/45709 | Average Loss in last 25 iteration(s): 0.2397 | Elapsed 4:20:37\n",
      "Epoch: 001/010 | Batch 15126/45709 | Average Loss in last 25 iteration(s): 0.2804 | Elapsed 4:21:02\n",
      "Epoch: 001/010 | Batch 15151/45709 | Average Loss in last 25 iteration(s): 0.2961 | Elapsed 4:21:27\n",
      "Epoch: 001/010 | Batch 15176/45709 | Average Loss in last 25 iteration(s): 0.2725 | Elapsed 4:21:53\n",
      "Epoch: 001/010 | Batch 15201/45709 | Average Loss in last 25 iteration(s): 0.2955 | Elapsed 4:22:17\n",
      "Epoch: 001/010 | Batch 15226/45709 | Average Loss in last 25 iteration(s): 0.2198 | Elapsed 4:22:42\n",
      "Epoch: 001/010 | Batch 15251/45709 | Average Loss in last 25 iteration(s): 0.3176 | Elapsed 4:23:09\n",
      "Epoch: 001/010 | Batch 15276/45709 | Average Loss in last 25 iteration(s): 0.3366 | Elapsed 4:23:35\n",
      "Epoch: 001/010 | Batch 15301/45709 | Average Loss in last 25 iteration(s): 0.3339 | Elapsed 4:24:01\n",
      "Epoch: 001/010 | Batch 15326/45709 | Average Loss in last 25 iteration(s): 0.3125 | Elapsed 4:24:26\n",
      "Epoch: 001/010 | Batch 15351/45709 | Average Loss in last 25 iteration(s): 0.2663 | Elapsed 4:24:52\n",
      "Epoch: 001/010 | Batch 15376/45709 | Average Loss in last 25 iteration(s): 0.3063 | Elapsed 4:25:15\n",
      "Epoch: 001/010 | Batch 15401/45709 | Average Loss in last 25 iteration(s): 0.2498 | Elapsed 4:25:42\n",
      "Epoch: 001/010 | Batch 15426/45709 | Average Loss in last 25 iteration(s): 0.2342 | Elapsed 4:26:08\n",
      "Epoch: 001/010 | Batch 15451/45709 | Average Loss in last 25 iteration(s): 0.3621 | Elapsed 4:26:34\n",
      "Epoch: 001/010 | Batch 15476/45709 | Average Loss in last 25 iteration(s): 0.2771 | Elapsed 4:26:59\n",
      "Epoch: 001/010 | Batch 15501/45709 | Average Loss in last 25 iteration(s): 0.2842 | Elapsed 4:27:27\n",
      "Epoch: 001/010 | Batch 15526/45709 | Average Loss in last 25 iteration(s): 0.2689 | Elapsed 4:27:51\n",
      "Epoch: 001/010 | Batch 15551/45709 | Average Loss in last 25 iteration(s): 0.2649 | Elapsed 4:28:13\n",
      "Epoch: 001/010 | Batch 15576/45709 | Average Loss in last 25 iteration(s): 0.2437 | Elapsed 4:28:41\n",
      "Epoch: 001/010 | Batch 15601/45709 | Average Loss in last 25 iteration(s): 0.2675 | Elapsed 4:29:10\n",
      "Epoch: 001/010 | Batch 15626/45709 | Average Loss in last 25 iteration(s): 0.3299 | Elapsed 4:29:34\n",
      "Epoch: 001/010 | Batch 15651/45709 | Average Loss in last 25 iteration(s): 0.3100 | Elapsed 4:30:00\n",
      "Epoch: 001/010 | Batch 15676/45709 | Average Loss in last 25 iteration(s): 0.3053 | Elapsed 4:30:26\n",
      "Epoch: 001/010 | Batch 15701/45709 | Average Loss in last 25 iteration(s): 0.2557 | Elapsed 4:30:48\n",
      "Epoch: 001/010 | Batch 15726/45709 | Average Loss in last 25 iteration(s): 0.3484 | Elapsed 4:31:15\n",
      "Epoch: 001/010 | Batch 15751/45709 | Average Loss in last 25 iteration(s): 0.3026 | Elapsed 4:31:42\n",
      "Epoch: 001/010 | Batch 15776/45709 | Average Loss in last 25 iteration(s): 0.2730 | Elapsed 4:32:09\n",
      "Epoch: 001/010 | Batch 15801/45709 | Average Loss in last 25 iteration(s): 0.3142 | Elapsed 4:32:35\n",
      "Epoch: 001/010 | Batch 15826/45709 | Average Loss in last 25 iteration(s): 0.2529 | Elapsed 4:33:01\n",
      "Epoch: 001/010 | Batch 15851/45709 | Average Loss in last 25 iteration(s): 0.2842 | Elapsed 4:33:26\n",
      "Epoch: 001/010 | Batch 15876/45709 | Average Loss in last 25 iteration(s): 0.2813 | Elapsed 4:33:49\n",
      "Epoch: 001/010 | Batch 15901/45709 | Average Loss in last 25 iteration(s): 0.3146 | Elapsed 4:34:18\n",
      "Epoch: 001/010 | Batch 15926/45709 | Average Loss in last 25 iteration(s): 0.2419 | Elapsed 4:34:45\n",
      "Epoch: 001/010 | Batch 15951/45709 | Average Loss in last 25 iteration(s): 0.2974 | Elapsed 4:35:10\n",
      "Epoch: 001/010 | Batch 15976/45709 | Average Loss in last 25 iteration(s): 0.2904 | Elapsed 4:35:36\n",
      "Epoch: 001/010 | Batch 16001/45709 | Average Loss in last 25 iteration(s): 0.2952 | Elapsed 4:36:01\n",
      "Epoch: 001/010 | Batch 16026/45709 | Average Loss in last 25 iteration(s): 0.3046 | Elapsed 4:36:24\n",
      "Epoch: 001/010 | Batch 16051/45709 | Average Loss in last 25 iteration(s): 0.2640 | Elapsed 4:36:51\n",
      "Epoch: 001/010 | Batch 16076/45709 | Average Loss in last 25 iteration(s): 0.3248 | Elapsed 4:37:20\n",
      "Epoch: 001/010 | Batch 16101/45709 | Average Loss in last 25 iteration(s): 0.2456 | Elapsed 4:37:46\n",
      "Epoch: 001/010 | Batch 16126/45709 | Average Loss in last 25 iteration(s): 0.2696 | Elapsed 4:38:12\n",
      "Epoch: 001/010 | Batch 16151/45709 | Average Loss in last 25 iteration(s): 0.2830 | Elapsed 4:38:37\n",
      "Epoch: 001/010 | Batch 16176/45709 | Average Loss in last 25 iteration(s): 0.2759 | Elapsed 4:39:01\n",
      "Epoch: 001/010 | Batch 16201/45709 | Average Loss in last 25 iteration(s): 0.2712 | Elapsed 4:39:28\n",
      "Epoch: 001/010 | Batch 16226/45709 | Average Loss in last 25 iteration(s): 0.2821 | Elapsed 4:39:55\n",
      "Epoch: 001/010 | Batch 16251/45709 | Average Loss in last 25 iteration(s): 0.3092 | Elapsed 4:40:21\n",
      "Epoch: 001/010 | Batch 16276/45709 | Average Loss in last 25 iteration(s): 0.2499 | Elapsed 4:40:48\n",
      "Epoch: 001/010 | Batch 16301/45709 | Average Loss in last 25 iteration(s): 0.2733 | Elapsed 4:41:14\n",
      "Epoch: 001/010 | Batch 16326/45709 | Average Loss in last 25 iteration(s): 0.2796 | Elapsed 4:41:39\n",
      "Epoch: 001/010 | Batch 16351/45709 | Average Loss in last 25 iteration(s): 0.2319 | Elapsed 4:42:02\n",
      "Epoch: 001/010 | Batch 16376/45709 | Average Loss in last 25 iteration(s): 0.2563 | Elapsed 4:42:30\n",
      "Epoch: 001/010 | Batch 16401/45709 | Average Loss in last 25 iteration(s): 0.2576 | Elapsed 4:42:56\n",
      "Epoch: 001/010 | Batch 16426/45709 | Average Loss in last 25 iteration(s): 0.2728 | Elapsed 4:43:21\n",
      "Epoch: 001/010 | Batch 16451/45709 | Average Loss in last 25 iteration(s): 0.3169 | Elapsed 4:43:49\n",
      "Epoch: 001/010 | Batch 16476/45709 | Average Loss in last 25 iteration(s): 0.2951 | Elapsed 4:44:14\n",
      "Epoch: 001/010 | Batch 16501/45709 | Average Loss in last 25 iteration(s): 0.2590 | Elapsed 4:44:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 16526/45709 | Average Loss in last 25 iteration(s): 0.2818 | Elapsed 4:45:01\n",
      "Epoch: 001/010 | Batch 16551/45709 | Average Loss in last 25 iteration(s): 0.2554 | Elapsed 4:45:28\n",
      "Epoch: 001/010 | Batch 16576/45709 | Average Loss in last 25 iteration(s): 0.2891 | Elapsed 4:45:55\n",
      "Epoch: 001/010 | Batch 16601/45709 | Average Loss in last 25 iteration(s): 0.2535 | Elapsed 4:46:23\n",
      "Epoch: 001/010 | Batch 16626/45709 | Average Loss in last 25 iteration(s): 0.3083 | Elapsed 4:46:48\n",
      "Epoch: 001/010 | Batch 16651/45709 | Average Loss in last 25 iteration(s): 0.2918 | Elapsed 4:47:10\n",
      "Epoch: 001/010 | Batch 16676/45709 | Average Loss in last 25 iteration(s): 0.2395 | Elapsed 4:47:36\n",
      "Epoch: 001/010 | Batch 16701/45709 | Average Loss in last 25 iteration(s): 0.2913 | Elapsed 4:48:03\n",
      "Epoch: 001/010 | Batch 16726/45709 | Average Loss in last 25 iteration(s): 0.2773 | Elapsed 4:48:32\n",
      "Epoch: 001/010 | Batch 16751/45709 | Average Loss in last 25 iteration(s): 0.3022 | Elapsed 4:49:02\n",
      "Epoch: 001/010 | Batch 16776/45709 | Average Loss in last 25 iteration(s): 0.2016 | Elapsed 4:49:25\n",
      "Epoch: 001/010 | Batch 16801/45709 | Average Loss in last 25 iteration(s): 0.2241 | Elapsed 4:49:47\n",
      "Epoch: 001/010 | Batch 16826/45709 | Average Loss in last 25 iteration(s): 0.2861 | Elapsed 4:50:20\n",
      "Epoch: 001/010 | Batch 16851/45709 | Average Loss in last 25 iteration(s): 0.3041 | Elapsed 4:50:46\n",
      "Epoch: 001/010 | Batch 16876/45709 | Average Loss in last 25 iteration(s): 0.2979 | Elapsed 4:51:12\n",
      "Epoch: 001/010 | Batch 16901/45709 | Average Loss in last 25 iteration(s): 0.2780 | Elapsed 4:51:42\n",
      "Epoch: 001/010 | Batch 16926/45709 | Average Loss in last 25 iteration(s): 0.2937 | Elapsed 4:52:06\n",
      "Epoch: 001/010 | Batch 16951/45709 | Average Loss in last 25 iteration(s): 0.2609 | Elapsed 4:52:35\n",
      "Epoch: 001/010 | Batch 16976/45709 | Average Loss in last 25 iteration(s): 0.2948 | Elapsed 4:52:58\n",
      "Epoch: 001/010 | Batch 17001/45709 | Average Loss in last 25 iteration(s): 0.2539 | Elapsed 4:53:26\n",
      "Epoch: 001/010 | Batch 17026/45709 | Average Loss in last 25 iteration(s): 0.3043 | Elapsed 4:53:54\n",
      "Epoch: 001/010 | Batch 17051/45709 | Average Loss in last 25 iteration(s): 0.3177 | Elapsed 4:54:21\n",
      "Epoch: 001/010 | Batch 17076/45709 | Average Loss in last 25 iteration(s): 0.2446 | Elapsed 4:54:44\n",
      "Epoch: 001/010 | Batch 17101/45709 | Average Loss in last 25 iteration(s): 0.2938 | Elapsed 4:55:13\n",
      "Epoch: 001/010 | Batch 17126/45709 | Average Loss in last 25 iteration(s): 0.2836 | Elapsed 4:55:43\n",
      "Epoch: 001/010 | Batch 17151/45709 | Average Loss in last 25 iteration(s): 0.2332 | Elapsed 4:56:05\n",
      "Epoch: 001/010 | Batch 17176/45709 | Average Loss in last 25 iteration(s): 0.2183 | Elapsed 4:56:26\n",
      "Epoch: 001/010 | Batch 17201/45709 | Average Loss in last 25 iteration(s): 0.2811 | Elapsed 4:56:52\n",
      "Epoch: 001/010 | Batch 17226/45709 | Average Loss in last 25 iteration(s): 0.2552 | Elapsed 4:57:18\n",
      "Epoch: 001/010 | Batch 17251/45709 | Average Loss in last 25 iteration(s): 0.2886 | Elapsed 4:57:44\n",
      "Epoch: 001/010 | Batch 17276/45709 | Average Loss in last 25 iteration(s): 0.3217 | Elapsed 4:58:11\n",
      "Epoch: 001/010 | Batch 17301/45709 | Average Loss in last 25 iteration(s): 0.2721 | Elapsed 4:58:40\n",
      "Epoch: 001/010 | Batch 17326/45709 | Average Loss in last 25 iteration(s): 0.2848 | Elapsed 4:59:03\n",
      "Epoch: 001/010 | Batch 17351/45709 | Average Loss in last 25 iteration(s): 0.2773 | Elapsed 4:59:33\n",
      "Epoch: 001/010 | Batch 17376/45709 | Average Loss in last 25 iteration(s): 0.2708 | Elapsed 5:00:00\n",
      "Epoch: 001/010 | Batch 17401/45709 | Average Loss in last 25 iteration(s): 0.2844 | Elapsed 5:00:23\n",
      "Epoch: 001/010 | Batch 17426/45709 | Average Loss in last 25 iteration(s): 0.3133 | Elapsed 5:00:53\n",
      "Epoch: 001/010 | Batch 17451/45709 | Average Loss in last 25 iteration(s): 0.2349 | Elapsed 5:01:20\n",
      "Epoch: 001/010 | Batch 17476/45709 | Average Loss in last 25 iteration(s): 0.2466 | Elapsed 5:01:48\n",
      "Epoch: 001/010 | Batch 17501/45709 | Average Loss in last 25 iteration(s): 0.3097 | Elapsed 5:02:13\n",
      "Epoch: 001/010 | Batch 17526/45709 | Average Loss in last 25 iteration(s): 0.2728 | Elapsed 5:02:39\n",
      "Epoch: 001/010 | Batch 17551/45709 | Average Loss in last 25 iteration(s): 0.2729 | Elapsed 5:03:02\n",
      "Epoch: 001/010 | Batch 17576/45709 | Average Loss in last 25 iteration(s): 0.2540 | Elapsed 5:03:29\n",
      "Epoch: 001/010 | Batch 17601/45709 | Average Loss in last 25 iteration(s): 0.2454 | Elapsed 5:03:57\n",
      "Epoch: 001/010 | Batch 17626/45709 | Average Loss in last 25 iteration(s): 0.2452 | Elapsed 5:04:24\n",
      "Epoch: 001/010 | Batch 17651/45709 | Average Loss in last 25 iteration(s): 0.2832 | Elapsed 5:04:51\n",
      "Epoch: 001/010 | Batch 17676/45709 | Average Loss in last 25 iteration(s): 0.2351 | Elapsed 5:05:18\n",
      "Epoch: 001/010 | Batch 17701/45709 | Average Loss in last 25 iteration(s): 0.2234 | Elapsed 5:05:39\n",
      "Epoch: 001/010 | Batch 17726/45709 | Average Loss in last 25 iteration(s): 0.2171 | Elapsed 5:06:00\n",
      "Epoch: 001/010 | Batch 17751/45709 | Average Loss in last 25 iteration(s): 0.3222 | Elapsed 5:06:31\n",
      "Epoch: 001/010 | Batch 17776/45709 | Average Loss in last 25 iteration(s): 0.2377 | Elapsed 5:06:58\n",
      "Epoch: 001/010 | Batch 17801/45709 | Average Loss in last 25 iteration(s): 0.2454 | Elapsed 5:07:24\n",
      "Epoch: 001/010 | Batch 17826/45709 | Average Loss in last 25 iteration(s): 0.2893 | Elapsed 5:07:50\n",
      "Epoch: 001/010 | Batch 17851/45709 | Average Loss in last 25 iteration(s): 0.2623 | Elapsed 5:08:17\n",
      "Epoch: 001/010 | Batch 17876/45709 | Average Loss in last 25 iteration(s): 0.2983 | Elapsed 5:08:39\n",
      "Epoch: 001/010 | Batch 17901/45709 | Average Loss in last 25 iteration(s): 0.2802 | Elapsed 5:09:07\n",
      "Epoch: 001/010 | Batch 17926/45709 | Average Loss in last 25 iteration(s): 0.2821 | Elapsed 5:09:33\n",
      "Epoch: 001/010 | Batch 17951/45709 | Average Loss in last 25 iteration(s): 0.2713 | Elapsed 5:10:00\n",
      "Epoch: 001/010 | Batch 17976/45709 | Average Loss in last 25 iteration(s): 0.2265 | Elapsed 5:10:25\n",
      "Epoch: 001/010 | Batch 18001/45709 | Average Loss in last 25 iteration(s): 0.2623 | Elapsed 5:10:51\n",
      "Epoch: 001/010 | Batch 18026/45709 | Average Loss in last 25 iteration(s): 0.2449 | Elapsed 5:11:16\n",
      "Epoch: 001/010 | Batch 18051/45709 | Average Loss in last 25 iteration(s): 0.2437 | Elapsed 5:11:47\n",
      "Epoch: 001/010 | Batch 18076/45709 | Average Loss in last 25 iteration(s): 0.2259 | Elapsed 5:12:10\n",
      "Epoch: 001/010 | Batch 18101/45709 | Average Loss in last 25 iteration(s): 0.2303 | Elapsed 5:12:37\n",
      "Epoch: 001/010 | Batch 18126/45709 | Average Loss in last 25 iteration(s): 0.3013 | Elapsed 5:13:03\n",
      "Epoch: 001/010 | Batch 18151/45709 | Average Loss in last 25 iteration(s): 0.2662 | Elapsed 5:13:32\n",
      "Epoch: 001/010 | Batch 18176/45709 | Average Loss in last 25 iteration(s): 0.2284 | Elapsed 5:13:56\n",
      "Epoch: 001/010 | Batch 18201/45709 | Average Loss in last 25 iteration(s): 0.2201 | Elapsed 5:14:24\n",
      "Epoch: 001/010 | Batch 18226/45709 | Average Loss in last 25 iteration(s): 0.2712 | Elapsed 5:14:51\n",
      "Epoch: 001/010 | Batch 18251/45709 | Average Loss in last 25 iteration(s): 0.3018 | Elapsed 5:15:12\n",
      "Epoch: 001/010 | Batch 18276/45709 | Average Loss in last 25 iteration(s): 0.2408 | Elapsed 5:15:40\n",
      "Epoch: 001/010 | Batch 18301/45709 | Average Loss in last 25 iteration(s): 0.2679 | Elapsed 5:16:08\n",
      "Epoch: 001/010 | Batch 18326/45709 | Average Loss in last 25 iteration(s): 0.2831 | Elapsed 5:16:34\n",
      "Epoch: 001/010 | Batch 18351/45709 | Average Loss in last 25 iteration(s): 0.2999 | Elapsed 5:16:57\n",
      "Epoch: 001/010 | Batch 18376/45709 | Average Loss in last 25 iteration(s): 0.2656 | Elapsed 5:17:22\n",
      "Epoch: 001/010 | Batch 18401/45709 | Average Loss in last 25 iteration(s): 0.2980 | Elapsed 5:17:51\n",
      "Epoch: 001/010 | Batch 18426/45709 | Average Loss in last 25 iteration(s): 0.2748 | Elapsed 5:18:16\n",
      "Epoch: 001/010 | Batch 18451/45709 | Average Loss in last 25 iteration(s): 0.2130 | Elapsed 5:18:42\n",
      "Epoch: 001/010 | Batch 18476/45709 | Average Loss in last 25 iteration(s): 0.2256 | Elapsed 5:19:06\n",
      "Epoch: 001/010 | Batch 18501/45709 | Average Loss in last 25 iteration(s): 0.2487 | Elapsed 5:19:35\n",
      "Epoch: 001/010 | Batch 18526/45709 | Average Loss in last 25 iteration(s): 0.2561 | Elapsed 5:19:56\n",
      "Epoch: 001/010 | Batch 18551/45709 | Average Loss in last 25 iteration(s): 0.2360 | Elapsed 5:20:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 18576/45709 | Average Loss in last 25 iteration(s): 0.2636 | Elapsed 5:20:53\n",
      "Epoch: 001/010 | Batch 18601/45709 | Average Loss in last 25 iteration(s): 0.2450 | Elapsed 5:21:21\n",
      "Epoch: 001/010 | Batch 18626/45709 | Average Loss in last 25 iteration(s): 0.2442 | Elapsed 5:21:45\n",
      "Epoch: 001/010 | Batch 18651/45709 | Average Loss in last 25 iteration(s): 0.2520 | Elapsed 5:22:05\n",
      "Epoch: 001/010 | Batch 18676/45709 | Average Loss in last 25 iteration(s): 0.2563 | Elapsed 5:22:28\n",
      "Epoch: 001/010 | Batch 18701/45709 | Average Loss in last 25 iteration(s): 0.2447 | Elapsed 5:22:58\n",
      "Epoch: 001/010 | Batch 18726/45709 | Average Loss in last 25 iteration(s): 0.2589 | Elapsed 5:23:25\n",
      "Epoch: 001/010 | Batch 18751/45709 | Average Loss in last 25 iteration(s): 0.3043 | Elapsed 5:23:52\n",
      "Epoch: 001/010 | Batch 18776/45709 | Average Loss in last 25 iteration(s): 0.2601 | Elapsed 5:24:18\n",
      "Epoch: 001/010 | Batch 18801/45709 | Average Loss in last 25 iteration(s): 0.2661 | Elapsed 5:24:43\n",
      "Epoch: 001/010 | Batch 18826/45709 | Average Loss in last 25 iteration(s): 0.2871 | Elapsed 5:25:03\n",
      "Epoch: 001/010 | Batch 18851/45709 | Average Loss in last 25 iteration(s): 0.2729 | Elapsed 5:25:30\n",
      "Epoch: 001/010 | Batch 18876/45709 | Average Loss in last 25 iteration(s): 0.2832 | Elapsed 5:25:58\n",
      "Epoch: 001/010 | Batch 18901/45709 | Average Loss in last 25 iteration(s): 0.2343 | Elapsed 5:26:23\n",
      "Epoch: 001/010 | Batch 18926/45709 | Average Loss in last 25 iteration(s): 0.3023 | Elapsed 5:26:51\n",
      "Epoch: 001/010 | Batch 18951/45709 | Average Loss in last 25 iteration(s): 0.1829 | Elapsed 5:27:20\n",
      "Epoch: 001/010 | Batch 18976/45709 | Average Loss in last 25 iteration(s): 0.2559 | Elapsed 5:27:41\n",
      "Epoch: 001/010 | Batch 19001/45709 | Average Loss in last 25 iteration(s): 0.2166 | Elapsed 5:28:04\n",
      "Epoch: 001/010 | Batch 19026/45709 | Average Loss in last 25 iteration(s): 0.2885 | Elapsed 5:28:33\n",
      "Epoch: 001/010 | Batch 19051/45709 | Average Loss in last 25 iteration(s): 0.2587 | Elapsed 5:29:01\n",
      "Epoch: 001/010 | Batch 19076/45709 | Average Loss in last 25 iteration(s): 0.2355 | Elapsed 5:29:21\n",
      "Epoch: 001/010 | Batch 19101/45709 | Average Loss in last 25 iteration(s): 0.2717 | Elapsed 5:29:48\n",
      "Epoch: 001/010 | Batch 19126/45709 | Average Loss in last 25 iteration(s): 0.2565 | Elapsed 5:30:15\n",
      "Epoch: 001/010 | Batch 19151/45709 | Average Loss in last 25 iteration(s): 0.3008 | Elapsed 5:30:39\n",
      "Epoch: 001/010 | Batch 19176/45709 | Average Loss in last 25 iteration(s): 0.2559 | Elapsed 5:31:00\n",
      "Epoch: 001/010 | Batch 19201/45709 | Average Loss in last 25 iteration(s): 0.2498 | Elapsed 5:31:29\n",
      "Epoch: 001/010 | Batch 19226/45709 | Average Loss in last 25 iteration(s): 0.2835 | Elapsed 5:31:59\n",
      "Epoch: 001/010 | Batch 19251/45709 | Average Loss in last 25 iteration(s): 0.2429 | Elapsed 5:32:19\n",
      "Epoch: 001/010 | Batch 19276/45709 | Average Loss in last 25 iteration(s): 0.2468 | Elapsed 5:32:44\n",
      "Epoch: 001/010 | Batch 19301/45709 | Average Loss in last 25 iteration(s): 0.2658 | Elapsed 5:33:17\n",
      "Epoch: 001/010 | Batch 19326/45709 | Average Loss in last 25 iteration(s): 0.2570 | Elapsed 5:33:38\n",
      "Epoch: 001/010 | Batch 19351/45709 | Average Loss in last 25 iteration(s): 0.2239 | Elapsed 5:34:00\n",
      "Epoch: 001/010 | Batch 19376/45709 | Average Loss in last 25 iteration(s): 0.2190 | Elapsed 5:34:27\n",
      "Epoch: 001/010 | Batch 19401/45709 | Average Loss in last 25 iteration(s): 0.2841 | Elapsed 5:34:58\n",
      "Epoch: 001/010 | Batch 19426/45709 | Average Loss in last 25 iteration(s): 0.2289 | Elapsed 5:35:19\n",
      "Epoch: 001/010 | Batch 19451/45709 | Average Loss in last 25 iteration(s): 0.2719 | Elapsed 5:35:44\n",
      "Epoch: 001/010 | Batch 19476/45709 | Average Loss in last 25 iteration(s): 0.2173 | Elapsed 5:36:16\n",
      "Epoch: 001/010 | Batch 19501/45709 | Average Loss in last 25 iteration(s): 0.1676 | Elapsed 5:36:39\n",
      "Epoch: 001/010 | Batch 19526/45709 | Average Loss in last 25 iteration(s): 0.2457 | Elapsed 5:36:59\n",
      "Epoch: 001/010 | Batch 19551/45709 | Average Loss in last 25 iteration(s): 0.2492 | Elapsed 5:37:26\n",
      "Epoch: 001/010 | Batch 19576/45709 | Average Loss in last 25 iteration(s): 0.2001 | Elapsed 5:37:56\n",
      "Epoch: 001/010 | Batch 19601/45709 | Average Loss in last 25 iteration(s): 0.2610 | Elapsed 5:38:17\n",
      "Epoch: 001/010 | Batch 19626/45709 | Average Loss in last 25 iteration(s): 0.2276 | Elapsed 5:38:45\n",
      "Epoch: 001/010 | Batch 19651/45709 | Average Loss in last 25 iteration(s): 0.2319 | Elapsed 5:39:17\n",
      "Epoch: 001/010 | Batch 19676/45709 | Average Loss in last 25 iteration(s): 0.2760 | Elapsed 5:39:37\n",
      "Epoch: 001/010 | Batch 19701/45709 | Average Loss in last 25 iteration(s): 0.2401 | Elapsed 5:39:58\n",
      "Epoch: 001/010 | Batch 19726/45709 | Average Loss in last 25 iteration(s): 0.2352 | Elapsed 5:40:28\n",
      "Epoch: 001/010 | Batch 19751/45709 | Average Loss in last 25 iteration(s): 0.3077 | Elapsed 5:40:56\n",
      "Epoch: 001/010 | Batch 19776/45709 | Average Loss in last 25 iteration(s): 0.3004 | Elapsed 5:41:17\n",
      "Epoch: 001/010 | Batch 19801/45709 | Average Loss in last 25 iteration(s): 0.2931 | Elapsed 5:41:49\n",
      "Epoch: 001/010 | Batch 19826/45709 | Average Loss in last 25 iteration(s): 0.2337 | Elapsed 5:42:15\n",
      "Epoch: 001/010 | Batch 19851/45709 | Average Loss in last 25 iteration(s): 0.2321 | Elapsed 5:42:36\n",
      "Epoch: 001/010 | Batch 19876/45709 | Average Loss in last 25 iteration(s): 0.2826 | Elapsed 5:42:57\n",
      "Epoch: 001/010 | Batch 19901/45709 | Average Loss in last 25 iteration(s): 0.2902 | Elapsed 5:43:17\n",
      "Epoch: 001/010 | Batch 19926/45709 | Average Loss in last 25 iteration(s): 0.2061 | Elapsed 5:43:47\n",
      "Epoch: 001/010 | Batch 19951/45709 | Average Loss in last 25 iteration(s): 0.2248 | Elapsed 5:44:17\n",
      "Epoch: 001/010 | Batch 19976/45709 | Average Loss in last 25 iteration(s): 0.2643 | Elapsed 5:44:41\n",
      "Epoch: 001/010 | Batch 20001/45709 | Average Loss in last 25 iteration(s): 0.2425 | Elapsed 5:45:14\n",
      "Epoch: 001/010 | Batch 20026/45709 | Average Loss in last 25 iteration(s): 0.2462 | Elapsed 5:45:35\n",
      "Epoch: 001/010 | Batch 20051/45709 | Average Loss in last 25 iteration(s): 0.2449 | Elapsed 5:45:59\n",
      "Epoch: 001/010 | Batch 20076/45709 | Average Loss in last 25 iteration(s): 0.3045 | Elapsed 5:46:29\n",
      "Epoch: 001/010 | Batch 20101/45709 | Average Loss in last 25 iteration(s): 0.2509 | Elapsed 5:46:56\n",
      "Epoch: 001/010 | Batch 20126/45709 | Average Loss in last 25 iteration(s): 0.2008 | Elapsed 5:47:20\n",
      "Epoch: 001/010 | Batch 20151/45709 | Average Loss in last 25 iteration(s): 0.2454 | Elapsed 5:47:49\n",
      "Epoch: 001/010 | Batch 20176/45709 | Average Loss in last 25 iteration(s): 0.2523 | Elapsed 5:48:11\n",
      "Epoch: 001/010 | Batch 20201/45709 | Average Loss in last 25 iteration(s): 0.2800 | Elapsed 5:48:36\n",
      "Epoch: 001/010 | Batch 20226/45709 | Average Loss in last 25 iteration(s): 0.2659 | Elapsed 5:49:01\n",
      "Epoch: 001/010 | Batch 20251/45709 | Average Loss in last 25 iteration(s): 0.2408 | Elapsed 5:49:30\n",
      "Epoch: 001/010 | Batch 20276/45709 | Average Loss in last 25 iteration(s): 0.2393 | Elapsed 5:49:56\n",
      "Epoch: 001/010 | Batch 20301/45709 | Average Loss in last 25 iteration(s): 0.2214 | Elapsed 5:50:22\n",
      "Epoch: 001/010 | Batch 20326/45709 | Average Loss in last 25 iteration(s): 0.2653 | Elapsed 5:50:45\n",
      "Epoch: 001/010 | Batch 20351/45709 | Average Loss in last 25 iteration(s): 0.2603 | Elapsed 5:51:08\n",
      "Epoch: 001/010 | Batch 20376/45709 | Average Loss in last 25 iteration(s): 0.1971 | Elapsed 5:51:38\n",
      "Epoch: 001/010 | Batch 20401/45709 | Average Loss in last 25 iteration(s): 0.1894 | Elapsed 5:52:05\n",
      "Epoch: 001/010 | Batch 20426/45709 | Average Loss in last 25 iteration(s): 0.3059 | Elapsed 5:52:27\n",
      "Epoch: 001/010 | Batch 20451/45709 | Average Loss in last 25 iteration(s): 0.2394 | Elapsed 5:52:52\n",
      "Epoch: 001/010 | Batch 20476/45709 | Average Loss in last 25 iteration(s): 0.2687 | Elapsed 5:53:20\n",
      "Epoch: 001/010 | Batch 20501/45709 | Average Loss in last 25 iteration(s): 0.2182 | Elapsed 5:53:44\n",
      "Epoch: 001/010 | Batch 20526/45709 | Average Loss in last 25 iteration(s): 0.2353 | Elapsed 5:54:06\n",
      "Epoch: 001/010 | Batch 20551/45709 | Average Loss in last 25 iteration(s): 0.2885 | Elapsed 5:54:37\n",
      "Epoch: 001/010 | Batch 20576/45709 | Average Loss in last 25 iteration(s): 0.2118 | Elapsed 5:55:04\n",
      "Epoch: 001/010 | Batch 20601/45709 | Average Loss in last 25 iteration(s): 0.2299 | Elapsed 5:55:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 20626/45709 | Average Loss in last 25 iteration(s): 0.2181 | Elapsed 5:55:56\n",
      "Epoch: 001/010 | Batch 20651/45709 | Average Loss in last 25 iteration(s): 0.2307 | Elapsed 5:56:23\n",
      "Epoch: 001/010 | Batch 20676/45709 | Average Loss in last 25 iteration(s): 0.2608 | Elapsed 5:56:44\n",
      "Epoch: 001/010 | Batch 20701/45709 | Average Loss in last 25 iteration(s): 0.2662 | Elapsed 5:57:09\n",
      "Epoch: 001/010 | Batch 20726/45709 | Average Loss in last 25 iteration(s): 0.2423 | Elapsed 5:57:40\n",
      "Epoch: 001/010 | Batch 20751/45709 | Average Loss in last 25 iteration(s): 0.2348 | Elapsed 5:58:03\n",
      "Epoch: 001/010 | Batch 20776/45709 | Average Loss in last 25 iteration(s): 0.2029 | Elapsed 5:58:33\n",
      "Epoch: 001/010 | Batch 20801/45709 | Average Loss in last 25 iteration(s): 0.3016 | Elapsed 5:59:01\n",
      "Epoch: 001/010 | Batch 20826/45709 | Average Loss in last 25 iteration(s): 0.2284 | Elapsed 5:59:24\n",
      "Epoch: 001/010 | Batch 20851/45709 | Average Loss in last 25 iteration(s): 0.2738 | Elapsed 5:59:48\n",
      "Epoch: 001/010 | Batch 20876/45709 | Average Loss in last 25 iteration(s): 0.1943 | Elapsed 6:00:16\n",
      "Epoch: 001/010 | Batch 20901/45709 | Average Loss in last 25 iteration(s): 0.2493 | Elapsed 6:00:44\n",
      "Epoch: 001/010 | Batch 20926/45709 | Average Loss in last 25 iteration(s): 0.2860 | Elapsed 6:01:16\n",
      "Epoch: 001/010 | Batch 20951/45709 | Average Loss in last 25 iteration(s): 0.2343 | Elapsed 6:01:39\n",
      "Epoch: 001/010 | Batch 20976/45709 | Average Loss in last 25 iteration(s): 0.2499 | Elapsed 6:02:08\n",
      "Epoch: 001/010 | Batch 21001/45709 | Average Loss in last 25 iteration(s): 0.2546 | Elapsed 6:02:34\n",
      "Epoch: 001/010 | Batch 21026/45709 | Average Loss in last 25 iteration(s): 0.2459 | Elapsed 6:02:55\n",
      "Epoch: 001/010 | Batch 21051/45709 | Average Loss in last 25 iteration(s): 0.2240 | Elapsed 6:03:21\n",
      "Epoch: 001/010 | Batch 21076/45709 | Average Loss in last 25 iteration(s): 0.2201 | Elapsed 6:03:46\n",
      "Epoch: 001/010 | Batch 21101/45709 | Average Loss in last 25 iteration(s): 0.2838 | Elapsed 6:04:14\n",
      "Epoch: 001/010 | Batch 21126/45709 | Average Loss in last 25 iteration(s): 0.2612 | Elapsed 6:04:37\n",
      "Epoch: 001/010 | Batch 21151/45709 | Average Loss in last 25 iteration(s): 0.2594 | Elapsed 6:05:04\n",
      "Epoch: 001/010 | Batch 21176/45709 | Average Loss in last 25 iteration(s): 0.2421 | Elapsed 6:05:26\n",
      "Epoch: 001/010 | Batch 21201/45709 | Average Loss in last 25 iteration(s): 0.2343 | Elapsed 6:05:53\n",
      "Epoch: 001/010 | Batch 21226/45709 | Average Loss in last 25 iteration(s): 0.2530 | Elapsed 6:06:20\n",
      "Epoch: 001/010 | Batch 21251/45709 | Average Loss in last 25 iteration(s): 0.2325 | Elapsed 6:06:44\n",
      "Epoch: 001/010 | Batch 21276/45709 | Average Loss in last 25 iteration(s): 0.2543 | Elapsed 6:07:10\n",
      "Epoch: 001/010 | Batch 21301/45709 | Average Loss in last 25 iteration(s): 0.2309 | Elapsed 6:07:33\n",
      "Epoch: 001/010 | Batch 21326/45709 | Average Loss in last 25 iteration(s): 0.2660 | Elapsed 6:08:01\n",
      "Epoch: 001/010 | Batch 21351/45709 | Average Loss in last 25 iteration(s): 0.2710 | Elapsed 6:08:25\n",
      "Epoch: 001/010 | Batch 21376/45709 | Average Loss in last 25 iteration(s): 0.2515 | Elapsed 6:08:51\n",
      "Epoch: 001/010 | Batch 21401/45709 | Average Loss in last 25 iteration(s): 0.2075 | Elapsed 6:09:19\n",
      "Epoch: 001/010 | Batch 21426/45709 | Average Loss in last 25 iteration(s): 0.2342 | Elapsed 6:09:44\n",
      "Epoch: 001/010 | Batch 21451/45709 | Average Loss in last 25 iteration(s): 0.2306 | Elapsed 6:10:10\n",
      "Epoch: 001/010 | Batch 21476/45709 | Average Loss in last 25 iteration(s): 0.2331 | Elapsed 6:10:31\n",
      "Epoch: 001/010 | Batch 21501/45709 | Average Loss in last 25 iteration(s): 0.2355 | Elapsed 6:11:00\n",
      "Epoch: 001/010 | Batch 21526/45709 | Average Loss in last 25 iteration(s): 0.2541 | Elapsed 6:11:25\n",
      "Epoch: 001/010 | Batch 21551/45709 | Average Loss in last 25 iteration(s): 0.2219 | Elapsed 6:11:52\n",
      "Epoch: 001/010 | Batch 21576/45709 | Average Loss in last 25 iteration(s): 0.1837 | Elapsed 6:12:19\n",
      "Epoch: 001/010 | Batch 21601/45709 | Average Loss in last 25 iteration(s): 0.1962 | Elapsed 6:12:43\n",
      "Epoch: 001/010 | Batch 21626/45709 | Average Loss in last 25 iteration(s): 0.2299 | Elapsed 6:13:11\n",
      "Epoch: 001/010 | Batch 21651/45709 | Average Loss in last 25 iteration(s): 0.2228 | Elapsed 6:13:34\n",
      "Epoch: 001/010 | Batch 21676/45709 | Average Loss in last 25 iteration(s): 0.2543 | Elapsed 6:14:00\n",
      "Epoch: 001/010 | Batch 21701/45709 | Average Loss in last 25 iteration(s): 0.2057 | Elapsed 6:14:26\n",
      "Epoch: 001/010 | Batch 21726/45709 | Average Loss in last 25 iteration(s): 0.2311 | Elapsed 6:14:53\n",
      "Epoch: 001/010 | Batch 21751/45709 | Average Loss in last 25 iteration(s): 0.2212 | Elapsed 6:15:18\n",
      "Epoch: 001/010 | Batch 21776/45709 | Average Loss in last 25 iteration(s): 0.2101 | Elapsed 6:15:44\n",
      "Epoch: 001/010 | Batch 21801/45709 | Average Loss in last 25 iteration(s): 0.2236 | Elapsed 6:16:09\n",
      "Epoch: 001/010 | Batch 21826/45709 | Average Loss in last 25 iteration(s): 0.2203 | Elapsed 6:16:35\n",
      "Epoch: 001/010 | Batch 21851/45709 | Average Loss in last 25 iteration(s): 0.2121 | Elapsed 6:17:03\n",
      "Epoch: 001/010 | Batch 21876/45709 | Average Loss in last 25 iteration(s): 0.2299 | Elapsed 6:17:29\n",
      "Epoch: 001/010 | Batch 21901/45709 | Average Loss in last 25 iteration(s): 0.2143 | Elapsed 6:17:56\n",
      "Epoch: 001/010 | Batch 21926/45709 | Average Loss in last 25 iteration(s): 0.3014 | Elapsed 6:18:22\n",
      "Epoch: 001/010 | Batch 21951/45709 | Average Loss in last 25 iteration(s): 0.2296 | Elapsed 6:18:46\n",
      "Epoch: 001/010 | Batch 21976/45709 | Average Loss in last 25 iteration(s): 0.3217 | Elapsed 6:19:09\n",
      "Epoch: 001/010 | Batch 22001/45709 | Average Loss in last 25 iteration(s): 0.2480 | Elapsed 6:19:38\n",
      "Epoch: 001/010 | Batch 22026/45709 | Average Loss in last 25 iteration(s): 0.2274 | Elapsed 6:20:03\n",
      "Epoch: 001/010 | Batch 22051/45709 | Average Loss in last 25 iteration(s): 0.2444 | Elapsed 6:20:29\n",
      "Epoch: 001/010 | Batch 22076/45709 | Average Loss in last 25 iteration(s): 0.2336 | Elapsed 6:20:55\n",
      "Epoch: 001/010 | Batch 22101/45709 | Average Loss in last 25 iteration(s): 0.2616 | Elapsed 6:21:22\n",
      "Epoch: 001/010 | Batch 22126/45709 | Average Loss in last 25 iteration(s): 0.2441 | Elapsed 6:21:46\n",
      "Epoch: 001/010 | Batch 22151/45709 | Average Loss in last 25 iteration(s): 0.2337 | Elapsed 6:22:13\n",
      "Epoch: 001/010 | Batch 22176/45709 | Average Loss in last 25 iteration(s): 0.2281 | Elapsed 6:22:39\n",
      "Epoch: 001/010 | Batch 22201/45709 | Average Loss in last 25 iteration(s): 0.2723 | Elapsed 6:23:05\n",
      "Epoch: 001/010 | Batch 22226/45709 | Average Loss in last 25 iteration(s): 0.2411 | Elapsed 6:23:30\n",
      "Epoch: 001/010 | Batch 22251/45709 | Average Loss in last 25 iteration(s): 0.2121 | Elapsed 6:23:56\n",
      "Epoch: 001/010 | Batch 22276/45709 | Average Loss in last 25 iteration(s): 0.2405 | Elapsed 6:24:20\n",
      "Epoch: 001/010 | Batch 22301/45709 | Average Loss in last 25 iteration(s): 0.2467 | Elapsed 6:24:42\n",
      "Epoch: 001/010 | Batch 22326/45709 | Average Loss in last 25 iteration(s): 0.2823 | Elapsed 6:25:11\n",
      "Epoch: 001/010 | Batch 22351/45709 | Average Loss in last 25 iteration(s): 0.2260 | Elapsed 6:25:37\n",
      "Epoch: 001/010 | Batch 22376/45709 | Average Loss in last 25 iteration(s): 0.2224 | Elapsed 6:26:03\n",
      "Epoch: 001/010 | Batch 22401/45709 | Average Loss in last 25 iteration(s): 0.2240 | Elapsed 6:26:29\n",
      "Epoch: 001/010 | Batch 22426/45709 | Average Loss in last 25 iteration(s): 0.2335 | Elapsed 6:26:54\n",
      "Epoch: 001/010 | Batch 22451/45709 | Average Loss in last 25 iteration(s): 0.2758 | Elapsed 6:27:17\n",
      "Epoch: 001/010 | Batch 22476/45709 | Average Loss in last 25 iteration(s): 0.2035 | Elapsed 6:27:44\n",
      "Epoch: 001/010 | Batch 22501/45709 | Average Loss in last 25 iteration(s): 0.2413 | Elapsed 6:28:12\n",
      "Epoch: 001/010 | Batch 22526/45709 | Average Loss in last 25 iteration(s): 0.2456 | Elapsed 6:28:37\n",
      "Epoch: 001/010 | Batch 22551/45709 | Average Loss in last 25 iteration(s): 0.2389 | Elapsed 6:29:04\n",
      "Epoch: 001/010 | Batch 22576/45709 | Average Loss in last 25 iteration(s): 0.2829 | Elapsed 6:29:31\n",
      "Epoch: 001/010 | Batch 22601/45709 | Average Loss in last 25 iteration(s): 0.1833 | Elapsed 6:29:54\n",
      "Epoch: 001/010 | Batch 22626/45709 | Average Loss in last 25 iteration(s): 0.1680 | Elapsed 6:30:21\n",
      "Epoch: 001/010 | Batch 22651/45709 | Average Loss in last 25 iteration(s): 0.2489 | Elapsed 6:30:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 22676/45709 | Average Loss in last 25 iteration(s): 0.2138 | Elapsed 6:31:15\n",
      "Epoch: 001/010 | Batch 22701/45709 | Average Loss in last 25 iteration(s): 0.2136 | Elapsed 6:31:41\n",
      "Epoch: 001/010 | Batch 22726/45709 | Average Loss in last 25 iteration(s): 0.2141 | Elapsed 6:32:07\n",
      "Epoch: 001/010 | Batch 22751/45709 | Average Loss in last 25 iteration(s): 0.2501 | Elapsed 6:32:32\n",
      "Epoch: 001/010 | Batch 22776/45709 | Average Loss in last 25 iteration(s): 0.2275 | Elapsed 6:32:54\n",
      "Epoch: 001/010 | Batch 22801/45709 | Average Loss in last 25 iteration(s): 0.2434 | Elapsed 6:33:22\n",
      "Epoch: 001/010 | Batch 22826/45709 | Average Loss in last 25 iteration(s): 0.2092 | Elapsed 6:33:51\n",
      "Epoch: 001/010 | Batch 22851/45709 | Average Loss in last 25 iteration(s): 0.2052 | Elapsed 6:34:17\n",
      "Epoch: 001/010 | Batch 22876/45709 | Average Loss in last 25 iteration(s): 0.2610 | Elapsed 6:34:43\n",
      "Epoch: 001/010 | Batch 22901/45709 | Average Loss in last 25 iteration(s): 0.2061 | Elapsed 6:35:10\n",
      "Epoch: 001/010 | Batch 22926/45709 | Average Loss in last 25 iteration(s): 0.2572 | Elapsed 6:35:32\n",
      "Epoch: 001/010 | Batch 22951/45709 | Average Loss in last 25 iteration(s): 0.2617 | Elapsed 6:35:56\n",
      "Epoch: 001/010 | Batch 22976/45709 | Average Loss in last 25 iteration(s): 0.2414 | Elapsed 6:36:22\n",
      "Epoch: 001/010 | Batch 23001/45709 | Average Loss in last 25 iteration(s): 0.2192 | Elapsed 6:36:48\n",
      "Epoch: 001/010 | Batch 23026/45709 | Average Loss in last 25 iteration(s): 0.2677 | Elapsed 6:37:15\n",
      "Epoch: 001/010 | Batch 23051/45709 | Average Loss in last 25 iteration(s): 0.2383 | Elapsed 6:37:40\n",
      "Epoch: 001/010 | Batch 23076/45709 | Average Loss in last 25 iteration(s): 0.2319 | Elapsed 6:38:06\n",
      "Epoch: 001/010 | Batch 23101/45709 | Average Loss in last 25 iteration(s): 0.2401 | Elapsed 6:38:28\n",
      "Epoch: 001/010 | Batch 23126/45709 | Average Loss in last 25 iteration(s): 0.2591 | Elapsed 6:38:55\n",
      "Epoch: 001/010 | Batch 23151/45709 | Average Loss in last 25 iteration(s): 0.2154 | Elapsed 6:39:23\n",
      "Epoch: 001/010 | Batch 23176/45709 | Average Loss in last 25 iteration(s): 0.2792 | Elapsed 6:39:49\n",
      "Epoch: 001/010 | Batch 23201/45709 | Average Loss in last 25 iteration(s): 0.2259 | Elapsed 6:40:15\n",
      "Epoch: 001/010 | Batch 23226/45709 | Average Loss in last 25 iteration(s): 0.2360 | Elapsed 6:40:42\n",
      "Epoch: 001/010 | Batch 23251/45709 | Average Loss in last 25 iteration(s): 0.2659 | Elapsed 6:41:06\n",
      "Epoch: 001/010 | Batch 23276/45709 | Average Loss in last 25 iteration(s): 0.2391 | Elapsed 6:41:30\n",
      "Epoch: 001/010 | Batch 23301/45709 | Average Loss in last 25 iteration(s): 0.2281 | Elapsed 6:41:57\n",
      "Epoch: 001/010 | Batch 23326/45709 | Average Loss in last 25 iteration(s): 0.2302 | Elapsed 6:42:25\n",
      "Epoch: 001/010 | Batch 23351/45709 | Average Loss in last 25 iteration(s): 0.2613 | Elapsed 6:42:51\n",
      "Epoch: 001/010 | Batch 23376/45709 | Average Loss in last 25 iteration(s): 0.2457 | Elapsed 6:43:17\n",
      "Epoch: 001/010 | Batch 23401/45709 | Average Loss in last 25 iteration(s): 0.2215 | Elapsed 6:43:42\n",
      "Epoch: 001/010 | Batch 23426/45709 | Average Loss in last 25 iteration(s): 0.2677 | Elapsed 6:44:06\n",
      "Epoch: 001/010 | Batch 23451/45709 | Average Loss in last 25 iteration(s): 0.1911 | Elapsed 6:44:33\n",
      "Epoch: 001/010 | Batch 23476/45709 | Average Loss in last 25 iteration(s): 0.2408 | Elapsed 6:45:00\n",
      "Epoch: 001/010 | Batch 23501/45709 | Average Loss in last 25 iteration(s): 0.2247 | Elapsed 6:45:27\n",
      "Epoch: 001/010 | Batch 23526/45709 | Average Loss in last 25 iteration(s): 0.2036 | Elapsed 6:45:53\n",
      "Epoch: 001/010 | Batch 23551/45709 | Average Loss in last 25 iteration(s): 0.1659 | Elapsed 6:46:19\n",
      "Epoch: 001/010 | Batch 23576/45709 | Average Loss in last 25 iteration(s): 0.2172 | Elapsed 6:46:42\n",
      "Epoch: 001/010 | Batch 23601/45709 | Average Loss in last 25 iteration(s): 0.2128 | Elapsed 6:47:06\n",
      "Epoch: 001/010 | Batch 23626/45709 | Average Loss in last 25 iteration(s): 0.1901 | Elapsed 6:47:35\n",
      "Epoch: 001/010 | Batch 23651/45709 | Average Loss in last 25 iteration(s): 0.1806 | Elapsed 6:48:02\n",
      "Epoch: 001/010 | Batch 23676/45709 | Average Loss in last 25 iteration(s): 0.2389 | Elapsed 6:48:28\n",
      "Epoch: 001/010 | Batch 23701/45709 | Average Loss in last 25 iteration(s): 0.1912 | Elapsed 6:48:54\n",
      "Epoch: 001/010 | Batch 23726/45709 | Average Loss in last 25 iteration(s): 0.2222 | Elapsed 6:49:19\n",
      "Epoch: 001/010 | Batch 23751/45709 | Average Loss in last 25 iteration(s): 0.1752 | Elapsed 6:49:42\n",
      "Epoch: 001/010 | Batch 23776/45709 | Average Loss in last 25 iteration(s): 0.2125 | Elapsed 6:50:09\n",
      "Epoch: 001/010 | Batch 23801/45709 | Average Loss in last 25 iteration(s): 0.2665 | Elapsed 6:50:35\n",
      "Epoch: 001/010 | Batch 23826/45709 | Average Loss in last 25 iteration(s): 0.1831 | Elapsed 6:51:01\n",
      "Epoch: 001/010 | Batch 23851/45709 | Average Loss in last 25 iteration(s): 0.2437 | Elapsed 6:51:28\n",
      "Epoch: 001/010 | Batch 23876/45709 | Average Loss in last 25 iteration(s): 0.2064 | Elapsed 6:51:55\n",
      "Epoch: 001/010 | Batch 23901/45709 | Average Loss in last 25 iteration(s): 0.2010 | Elapsed 6:52:17\n",
      "Epoch: 001/010 | Batch 23926/45709 | Average Loss in last 25 iteration(s): 0.1706 | Elapsed 6:52:42\n",
      "Epoch: 001/010 | Batch 23951/45709 | Average Loss in last 25 iteration(s): 0.2039 | Elapsed 6:53:10\n",
      "Epoch: 001/010 | Batch 23976/45709 | Average Loss in last 25 iteration(s): 0.2153 | Elapsed 6:53:37\n",
      "Epoch: 001/010 | Batch 24001/45709 | Average Loss in last 25 iteration(s): 0.1719 | Elapsed 6:54:02\n",
      "Epoch: 001/010 | Batch 24026/45709 | Average Loss in last 25 iteration(s): 0.1881 | Elapsed 6:54:29\n",
      "Epoch: 001/010 | Batch 24051/45709 | Average Loss in last 25 iteration(s): 0.2004 | Elapsed 6:54:54\n",
      "Epoch: 001/010 | Batch 24076/45709 | Average Loss in last 25 iteration(s): 0.2043 | Elapsed 6:55:20\n",
      "Epoch: 001/010 | Batch 24101/45709 | Average Loss in last 25 iteration(s): 0.1931 | Elapsed 6:55:47\n",
      "Epoch: 001/010 | Batch 24126/45709 | Average Loss in last 25 iteration(s): 0.2424 | Elapsed 6:56:14\n",
      "Epoch: 001/010 | Batch 24151/45709 | Average Loss in last 25 iteration(s): 0.2253 | Elapsed 6:56:40\n",
      "Epoch: 001/010 | Batch 24176/45709 | Average Loss in last 25 iteration(s): 0.2492 | Elapsed 6:57:07\n",
      "Epoch: 001/010 | Batch 24201/45709 | Average Loss in last 25 iteration(s): 0.2050 | Elapsed 6:57:32\n",
      "Epoch: 001/010 | Batch 24226/45709 | Average Loss in last 25 iteration(s): 0.2190 | Elapsed 6:57:54\n",
      "Epoch: 001/010 | Batch 24251/45709 | Average Loss in last 25 iteration(s): 0.2302 | Elapsed 6:58:24\n",
      "Epoch: 001/010 | Batch 24276/45709 | Average Loss in last 25 iteration(s): 0.2117 | Elapsed 6:58:53\n",
      "Epoch: 001/010 | Batch 24301/45709 | Average Loss in last 25 iteration(s): 0.2400 | Elapsed 6:59:22\n",
      "Epoch: 001/010 | Batch 24326/45709 | Average Loss in last 25 iteration(s): 0.2225 | Elapsed 6:59:47\n",
      "Epoch: 001/010 | Batch 24351/45709 | Average Loss in last 25 iteration(s): 0.2309 | Elapsed 7:00:09\n",
      "Epoch: 001/010 | Batch 24376/45709 | Average Loss in last 25 iteration(s): 0.2276 | Elapsed 7:00:41\n",
      "Epoch: 001/010 | Batch 24401/45709 | Average Loss in last 25 iteration(s): 0.2367 | Elapsed 7:01:08\n",
      "Epoch: 001/010 | Batch 24426/45709 | Average Loss in last 25 iteration(s): 0.2030 | Elapsed 7:01:38\n",
      "Epoch: 001/010 | Batch 24451/45709 | Average Loss in last 25 iteration(s): 0.1973 | Elapsed 7:02:05\n",
      "Epoch: 001/010 | Batch 24476/45709 | Average Loss in last 25 iteration(s): 0.2006 | Elapsed 7:02:26\n",
      "Epoch: 001/010 | Batch 24501/45709 | Average Loss in last 25 iteration(s): 0.2315 | Elapsed 7:02:48\n",
      "Epoch: 001/010 | Batch 24526/45709 | Average Loss in last 25 iteration(s): 0.2004 | Elapsed 7:03:18\n",
      "Epoch: 001/010 | Batch 24551/45709 | Average Loss in last 25 iteration(s): 0.2179 | Elapsed 7:03:47\n",
      "Epoch: 001/010 | Batch 24576/45709 | Average Loss in last 25 iteration(s): 0.2403 | Elapsed 7:04:15\n",
      "Epoch: 001/010 | Batch 24601/45709 | Average Loss in last 25 iteration(s): 0.2337 | Elapsed 7:04:41\n",
      "Epoch: 001/010 | Batch 24626/45709 | Average Loss in last 25 iteration(s): 0.2277 | Elapsed 7:05:05\n",
      "Epoch: 001/010 | Batch 24651/45709 | Average Loss in last 25 iteration(s): 0.2271 | Elapsed 7:05:29\n",
      "Epoch: 001/010 | Batch 24676/45709 | Average Loss in last 25 iteration(s): 0.2170 | Elapsed 7:05:51\n",
      "Epoch: 001/010 | Batch 24701/45709 | Average Loss in last 25 iteration(s): 0.2382 | Elapsed 7:06:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 24726/45709 | Average Loss in last 25 iteration(s): 0.2185 | Elapsed 7:06:45\n",
      "Epoch: 001/010 | Batch 24751/45709 | Average Loss in last 25 iteration(s): 0.2244 | Elapsed 7:07:11\n",
      "Epoch: 001/010 | Batch 24776/45709 | Average Loss in last 25 iteration(s): 0.2217 | Elapsed 7:07:38\n",
      "Epoch: 001/010 | Batch 24801/45709 | Average Loss in last 25 iteration(s): 0.2005 | Elapsed 7:08:00\n",
      "Epoch: 001/010 | Batch 24826/45709 | Average Loss in last 25 iteration(s): 0.2337 | Elapsed 7:08:29\n",
      "Epoch: 001/010 | Batch 24851/45709 | Average Loss in last 25 iteration(s): 0.2252 | Elapsed 7:09:00\n",
      "Epoch: 001/010 | Batch 24876/45709 | Average Loss in last 25 iteration(s): 0.2544 | Elapsed 7:09:27\n",
      "Epoch: 001/010 | Batch 24901/45709 | Average Loss in last 25 iteration(s): 0.2257 | Elapsed 7:09:52\n",
      "Epoch: 001/010 | Batch 24926/45709 | Average Loss in last 25 iteration(s): 0.1991 | Elapsed 7:10:16\n",
      "Epoch: 001/010 | Batch 24951/45709 | Average Loss in last 25 iteration(s): 0.1917 | Elapsed 7:10:41\n",
      "Epoch: 001/010 | Batch 24976/45709 | Average Loss in last 25 iteration(s): 0.2005 | Elapsed 7:11:14\n",
      "Epoch: 001/010 | Batch 25001/45709 | Average Loss in last 25 iteration(s): 0.2055 | Elapsed 7:11:41\n",
      "Epoch: 001/010 | Batch 25026/45709 | Average Loss in last 25 iteration(s): 0.2222 | Elapsed 7:12:08\n",
      "Epoch: 001/010 | Batch 25051/45709 | Average Loss in last 25 iteration(s): 0.2206 | Elapsed 7:12:29\n",
      "Epoch: 001/010 | Batch 25076/45709 | Average Loss in last 25 iteration(s): 0.2088 | Elapsed 7:12:49\n",
      "Epoch: 001/010 | Batch 25101/45709 | Average Loss in last 25 iteration(s): 0.2456 | Elapsed 7:13:11\n",
      "Epoch: 001/010 | Batch 25126/45709 | Average Loss in last 25 iteration(s): 0.1905 | Elapsed 7:13:36\n",
      "Epoch: 001/010 | Batch 25151/45709 | Average Loss in last 25 iteration(s): 0.2770 | Elapsed 7:14:05\n",
      "Epoch: 001/010 | Batch 25176/45709 | Average Loss in last 25 iteration(s): 0.2111 | Elapsed 7:14:37\n",
      "Epoch: 001/010 | Batch 25201/45709 | Average Loss in last 25 iteration(s): 0.2076 | Elapsed 7:15:03\n",
      "Epoch: 001/010 | Batch 25226/45709 | Average Loss in last 25 iteration(s): 0.2155 | Elapsed 7:15:27\n",
      "Epoch: 001/010 | Batch 25251/45709 | Average Loss in last 25 iteration(s): 0.2256 | Elapsed 7:15:48\n",
      "Epoch: 001/010 | Batch 25276/45709 | Average Loss in last 25 iteration(s): 0.1954 | Elapsed 7:16:08\n",
      "Epoch: 001/010 | Batch 25301/45709 | Average Loss in last 25 iteration(s): 0.2406 | Elapsed 7:16:34\n",
      "Epoch: 001/010 | Batch 25326/45709 | Average Loss in last 25 iteration(s): 0.1841 | Elapsed 7:16:58\n",
      "Epoch: 001/010 | Batch 25351/45709 | Average Loss in last 25 iteration(s): 0.2229 | Elapsed 7:17:30\n",
      "Epoch: 001/010 | Batch 25376/45709 | Average Loss in last 25 iteration(s): 0.2024 | Elapsed 7:17:57\n",
      "Epoch: 001/010 | Batch 25401/45709 | Average Loss in last 25 iteration(s): 0.2314 | Elapsed 7:18:22\n",
      "Epoch: 001/010 | Batch 25426/45709 | Average Loss in last 25 iteration(s): 0.2089 | Elapsed 7:18:45\n",
      "Epoch: 001/010 | Batch 25451/45709 | Average Loss in last 25 iteration(s): 0.2245 | Elapsed 7:19:05\n",
      "Epoch: 001/010 | Batch 25476/45709 | Average Loss in last 25 iteration(s): 0.2570 | Elapsed 7:19:27\n",
      "Epoch: 001/010 | Batch 25501/45709 | Average Loss in last 25 iteration(s): 0.2047 | Elapsed 7:19:52\n",
      "Epoch: 001/010 | Batch 25526/45709 | Average Loss in last 25 iteration(s): 0.2123 | Elapsed 7:20:22\n",
      "Epoch: 001/010 | Batch 25551/45709 | Average Loss in last 25 iteration(s): 0.2450 | Elapsed 7:20:51\n",
      "Epoch: 001/010 | Batch 25576/45709 | Average Loss in last 25 iteration(s): 0.1907 | Elapsed 7:21:16\n",
      "Epoch: 001/010 | Batch 25601/45709 | Average Loss in last 25 iteration(s): 0.1846 | Elapsed 7:21:43\n",
      "Epoch: 001/010 | Batch 25626/45709 | Average Loss in last 25 iteration(s): 0.2392 | Elapsed 7:22:04\n",
      "Epoch: 001/010 | Batch 25651/45709 | Average Loss in last 25 iteration(s): 0.1899 | Elapsed 7:22:25\n",
      "Epoch: 001/010 | Batch 25676/45709 | Average Loss in last 25 iteration(s): 0.2196 | Elapsed 7:22:50\n",
      "Epoch: 001/010 | Batch 25701/45709 | Average Loss in last 25 iteration(s): 0.2359 | Elapsed 7:23:13\n",
      "Epoch: 001/010 | Batch 25726/45709 | Average Loss in last 25 iteration(s): 0.2231 | Elapsed 7:23:39\n",
      "Epoch: 001/010 | Batch 25751/45709 | Average Loss in last 25 iteration(s): 0.2519 | Elapsed 7:24:11\n",
      "Epoch: 001/010 | Batch 25776/45709 | Average Loss in last 25 iteration(s): 0.1910 | Elapsed 7:24:39\n",
      "Epoch: 001/010 | Batch 25801/45709 | Average Loss in last 25 iteration(s): 0.1977 | Elapsed 7:25:03\n",
      "Epoch: 001/010 | Batch 25826/45709 | Average Loss in last 25 iteration(s): 0.2274 | Elapsed 7:25:24\n",
      "Epoch: 001/010 | Batch 25851/45709 | Average Loss in last 25 iteration(s): 0.2284 | Elapsed 7:25:50\n",
      "Epoch: 001/010 | Batch 25876/45709 | Average Loss in last 25 iteration(s): 0.2034 | Elapsed 7:26:12\n",
      "Epoch: 001/010 | Batch 25901/45709 | Average Loss in last 25 iteration(s): 0.2052 | Elapsed 7:26:37\n",
      "Epoch: 001/010 | Batch 25926/45709 | Average Loss in last 25 iteration(s): 0.2403 | Elapsed 7:27:07\n",
      "Epoch: 001/010 | Batch 25951/45709 | Average Loss in last 25 iteration(s): 0.2302 | Elapsed 7:27:34\n",
      "Epoch: 001/010 | Batch 25976/45709 | Average Loss in last 25 iteration(s): 0.2045 | Elapsed 7:27:58\n",
      "Epoch: 001/010 | Batch 26001/45709 | Average Loss in last 25 iteration(s): 0.2062 | Elapsed 7:28:24\n",
      "Epoch: 001/010 | Batch 26026/45709 | Average Loss in last 25 iteration(s): 0.2475 | Elapsed 7:28:46\n",
      "Epoch: 001/010 | Batch 26051/45709 | Average Loss in last 25 iteration(s): 0.1639 | Elapsed 7:29:07\n",
      "Epoch: 001/010 | Batch 26076/45709 | Average Loss in last 25 iteration(s): 0.2055 | Elapsed 7:29:32\n",
      "Epoch: 001/010 | Batch 26101/45709 | Average Loss in last 25 iteration(s): 0.1801 | Elapsed 7:30:05\n",
      "Epoch: 001/010 | Batch 26126/45709 | Average Loss in last 25 iteration(s): 0.1793 | Elapsed 7:30:32\n",
      "Epoch: 001/010 | Batch 26151/45709 | Average Loss in last 25 iteration(s): 0.2231 | Elapsed 7:30:56\n",
      "Epoch: 001/010 | Batch 26176/45709 | Average Loss in last 25 iteration(s): 0.2313 | Elapsed 7:31:23\n",
      "Epoch: 001/010 | Batch 26201/45709 | Average Loss in last 25 iteration(s): 0.2133 | Elapsed 7:31:45\n",
      "Epoch: 001/010 | Batch 26226/45709 | Average Loss in last 25 iteration(s): 0.1758 | Elapsed 7:32:08\n",
      "Epoch: 001/010 | Batch 26251/45709 | Average Loss in last 25 iteration(s): 0.2183 | Elapsed 7:32:36\n",
      "Epoch: 001/010 | Batch 26276/45709 | Average Loss in last 25 iteration(s): 0.2209 | Elapsed 7:33:05\n",
      "Epoch: 001/010 | Batch 26301/45709 | Average Loss in last 25 iteration(s): 0.2315 | Elapsed 7:33:30\n",
      "Epoch: 001/010 | Batch 26326/45709 | Average Loss in last 25 iteration(s): 0.1544 | Elapsed 7:33:59\n",
      "Epoch: 001/010 | Batch 26351/45709 | Average Loss in last 25 iteration(s): 0.2257 | Elapsed 7:34:23\n",
      "Epoch: 001/010 | Batch 26376/45709 | Average Loss in last 25 iteration(s): 0.2349 | Elapsed 7:34:44\n",
      "Epoch: 001/010 | Batch 26401/45709 | Average Loss in last 25 iteration(s): 0.2142 | Elapsed 7:35:06\n",
      "Epoch: 001/010 | Batch 26426/45709 | Average Loss in last 25 iteration(s): 0.2355 | Elapsed 7:35:37\n",
      "Epoch: 001/010 | Batch 26451/45709 | Average Loss in last 25 iteration(s): 0.2344 | Elapsed 7:36:05\n",
      "Epoch: 001/010 | Batch 26476/45709 | Average Loss in last 25 iteration(s): 0.2020 | Elapsed 7:36:29\n",
      "Epoch: 001/010 | Batch 26501/45709 | Average Loss in last 25 iteration(s): 0.1947 | Elapsed 7:36:56\n",
      "Epoch: 001/010 | Batch 26526/45709 | Average Loss in last 25 iteration(s): 0.2028 | Elapsed 7:37:21\n",
      "Epoch: 001/010 | Batch 26551/45709 | Average Loss in last 25 iteration(s): 0.1667 | Elapsed 7:37:47\n",
      "Epoch: 001/010 | Batch 26576/45709 | Average Loss in last 25 iteration(s): 0.2149 | Elapsed 7:38:16\n",
      "Epoch: 001/010 | Batch 26601/45709 | Average Loss in last 25 iteration(s): 0.2084 | Elapsed 7:38:42\n",
      "Epoch: 001/010 | Batch 26626/45709 | Average Loss in last 25 iteration(s): 0.1800 | Elapsed 7:39:06\n",
      "Epoch: 001/010 | Batch 26651/45709 | Average Loss in last 25 iteration(s): 0.2005 | Elapsed 7:39:30\n",
      "Epoch: 001/010 | Batch 26676/45709 | Average Loss in last 25 iteration(s): 0.2296 | Elapsed 7:39:59\n",
      "Epoch: 001/010 | Batch 26701/45709 | Average Loss in last 25 iteration(s): 0.2420 | Elapsed 7:40:24\n",
      "Epoch: 001/010 | Batch 26726/45709 | Average Loss in last 25 iteration(s): 0.2187 | Elapsed 7:40:53\n",
      "Epoch: 001/010 | Batch 26751/45709 | Average Loss in last 25 iteration(s): 0.2018 | Elapsed 7:41:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 26776/45709 | Average Loss in last 25 iteration(s): 0.1822 | Elapsed 7:41:41\n",
      "Epoch: 001/010 | Batch 26801/45709 | Average Loss in last 25 iteration(s): 0.1809 | Elapsed 7:42:07\n",
      "Epoch: 001/010 | Batch 26826/45709 | Average Loss in last 25 iteration(s): 0.2317 | Elapsed 7:42:32\n",
      "Epoch: 001/010 | Batch 26851/45709 | Average Loss in last 25 iteration(s): 0.1703 | Elapsed 7:42:57\n",
      "Epoch: 001/010 | Batch 26876/45709 | Average Loss in last 25 iteration(s): 0.2004 | Elapsed 7:43:20\n",
      "Epoch: 001/010 | Batch 26901/45709 | Average Loss in last 25 iteration(s): 0.2231 | Elapsed 7:43:48\n",
      "Epoch: 001/010 | Batch 26926/45709 | Average Loss in last 25 iteration(s): 0.1798 | Elapsed 7:44:15\n",
      "Epoch: 001/010 | Batch 26951/45709 | Average Loss in last 25 iteration(s): 0.2670 | Elapsed 7:44:41\n",
      "Epoch: 001/010 | Batch 26976/45709 | Average Loss in last 25 iteration(s): 0.2198 | Elapsed 7:45:07\n",
      "Epoch: 001/010 | Batch 27001/45709 | Average Loss in last 25 iteration(s): 0.2243 | Elapsed 7:45:33\n",
      "Epoch: 001/010 | Batch 27026/45709 | Average Loss in last 25 iteration(s): 0.1885 | Elapsed 7:45:55\n",
      "Epoch: 001/010 | Batch 27051/45709 | Average Loss in last 25 iteration(s): 0.1932 | Elapsed 7:46:21\n",
      "Epoch: 001/010 | Batch 27076/45709 | Average Loss in last 25 iteration(s): 0.1820 | Elapsed 7:46:50\n",
      "Epoch: 001/010 | Batch 27101/45709 | Average Loss in last 25 iteration(s): 0.2075 | Elapsed 7:47:14\n",
      "Epoch: 001/010 | Batch 27126/45709 | Average Loss in last 25 iteration(s): 0.2016 | Elapsed 7:47:40\n",
      "Epoch: 001/010 | Batch 27151/45709 | Average Loss in last 25 iteration(s): 0.1946 | Elapsed 7:48:05\n",
      "Epoch: 001/010 | Batch 27176/45709 | Average Loss in last 25 iteration(s): 0.1791 | Elapsed 7:48:30\n",
      "Epoch: 001/010 | Batch 27201/45709 | Average Loss in last 25 iteration(s): 0.2215 | Elapsed 7:48:54\n",
      "Epoch: 001/010 | Batch 27226/45709 | Average Loss in last 25 iteration(s): 0.2482 | Elapsed 7:49:25\n",
      "Epoch: 001/010 | Batch 27251/45709 | Average Loss in last 25 iteration(s): 0.1728 | Elapsed 7:49:50\n",
      "Epoch: 001/010 | Batch 27276/45709 | Average Loss in last 25 iteration(s): 0.1643 | Elapsed 7:50:15\n",
      "Epoch: 001/010 | Batch 27301/45709 | Average Loss in last 25 iteration(s): 0.1777 | Elapsed 7:50:42\n",
      "Epoch: 001/010 | Batch 27326/45709 | Average Loss in last 25 iteration(s): 0.1461 | Elapsed 7:51:07\n",
      "Epoch: 001/010 | Batch 27351/45709 | Average Loss in last 25 iteration(s): 0.2355 | Elapsed 7:51:30\n",
      "Epoch: 001/010 | Batch 27376/45709 | Average Loss in last 25 iteration(s): 0.1994 | Elapsed 7:51:59\n",
      "Epoch: 001/010 | Batch 27401/45709 | Average Loss in last 25 iteration(s): 0.2001 | Elapsed 7:52:26\n",
      "Epoch: 001/010 | Batch 27426/45709 | Average Loss in last 25 iteration(s): 0.2038 | Elapsed 7:52:54\n",
      "Epoch: 001/010 | Batch 27451/45709 | Average Loss in last 25 iteration(s): 0.1987 | Elapsed 7:53:20\n",
      "Epoch: 001/010 | Batch 27476/45709 | Average Loss in last 25 iteration(s): 0.1874 | Elapsed 7:53:44\n",
      "Epoch: 001/010 | Batch 27501/45709 | Average Loss in last 25 iteration(s): 0.2172 | Elapsed 7:54:07\n",
      "Epoch: 001/010 | Batch 27526/45709 | Average Loss in last 25 iteration(s): 0.1724 | Elapsed 7:54:35\n",
      "Epoch: 001/010 | Batch 27551/45709 | Average Loss in last 25 iteration(s): 0.1975 | Elapsed 7:55:02\n",
      "Epoch: 001/010 | Batch 27576/45709 | Average Loss in last 25 iteration(s): 0.2322 | Elapsed 7:55:28\n",
      "Epoch: 001/010 | Batch 27601/45709 | Average Loss in last 25 iteration(s): 0.2372 | Elapsed 7:55:53\n",
      "Epoch: 001/010 | Batch 27626/45709 | Average Loss in last 25 iteration(s): 0.1901 | Elapsed 7:56:19\n",
      "Epoch: 001/010 | Batch 27651/45709 | Average Loss in last 25 iteration(s): 0.2281 | Elapsed 7:56:44\n",
      "Epoch: 001/010 | Batch 27676/45709 | Average Loss in last 25 iteration(s): 0.2360 | Elapsed 7:57:08\n",
      "Epoch: 001/010 | Batch 27701/45709 | Average Loss in last 25 iteration(s): 0.2408 | Elapsed 7:57:36\n",
      "Epoch: 001/010 | Batch 27726/45709 | Average Loss in last 25 iteration(s): 0.2336 | Elapsed 7:58:02\n",
      "Epoch: 001/010 | Batch 27751/45709 | Average Loss in last 25 iteration(s): 0.1455 | Elapsed 7:58:29\n",
      "Epoch: 001/010 | Batch 27776/45709 | Average Loss in last 25 iteration(s): 0.2014 | Elapsed 7:58:55\n",
      "Epoch: 001/010 | Batch 27801/45709 | Average Loss in last 25 iteration(s): 0.1607 | Elapsed 7:59:20\n",
      "Epoch: 001/010 | Batch 27826/45709 | Average Loss in last 25 iteration(s): 0.2055 | Elapsed 7:59:44\n",
      "Epoch: 001/010 | Batch 27851/45709 | Average Loss in last 25 iteration(s): 0.1829 | Elapsed 8:00:12\n",
      "Epoch: 001/010 | Batch 27876/45709 | Average Loss in last 25 iteration(s): 0.2244 | Elapsed 8:00:38\n",
      "Epoch: 001/010 | Batch 27901/45709 | Average Loss in last 25 iteration(s): 0.1881 | Elapsed 8:01:02\n",
      "Epoch: 001/010 | Batch 27926/45709 | Average Loss in last 25 iteration(s): 0.1798 | Elapsed 8:01:30\n",
      "Epoch: 001/010 | Batch 27951/45709 | Average Loss in last 25 iteration(s): 0.2246 | Elapsed 8:01:56\n",
      "Epoch: 001/010 | Batch 27976/45709 | Average Loss in last 25 iteration(s): 0.2316 | Elapsed 8:02:19\n",
      "Epoch: 001/010 | Batch 28001/45709 | Average Loss in last 25 iteration(s): 0.2136 | Elapsed 8:02:45\n",
      "Epoch: 001/010 | Batch 28026/45709 | Average Loss in last 25 iteration(s): 0.2670 | Elapsed 8:03:12\n",
      "Epoch: 001/010 | Batch 28051/45709 | Average Loss in last 25 iteration(s): 0.2056 | Elapsed 8:03:38\n",
      "Epoch: 001/010 | Batch 28076/45709 | Average Loss in last 25 iteration(s): 0.1876 | Elapsed 8:04:05\n",
      "Epoch: 001/010 | Batch 28101/45709 | Average Loss in last 25 iteration(s): 0.1995 | Elapsed 8:04:30\n",
      "Epoch: 001/010 | Batch 28126/45709 | Average Loss in last 25 iteration(s): 0.2085 | Elapsed 8:04:55\n",
      "Epoch: 001/010 | Batch 28151/45709 | Average Loss in last 25 iteration(s): 0.1855 | Elapsed 8:05:20\n",
      "Epoch: 001/010 | Batch 28176/45709 | Average Loss in last 25 iteration(s): 0.1878 | Elapsed 8:05:47\n",
      "Epoch: 001/010 | Batch 28201/45709 | Average Loss in last 25 iteration(s): 0.1692 | Elapsed 8:06:11\n",
      "Epoch: 001/010 | Batch 28226/45709 | Average Loss in last 25 iteration(s): 0.2116 | Elapsed 8:06:39\n",
      "Epoch: 001/010 | Batch 28251/45709 | Average Loss in last 25 iteration(s): 0.1917 | Elapsed 8:07:04\n",
      "Epoch: 001/010 | Batch 28276/45709 | Average Loss in last 25 iteration(s): 0.1722 | Elapsed 8:07:29\n",
      "Epoch: 001/010 | Batch 28301/45709 | Average Loss in last 25 iteration(s): 0.1896 | Elapsed 8:07:52\n",
      "Epoch: 001/010 | Batch 28326/45709 | Average Loss in last 25 iteration(s): 0.2143 | Elapsed 8:08:18\n",
      "Epoch: 001/010 | Batch 28351/45709 | Average Loss in last 25 iteration(s): 0.1768 | Elapsed 8:08:46\n",
      "Epoch: 001/010 | Batch 28376/45709 | Average Loss in last 25 iteration(s): 0.1817 | Elapsed 8:09:13\n",
      "Epoch: 001/010 | Batch 28401/45709 | Average Loss in last 25 iteration(s): 0.1657 | Elapsed 8:09:40\n",
      "Epoch: 001/010 | Batch 28426/45709 | Average Loss in last 25 iteration(s): 0.1998 | Elapsed 8:10:06\n",
      "Epoch: 001/010 | Batch 28451/45709 | Average Loss in last 25 iteration(s): 0.1453 | Elapsed 8:10:31\n",
      "Epoch: 001/010 | Batch 28476/45709 | Average Loss in last 25 iteration(s): 0.2356 | Elapsed 8:10:53\n",
      "Epoch: 001/010 | Batch 28501/45709 | Average Loss in last 25 iteration(s): 0.1564 | Elapsed 8:11:21\n",
      "Epoch: 001/010 | Batch 28526/45709 | Average Loss in last 25 iteration(s): 0.1825 | Elapsed 8:11:49\n",
      "Epoch: 001/010 | Batch 28551/45709 | Average Loss in last 25 iteration(s): 0.1979 | Elapsed 8:12:16\n",
      "Epoch: 001/010 | Batch 28576/45709 | Average Loss in last 25 iteration(s): 0.2015 | Elapsed 8:12:42\n",
      "Epoch: 001/010 | Batch 28601/45709 | Average Loss in last 25 iteration(s): 0.2026 | Elapsed 8:13:08\n",
      "Epoch: 001/010 | Batch 28626/45709 | Average Loss in last 25 iteration(s): 0.2520 | Elapsed 8:13:30\n",
      "Epoch: 001/010 | Batch 28651/45709 | Average Loss in last 25 iteration(s): 0.2084 | Elapsed 8:13:56\n",
      "Epoch: 001/010 | Batch 28676/45709 | Average Loss in last 25 iteration(s): 0.1676 | Elapsed 8:14:26\n",
      "Epoch: 001/010 | Batch 28701/45709 | Average Loss in last 25 iteration(s): 0.2197 | Elapsed 8:14:51\n",
      "Epoch: 001/010 | Batch 28726/45709 | Average Loss in last 25 iteration(s): 0.2144 | Elapsed 8:15:19\n",
      "Epoch: 001/010 | Batch 28751/45709 | Average Loss in last 25 iteration(s): 0.1791 | Elapsed 8:15:45\n",
      "Epoch: 001/010 | Batch 28776/45709 | Average Loss in last 25 iteration(s): 0.1893 | Elapsed 8:16:09\n",
      "Epoch: 001/010 | Batch 28801/45709 | Average Loss in last 25 iteration(s): 0.2083 | Elapsed 8:16:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 28826/45709 | Average Loss in last 25 iteration(s): 0.2134 | Elapsed 8:17:00\n",
      "Epoch: 001/010 | Batch 28851/45709 | Average Loss in last 25 iteration(s): 0.1762 | Elapsed 8:17:25\n",
      "Epoch: 001/010 | Batch 28876/45709 | Average Loss in last 25 iteration(s): 0.1824 | Elapsed 8:17:51\n",
      "Epoch: 001/010 | Batch 28901/45709 | Average Loss in last 25 iteration(s): 0.2131 | Elapsed 8:18:17\n",
      "Epoch: 001/010 | Batch 28926/45709 | Average Loss in last 25 iteration(s): 0.1738 | Elapsed 8:18:43\n",
      "Epoch: 001/010 | Batch 28951/45709 | Average Loss in last 25 iteration(s): 0.1861 | Elapsed 8:19:06\n",
      "Epoch: 001/010 | Batch 28976/45709 | Average Loss in last 25 iteration(s): 0.1860 | Elapsed 8:19:32\n",
      "Epoch: 001/010 | Batch 29001/45709 | Average Loss in last 25 iteration(s): 0.2000 | Elapsed 8:20:00\n",
      "Epoch: 001/010 | Batch 29026/45709 | Average Loss in last 25 iteration(s): 0.2019 | Elapsed 8:20:27\n",
      "Epoch: 001/010 | Batch 29051/45709 | Average Loss in last 25 iteration(s): 0.1831 | Elapsed 8:20:52\n",
      "Epoch: 001/010 | Batch 29076/45709 | Average Loss in last 25 iteration(s): 0.2393 | Elapsed 8:21:18\n",
      "Epoch: 001/010 | Batch 29101/45709 | Average Loss in last 25 iteration(s): 0.1927 | Elapsed 8:21:43\n",
      "Epoch: 001/010 | Batch 29126/45709 | Average Loss in last 25 iteration(s): 0.2333 | Elapsed 8:22:08\n",
      "Epoch: 001/010 | Batch 29151/45709 | Average Loss in last 25 iteration(s): 0.1666 | Elapsed 8:22:35\n",
      "Epoch: 001/010 | Batch 29176/45709 | Average Loss in last 25 iteration(s): 0.2005 | Elapsed 8:23:02\n",
      "Epoch: 001/010 | Batch 29201/45709 | Average Loss in last 25 iteration(s): 0.2563 | Elapsed 8:23:27\n",
      "Epoch: 001/010 | Batch 29226/45709 | Average Loss in last 25 iteration(s): 0.2103 | Elapsed 8:23:52\n",
      "Epoch: 001/010 | Batch 29251/45709 | Average Loss in last 25 iteration(s): 0.1980 | Elapsed 8:24:19\n",
      "Epoch: 001/010 | Batch 29276/45709 | Average Loss in last 25 iteration(s): 0.1999 | Elapsed 8:24:41\n",
      "Epoch: 001/010 | Batch 29301/45709 | Average Loss in last 25 iteration(s): 0.2010 | Elapsed 8:25:08\n",
      "Epoch: 001/010 | Batch 29326/45709 | Average Loss in last 25 iteration(s): 0.1718 | Elapsed 8:25:35\n",
      "Epoch: 001/010 | Batch 29351/45709 | Average Loss in last 25 iteration(s): 0.1752 | Elapsed 8:26:01\n",
      "Epoch: 001/010 | Batch 29376/45709 | Average Loss in last 25 iteration(s): 0.2189 | Elapsed 8:26:31\n",
      "Epoch: 001/010 | Batch 29401/45709 | Average Loss in last 25 iteration(s): 0.1783 | Elapsed 8:26:59\n",
      "Epoch: 001/010 | Batch 29426/45709 | Average Loss in last 25 iteration(s): 0.1894 | Elapsed 8:27:30\n",
      "Epoch: 001/010 | Batch 29451/45709 | Average Loss in last 25 iteration(s): 0.1866 | Elapsed 8:28:01\n",
      "Epoch: 001/010 | Batch 29476/45709 | Average Loss in last 25 iteration(s): 0.2115 | Elapsed 8:28:37\n",
      "Epoch: 001/010 | Batch 29501/45709 | Average Loss in last 25 iteration(s): 0.1789 | Elapsed 8:29:05\n",
      "Epoch: 001/010 | Batch 29526/45709 | Average Loss in last 25 iteration(s): 0.2476 | Elapsed 8:29:30\n",
      "Epoch: 001/010 | Batch 29551/45709 | Average Loss in last 25 iteration(s): 0.1996 | Elapsed 8:29:57\n",
      "Epoch: 001/010 | Batch 29576/45709 | Average Loss in last 25 iteration(s): 0.1858 | Elapsed 8:30:20\n",
      "Epoch: 001/010 | Batch 29601/45709 | Average Loss in last 25 iteration(s): 0.1551 | Elapsed 8:30:47\n",
      "Epoch: 001/010 | Batch 29626/45709 | Average Loss in last 25 iteration(s): 0.1494 | Elapsed 8:31:15\n",
      "Epoch: 001/010 | Batch 29651/45709 | Average Loss in last 25 iteration(s): 0.2060 | Elapsed 8:31:44\n",
      "Epoch: 001/010 | Batch 29676/45709 | Average Loss in last 25 iteration(s): 0.1959 | Elapsed 8:32:16\n",
      "Epoch: 001/010 | Batch 29701/45709 | Average Loss in last 25 iteration(s): 0.1936 | Elapsed 8:32:45\n",
      "Epoch: 001/010 | Batch 29726/45709 | Average Loss in last 25 iteration(s): 0.1710 | Elapsed 8:33:12\n",
      "Epoch: 001/010 | Batch 29751/45709 | Average Loss in last 25 iteration(s): 0.1963 | Elapsed 8:33:42\n",
      "Epoch: 001/010 | Batch 29776/45709 | Average Loss in last 25 iteration(s): 0.1917 | Elapsed 8:34:08\n",
      "Epoch: 001/010 | Batch 29801/45709 | Average Loss in last 25 iteration(s): 0.1950 | Elapsed 8:34:34\n",
      "Epoch: 001/010 | Batch 29826/45709 | Average Loss in last 25 iteration(s): 0.2134 | Elapsed 8:35:03\n",
      "Epoch: 001/010 | Batch 29851/45709 | Average Loss in last 25 iteration(s): 0.2232 | Elapsed 8:35:27\n",
      "Epoch: 001/010 | Batch 29876/45709 | Average Loss in last 25 iteration(s): 0.2218 | Elapsed 8:35:51\n",
      "Epoch: 001/010 | Batch 29901/45709 | Average Loss in last 25 iteration(s): 0.1586 | Elapsed 8:36:14\n",
      "Epoch: 001/010 | Batch 29926/45709 | Average Loss in last 25 iteration(s): 0.1837 | Elapsed 8:36:45\n",
      "Epoch: 001/010 | Batch 29951/45709 | Average Loss in last 25 iteration(s): 0.1476 | Elapsed 8:37:15\n",
      "Epoch: 001/010 | Batch 29976/45709 | Average Loss in last 25 iteration(s): 0.1795 | Elapsed 8:37:41\n",
      "Epoch: 001/010 | Batch 30001/45709 | Average Loss in last 25 iteration(s): 0.1479 | Elapsed 8:38:08\n",
      "Epoch: 001/010 | Batch 30026/45709 | Average Loss in last 25 iteration(s): 0.2153 | Elapsed 8:38:33\n",
      "Epoch: 001/010 | Batch 30051/45709 | Average Loss in last 25 iteration(s): 0.2138 | Elapsed 8:39:07\n",
      "Epoch: 001/010 | Batch 30076/45709 | Average Loss in last 25 iteration(s): 0.1829 | Elapsed 8:39:43\n",
      "Epoch: 001/010 | Batch 30101/45709 | Average Loss in last 25 iteration(s): 0.1672 | Elapsed 8:40:29\n",
      "Epoch: 001/010 | Batch 30126/45709 | Average Loss in last 25 iteration(s): 0.1946 | Elapsed 8:40:53\n",
      "Epoch: 001/010 | Batch 30151/45709 | Average Loss in last 25 iteration(s): 0.1735 | Elapsed 8:41:18\n",
      "Epoch: 001/010 | Batch 30176/45709 | Average Loss in last 25 iteration(s): 0.1758 | Elapsed 8:41:41\n",
      "Epoch: 001/010 | Batch 30201/45709 | Average Loss in last 25 iteration(s): 0.1934 | Elapsed 8:42:12\n",
      "Epoch: 001/010 | Batch 30226/45709 | Average Loss in last 25 iteration(s): 0.1948 | Elapsed 8:42:39\n",
      "Epoch: 001/010 | Batch 30251/45709 | Average Loss in last 25 iteration(s): 0.1545 | Elapsed 8:43:06\n",
      "Epoch: 001/010 | Batch 30276/45709 | Average Loss in last 25 iteration(s): 0.1627 | Elapsed 8:43:27\n",
      "Epoch: 001/010 | Batch 30301/45709 | Average Loss in last 25 iteration(s): 0.1473 | Elapsed 8:43:49\n",
      "Epoch: 001/010 | Batch 30326/45709 | Average Loss in last 25 iteration(s): 0.1955 | Elapsed 8:44:17\n",
      "Epoch: 001/010 | Batch 30351/45709 | Average Loss in last 25 iteration(s): 0.2216 | Elapsed 8:44:44\n",
      "Epoch: 001/010 | Batch 30376/45709 | Average Loss in last 25 iteration(s): 0.2072 | Elapsed 8:45:14\n",
      "Epoch: 001/010 | Batch 30401/45709 | Average Loss in last 25 iteration(s): 0.1736 | Elapsed 8:45:41\n",
      "Epoch: 001/010 | Batch 30426/45709 | Average Loss in last 25 iteration(s): 0.1496 | Elapsed 8:46:04\n",
      "Epoch: 001/010 | Batch 30451/45709 | Average Loss in last 25 iteration(s): 0.1656 | Elapsed 8:46:24\n",
      "Epoch: 001/010 | Batch 30476/45709 | Average Loss in last 25 iteration(s): 0.1952 | Elapsed 8:46:49\n",
      "Epoch: 001/010 | Batch 30501/45709 | Average Loss in last 25 iteration(s): 0.1788 | Elapsed 8:47:14\n",
      "Epoch: 001/010 | Batch 30526/45709 | Average Loss in last 25 iteration(s): 0.2034 | Elapsed 8:47:46\n",
      "Epoch: 001/010 | Batch 30551/45709 | Average Loss in last 25 iteration(s): 0.1732 | Elapsed 8:48:14\n",
      "Epoch: 001/010 | Batch 30576/45709 | Average Loss in last 25 iteration(s): 0.1649 | Elapsed 8:48:38\n",
      "Epoch: 001/010 | Batch 30601/45709 | Average Loss in last 25 iteration(s): 0.2210 | Elapsed 8:49:06\n",
      "Epoch: 001/010 | Batch 30626/45709 | Average Loss in last 25 iteration(s): 0.1931 | Elapsed 8:49:31\n",
      "Epoch: 001/010 | Batch 30651/45709 | Average Loss in last 25 iteration(s): 0.2044 | Elapsed 8:50:01\n",
      "Epoch: 001/010 | Batch 30676/45709 | Average Loss in last 25 iteration(s): 0.2338 | Elapsed 8:50:29\n",
      "Epoch: 001/010 | Batch 30701/45709 | Average Loss in last 25 iteration(s): 0.2072 | Elapsed 8:50:52\n",
      "Epoch: 001/010 | Batch 30726/45709 | Average Loss in last 25 iteration(s): 0.2508 | Elapsed 8:51:21\n",
      "Epoch: 001/010 | Batch 30751/45709 | Average Loss in last 25 iteration(s): 0.2332 | Elapsed 8:51:47\n",
      "Epoch: 001/010 | Batch 30776/45709 | Average Loss in last 25 iteration(s): 0.1760 | Elapsed 8:52:10\n",
      "Epoch: 001/010 | Batch 30801/45709 | Average Loss in last 25 iteration(s): 0.1990 | Elapsed 8:52:37\n",
      "Epoch: 001/010 | Batch 30826/45709 | Average Loss in last 25 iteration(s): 0.1551 | Elapsed 8:53:04\n",
      "Epoch: 001/010 | Batch 30851/45709 | Average Loss in last 25 iteration(s): 0.1825 | Elapsed 8:53:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 30876/45709 | Average Loss in last 25 iteration(s): 0.1872 | Elapsed 8:53:55\n",
      "Epoch: 001/010 | Batch 30901/45709 | Average Loss in last 25 iteration(s): 0.1692 | Elapsed 8:54:21\n",
      "Epoch: 001/010 | Batch 30926/45709 | Average Loss in last 25 iteration(s): 0.1894 | Elapsed 8:54:44\n",
      "Epoch: 001/010 | Batch 30951/45709 | Average Loss in last 25 iteration(s): 0.1848 | Elapsed 8:55:12\n",
      "Epoch: 001/010 | Batch 30976/45709 | Average Loss in last 25 iteration(s): 0.1930 | Elapsed 8:55:40\n",
      "Epoch: 001/010 | Batch 31001/45709 | Average Loss in last 25 iteration(s): 0.1294 | Elapsed 8:56:03\n",
      "Epoch: 001/010 | Batch 31026/45709 | Average Loss in last 25 iteration(s): 0.2091 | Elapsed 8:56:30\n",
      "Epoch: 001/010 | Batch 31051/45709 | Average Loss in last 25 iteration(s): 0.1752 | Elapsed 8:56:55\n",
      "Epoch: 001/010 | Batch 31076/45709 | Average Loss in last 25 iteration(s): 0.1588 | Elapsed 8:57:19\n",
      "Epoch: 001/010 | Batch 31101/45709 | Average Loss in last 25 iteration(s): 0.1896 | Elapsed 8:57:45\n",
      "Epoch: 001/010 | Batch 31126/45709 | Average Loss in last 25 iteration(s): 0.1773 | Elapsed 8:58:11\n",
      "Epoch: 001/010 | Batch 31151/45709 | Average Loss in last 25 iteration(s): 0.2147 | Elapsed 8:58:37\n",
      "Epoch: 001/010 | Batch 31176/45709 | Average Loss in last 25 iteration(s): 0.1481 | Elapsed 8:59:03\n",
      "Epoch: 001/010 | Batch 31201/45709 | Average Loss in last 25 iteration(s): 0.1983 | Elapsed 8:59:29\n",
      "Epoch: 001/010 | Batch 31226/45709 | Average Loss in last 25 iteration(s): 0.1667 | Elapsed 8:59:54\n",
      "Epoch: 001/010 | Batch 31251/45709 | Average Loss in last 25 iteration(s): 0.1880 | Elapsed 9:00:17\n",
      "Epoch: 001/010 | Batch 31276/45709 | Average Loss in last 25 iteration(s): 0.1646 | Elapsed 9:00:46\n",
      "Epoch: 001/010 | Batch 31301/45709 | Average Loss in last 25 iteration(s): 0.2049 | Elapsed 9:01:12\n",
      "Epoch: 001/010 | Batch 31326/45709 | Average Loss in last 25 iteration(s): 0.1631 | Elapsed 9:01:38\n",
      "Epoch: 001/010 | Batch 31351/45709 | Average Loss in last 25 iteration(s): 0.2130 | Elapsed 9:02:04\n",
      "Epoch: 001/010 | Batch 31376/45709 | Average Loss in last 25 iteration(s): 0.1676 | Elapsed 9:02:30\n",
      "Epoch: 001/010 | Batch 31401/45709 | Average Loss in last 25 iteration(s): 0.2274 | Elapsed 9:02:52\n",
      "Epoch: 001/010 | Batch 31426/45709 | Average Loss in last 25 iteration(s): 0.1647 | Elapsed 9:03:18\n",
      "Epoch: 001/010 | Batch 31451/45709 | Average Loss in last 25 iteration(s): 0.1797 | Elapsed 9:03:45\n",
      "Epoch: 001/010 | Batch 31476/45709 | Average Loss in last 25 iteration(s): 0.1876 | Elapsed 9:04:11\n",
      "Epoch: 001/010 | Batch 31501/45709 | Average Loss in last 25 iteration(s): 0.2187 | Elapsed 9:04:37\n",
      "Epoch: 001/010 | Batch 31526/45709 | Average Loss in last 25 iteration(s): 0.2144 | Elapsed 9:05:04\n",
      "Epoch: 001/010 | Batch 31551/45709 | Average Loss in last 25 iteration(s): 0.1531 | Elapsed 9:05:29\n",
      "Epoch: 001/010 | Batch 31576/45709 | Average Loss in last 25 iteration(s): 0.1792 | Elapsed 9:05:52\n",
      "Epoch: 001/010 | Batch 31601/45709 | Average Loss in last 25 iteration(s): 0.2044 | Elapsed 9:06:18\n",
      "Epoch: 001/010 | Batch 31626/45709 | Average Loss in last 25 iteration(s): 0.2016 | Elapsed 9:06:45\n",
      "Epoch: 001/010 | Batch 31651/45709 | Average Loss in last 25 iteration(s): 0.1808 | Elapsed 9:07:11\n",
      "Epoch: 001/010 | Batch 31676/45709 | Average Loss in last 25 iteration(s): 0.1484 | Elapsed 9:07:38\n",
      "Epoch: 001/010 | Batch 31701/45709 | Average Loss in last 25 iteration(s): 0.1762 | Elapsed 9:08:03\n",
      "Epoch: 001/010 | Batch 31726/45709 | Average Loss in last 25 iteration(s): 0.2126 | Elapsed 9:08:26\n",
      "Epoch: 001/010 | Batch 31751/45709 | Average Loss in last 25 iteration(s): 0.1984 | Elapsed 9:08:51\n",
      "Epoch: 001/010 | Batch 31776/45709 | Average Loss in last 25 iteration(s): 0.1822 | Elapsed 9:09:19\n",
      "Epoch: 001/010 | Batch 31801/45709 | Average Loss in last 25 iteration(s): 0.2039 | Elapsed 9:09:46\n",
      "Epoch: 001/010 | Batch 31826/45709 | Average Loss in last 25 iteration(s): 0.1513 | Elapsed 9:10:11\n",
      "Epoch: 001/010 | Batch 31851/45709 | Average Loss in last 25 iteration(s): 0.1835 | Elapsed 9:10:36\n",
      "Epoch: 001/010 | Batch 31876/45709 | Average Loss in last 25 iteration(s): 0.1725 | Elapsed 9:11:02\n",
      "Epoch: 001/010 | Batch 31901/45709 | Average Loss in last 25 iteration(s): 0.1393 | Elapsed 9:11:25\n",
      "Epoch: 001/010 | Batch 31926/45709 | Average Loss in last 25 iteration(s): 0.1883 | Elapsed 9:11:55\n",
      "Epoch: 001/010 | Batch 31951/45709 | Average Loss in last 25 iteration(s): 0.1876 | Elapsed 9:12:20\n",
      "Epoch: 001/010 | Batch 31976/45709 | Average Loss in last 25 iteration(s): 0.1864 | Elapsed 9:12:46\n",
      "Epoch: 001/010 | Batch 32001/45709 | Average Loss in last 25 iteration(s): 0.1717 | Elapsed 9:13:13\n",
      "Epoch: 001/010 | Batch 32026/45709 | Average Loss in last 25 iteration(s): 0.1922 | Elapsed 9:13:38\n",
      "Epoch: 001/010 | Batch 32051/45709 | Average Loss in last 25 iteration(s): 0.2024 | Elapsed 9:14:00\n",
      "Epoch: 001/010 | Batch 32076/45709 | Average Loss in last 25 iteration(s): 0.2029 | Elapsed 9:14:28\n",
      "Epoch: 001/010 | Batch 32101/45709 | Average Loss in last 25 iteration(s): 0.1573 | Elapsed 9:14:55\n",
      "Epoch: 001/010 | Batch 32126/45709 | Average Loss in last 25 iteration(s): 0.1756 | Elapsed 9:15:21\n",
      "Epoch: 001/010 | Batch 32151/45709 | Average Loss in last 25 iteration(s): 0.1843 | Elapsed 9:15:48\n",
      "Epoch: 001/010 | Batch 32176/45709 | Average Loss in last 25 iteration(s): 0.2105 | Elapsed 9:16:13\n",
      "Epoch: 001/010 | Batch 32201/45709 | Average Loss in last 25 iteration(s): 0.2239 | Elapsed 9:16:37\n",
      "Epoch: 001/010 | Batch 32226/45709 | Average Loss in last 25 iteration(s): 0.1487 | Elapsed 9:17:01\n",
      "Epoch: 001/010 | Batch 32251/45709 | Average Loss in last 25 iteration(s): 0.2155 | Elapsed 9:17:29\n",
      "Epoch: 001/010 | Batch 32276/45709 | Average Loss in last 25 iteration(s): 0.2327 | Elapsed 9:17:55\n",
      "Epoch: 001/010 | Batch 32301/45709 | Average Loss in last 25 iteration(s): 0.1538 | Elapsed 9:18:21\n",
      "Epoch: 001/010 | Batch 32326/45709 | Average Loss in last 25 iteration(s): 0.1787 | Elapsed 9:18:47\n",
      "Epoch: 001/010 | Batch 32351/45709 | Average Loss in last 25 iteration(s): 0.1795 | Elapsed 9:19:12\n",
      "Epoch: 001/010 | Batch 32376/45709 | Average Loss in last 25 iteration(s): 0.1805 | Elapsed 9:19:35\n",
      "Epoch: 001/010 | Batch 32401/45709 | Average Loss in last 25 iteration(s): 0.2164 | Elapsed 9:20:02\n",
      "Epoch: 001/010 | Batch 32426/45709 | Average Loss in last 25 iteration(s): 0.1993 | Elapsed 9:20:30\n",
      "Epoch: 001/010 | Batch 32451/45709 | Average Loss in last 25 iteration(s): 0.2080 | Elapsed 9:20:55\n",
      "Epoch: 001/010 | Batch 32476/45709 | Average Loss in last 25 iteration(s): 0.1840 | Elapsed 9:21:22\n",
      "Epoch: 001/010 | Batch 32501/45709 | Average Loss in last 25 iteration(s): 0.2051 | Elapsed 9:21:48\n",
      "Epoch: 001/010 | Batch 32526/45709 | Average Loss in last 25 iteration(s): 0.2129 | Elapsed 9:22:13\n",
      "Epoch: 001/010 | Batch 32551/45709 | Average Loss in last 25 iteration(s): 0.1947 | Elapsed 9:22:37\n",
      "Epoch: 001/010 | Batch 32576/45709 | Average Loss in last 25 iteration(s): 0.1866 | Elapsed 9:23:04\n",
      "Epoch: 001/010 | Batch 32601/45709 | Average Loss in last 25 iteration(s): 0.2005 | Elapsed 9:23:30\n",
      "Epoch: 001/010 | Batch 32626/45709 | Average Loss in last 25 iteration(s): 0.1236 | Elapsed 9:23:58\n",
      "Epoch: 001/010 | Batch 32651/45709 | Average Loss in last 25 iteration(s): 0.1593 | Elapsed 9:24:24\n",
      "Epoch: 001/010 | Batch 32676/45709 | Average Loss in last 25 iteration(s): 0.1955 | Elapsed 9:24:48\n",
      "Epoch: 001/010 | Batch 32701/45709 | Average Loss in last 25 iteration(s): 0.1659 | Elapsed 9:25:13\n",
      "Epoch: 001/010 | Batch 32726/45709 | Average Loss in last 25 iteration(s): 0.1887 | Elapsed 9:25:40\n",
      "Epoch: 001/010 | Batch 32751/45709 | Average Loss in last 25 iteration(s): 0.1651 | Elapsed 9:26:06\n",
      "Epoch: 001/010 | Batch 32776/45709 | Average Loss in last 25 iteration(s): 0.1680 | Elapsed 9:26:31\n",
      "Epoch: 001/010 | Batch 32801/45709 | Average Loss in last 25 iteration(s): 0.1470 | Elapsed 9:26:59\n",
      "Epoch: 001/010 | Batch 32826/45709 | Average Loss in last 25 iteration(s): 0.1776 | Elapsed 9:27:25\n",
      "Epoch: 001/010 | Batch 32851/45709 | Average Loss in last 25 iteration(s): 0.1786 | Elapsed 9:27:49\n",
      "Epoch: 001/010 | Batch 32876/45709 | Average Loss in last 25 iteration(s): 0.2001 | Elapsed 9:28:14\n",
      "Epoch: 001/010 | Batch 32901/45709 | Average Loss in last 25 iteration(s): 0.1717 | Elapsed 9:28:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 32926/45709 | Average Loss in last 25 iteration(s): 0.2085 | Elapsed 9:29:08\n",
      "Epoch: 001/010 | Batch 32951/45709 | Average Loss in last 25 iteration(s): 0.1798 | Elapsed 9:29:33\n",
      "Epoch: 001/010 | Batch 32976/45709 | Average Loss in last 25 iteration(s): 0.1864 | Elapsed 9:29:59\n",
      "Epoch: 001/010 | Batch 33001/45709 | Average Loss in last 25 iteration(s): 0.2097 | Elapsed 9:30:24\n",
      "Epoch: 001/010 | Batch 33026/45709 | Average Loss in last 25 iteration(s): 0.1785 | Elapsed 9:30:47\n",
      "Epoch: 001/010 | Batch 33051/45709 | Average Loss in last 25 iteration(s): 0.1792 | Elapsed 9:31:16\n",
      "Epoch: 001/010 | Batch 33076/45709 | Average Loss in last 25 iteration(s): 0.1697 | Elapsed 9:31:43\n",
      "Epoch: 001/010 | Batch 33101/45709 | Average Loss in last 25 iteration(s): 0.2271 | Elapsed 9:32:09\n",
      "Epoch: 001/010 | Batch 33126/45709 | Average Loss in last 25 iteration(s): 0.1921 | Elapsed 9:32:35\n",
      "Epoch: 001/010 | Batch 33151/45709 | Average Loss in last 25 iteration(s): 0.1935 | Elapsed 9:33:00\n",
      "Epoch: 001/010 | Batch 33176/45709 | Average Loss in last 25 iteration(s): 0.2010 | Elapsed 9:33:23\n",
      "Epoch: 001/010 | Batch 33201/45709 | Average Loss in last 25 iteration(s): 0.2216 | Elapsed 9:33:49\n",
      "Epoch: 001/010 | Batch 33226/45709 | Average Loss in last 25 iteration(s): 0.1738 | Elapsed 9:34:16\n",
      "Epoch: 001/010 | Batch 33251/45709 | Average Loss in last 25 iteration(s): 0.1583 | Elapsed 9:34:42\n",
      "Epoch: 001/010 | Batch 33276/45709 | Average Loss in last 25 iteration(s): 0.1872 | Elapsed 9:35:10\n",
      "Epoch: 001/010 | Batch 33301/45709 | Average Loss in last 25 iteration(s): 0.1916 | Elapsed 9:35:36\n",
      "Epoch: 001/010 | Batch 33326/45709 | Average Loss in last 25 iteration(s): 0.1722 | Elapsed 9:35:59\n",
      "Epoch: 001/010 | Batch 33351/45709 | Average Loss in last 25 iteration(s): 0.1765 | Elapsed 9:36:23\n",
      "Epoch: 001/010 | Batch 33376/45709 | Average Loss in last 25 iteration(s): 0.1921 | Elapsed 9:36:51\n",
      "Epoch: 001/010 | Batch 33401/45709 | Average Loss in last 25 iteration(s): 0.1845 | Elapsed 9:37:19\n",
      "Epoch: 001/010 | Batch 33426/45709 | Average Loss in last 25 iteration(s): 0.1971 | Elapsed 9:37:45\n",
      "Epoch: 001/010 | Batch 33451/45709 | Average Loss in last 25 iteration(s): 0.1692 | Elapsed 9:38:12\n",
      "Epoch: 001/010 | Batch 33476/45709 | Average Loss in last 25 iteration(s): 0.1760 | Elapsed 9:38:36\n",
      "Epoch: 001/010 | Batch 33501/45709 | Average Loss in last 25 iteration(s): 0.1798 | Elapsed 9:38:58\n",
      "Epoch: 001/010 | Batch 33526/45709 | Average Loss in last 25 iteration(s): 0.1865 | Elapsed 9:39:26\n",
      "Epoch: 001/010 | Batch 33551/45709 | Average Loss in last 25 iteration(s): 0.1777 | Elapsed 9:39:54\n",
      "Epoch: 001/010 | Batch 33576/45709 | Average Loss in last 25 iteration(s): 0.1929 | Elapsed 9:40:19\n",
      "Epoch: 001/010 | Batch 33601/45709 | Average Loss in last 25 iteration(s): 0.2021 | Elapsed 9:40:44\n",
      "Epoch: 001/010 | Batch 33626/45709 | Average Loss in last 25 iteration(s): 0.1838 | Elapsed 9:41:10\n",
      "Epoch: 001/010 | Batch 33651/45709 | Average Loss in last 25 iteration(s): 0.1741 | Elapsed 9:41:34\n",
      "Epoch: 001/010 | Batch 33676/45709 | Average Loss in last 25 iteration(s): 0.1580 | Elapsed 9:42:01\n",
      "Epoch: 001/010 | Batch 33701/45709 | Average Loss in last 25 iteration(s): 0.1731 | Elapsed 9:42:27\n",
      "Epoch: 001/010 | Batch 33726/45709 | Average Loss in last 25 iteration(s): 0.1744 | Elapsed 9:42:52\n",
      "Epoch: 001/010 | Batch 33751/45709 | Average Loss in last 25 iteration(s): 0.1724 | Elapsed 9:43:18\n",
      "Epoch: 001/010 | Batch 33776/45709 | Average Loss in last 25 iteration(s): 0.1792 | Elapsed 9:43:43\n",
      "Epoch: 001/010 | Batch 33801/45709 | Average Loss in last 25 iteration(s): 0.1722 | Elapsed 9:44:08\n",
      "Epoch: 001/010 | Batch 33826/45709 | Average Loss in last 25 iteration(s): 0.2281 | Elapsed 9:44:32\n",
      "Epoch: 001/010 | Batch 33851/45709 | Average Loss in last 25 iteration(s): 0.1987 | Elapsed 9:44:58\n",
      "Epoch: 001/010 | Batch 33876/45709 | Average Loss in last 25 iteration(s): 0.1404 | Elapsed 9:45:25\n",
      "Epoch: 001/010 | Batch 33901/45709 | Average Loss in last 25 iteration(s): 0.1851 | Elapsed 9:45:52\n",
      "Epoch: 001/010 | Batch 33926/45709 | Average Loss in last 25 iteration(s): 0.1751 | Elapsed 9:46:18\n",
      "Epoch: 001/010 | Batch 33951/45709 | Average Loss in last 25 iteration(s): 0.1488 | Elapsed 9:46:42\n",
      "Epoch: 001/010 | Batch 33976/45709 | Average Loss in last 25 iteration(s): 0.2139 | Elapsed 9:47:05\n",
      "Epoch: 001/010 | Batch 34001/45709 | Average Loss in last 25 iteration(s): 0.2252 | Elapsed 9:47:31\n",
      "Epoch: 001/010 | Batch 34026/45709 | Average Loss in last 25 iteration(s): 0.1607 | Elapsed 9:47:58\n",
      "Epoch: 001/010 | Batch 34051/45709 | Average Loss in last 25 iteration(s): 0.1686 | Elapsed 9:48:23\n",
      "Epoch: 001/010 | Batch 34076/45709 | Average Loss in last 25 iteration(s): 0.1640 | Elapsed 9:48:51\n",
      "Epoch: 001/010 | Batch 34101/45709 | Average Loss in last 25 iteration(s): 0.1896 | Elapsed 9:49:17\n",
      "Epoch: 001/010 | Batch 34126/45709 | Average Loss in last 25 iteration(s): 0.1478 | Elapsed 9:49:40\n",
      "Epoch: 001/010 | Batch 34151/45709 | Average Loss in last 25 iteration(s): 0.2457 | Elapsed 9:50:06\n",
      "Epoch: 001/010 | Batch 34176/45709 | Average Loss in last 25 iteration(s): 0.1653 | Elapsed 9:50:33\n",
      "Epoch: 001/010 | Batch 34201/45709 | Average Loss in last 25 iteration(s): 0.1806 | Elapsed 9:51:00\n",
      "Epoch: 001/010 | Batch 34226/45709 | Average Loss in last 25 iteration(s): 0.1259 | Elapsed 9:51:27\n",
      "Epoch: 001/010 | Batch 34251/45709 | Average Loss in last 25 iteration(s): 0.2388 | Elapsed 9:51:52\n",
      "Epoch: 001/010 | Batch 34276/45709 | Average Loss in last 25 iteration(s): 0.1969 | Elapsed 9:52:17\n",
      "Epoch: 001/010 | Batch 34301/45709 | Average Loss in last 25 iteration(s): 0.1437 | Elapsed 9:52:40\n",
      "Epoch: 001/010 | Batch 34326/45709 | Average Loss in last 25 iteration(s): 0.1915 | Elapsed 9:53:07\n",
      "Epoch: 001/010 | Batch 34351/45709 | Average Loss in last 25 iteration(s): 0.1518 | Elapsed 9:53:33\n",
      "Epoch: 001/010 | Batch 34376/45709 | Average Loss in last 25 iteration(s): 0.1657 | Elapsed 9:54:01\n",
      "Epoch: 001/010 | Batch 34401/45709 | Average Loss in last 25 iteration(s): 0.1998 | Elapsed 9:54:30\n",
      "Epoch: 001/010 | Batch 34426/45709 | Average Loss in last 25 iteration(s): 0.1711 | Elapsed 9:54:54\n",
      "Epoch: 001/010 | Batch 34451/45709 | Average Loss in last 25 iteration(s): 0.1726 | Elapsed 9:55:18\n",
      "Epoch: 001/010 | Batch 34476/45709 | Average Loss in last 25 iteration(s): 0.1561 | Elapsed 9:55:45\n",
      "Epoch: 001/010 | Batch 34501/45709 | Average Loss in last 25 iteration(s): 0.1823 | Elapsed 9:56:13\n",
      "Epoch: 001/010 | Batch 34526/45709 | Average Loss in last 25 iteration(s): 0.2135 | Elapsed 9:56:42\n",
      "Epoch: 001/010 | Batch 34551/45709 | Average Loss in last 25 iteration(s): 0.1662 | Elapsed 9:57:08\n",
      "Epoch: 001/010 | Batch 34576/45709 | Average Loss in last 25 iteration(s): 0.1606 | Elapsed 9:57:30\n",
      "Epoch: 001/010 | Batch 34601/45709 | Average Loss in last 25 iteration(s): 0.1919 | Elapsed 9:57:54\n",
      "Epoch: 001/010 | Batch 34626/45709 | Average Loss in last 25 iteration(s): 0.1845 | Elapsed 9:58:22\n",
      "Epoch: 001/010 | Batch 34651/45709 | Average Loss in last 25 iteration(s): 0.1991 | Elapsed 9:58:50\n",
      "Epoch: 001/010 | Batch 34676/45709 | Average Loss in last 25 iteration(s): 0.1434 | Elapsed 9:59:17\n",
      "Epoch: 001/010 | Batch 34701/45709 | Average Loss in last 25 iteration(s): 0.1199 | Elapsed 9:59:44\n",
      "Epoch: 001/010 | Batch 34726/45709 | Average Loss in last 25 iteration(s): 0.1884 | Elapsed 10:00:12\n",
      "Epoch: 001/010 | Batch 34751/45709 | Average Loss in last 25 iteration(s): 0.2599 | Elapsed 10:00:42\n",
      "Epoch: 001/010 | Batch 34776/45709 | Average Loss in last 25 iteration(s): 0.1616 | Elapsed 10:01:09\n",
      "Epoch: 001/010 | Batch 34801/45709 | Average Loss in last 25 iteration(s): 0.1349 | Elapsed 10:01:38\n",
      "Epoch: 001/010 | Batch 34826/45709 | Average Loss in last 25 iteration(s): 0.1500 | Elapsed 10:02:02\n",
      "Epoch: 001/010 | Batch 34851/45709 | Average Loss in last 25 iteration(s): 0.1429 | Elapsed 10:02:29\n",
      "Epoch: 001/010 | Batch 34876/45709 | Average Loss in last 25 iteration(s): 0.1874 | Elapsed 10:03:00\n",
      "Epoch: 001/010 | Batch 34901/45709 | Average Loss in last 25 iteration(s): 0.2288 | Elapsed 10:03:26\n",
      "Epoch: 001/010 | Batch 34926/45709 | Average Loss in last 25 iteration(s): 0.1952 | Elapsed 10:03:53\n",
      "Epoch: 001/010 | Batch 34951/45709 | Average Loss in last 25 iteration(s): 0.1741 | Elapsed 10:04:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 34976/45709 | Average Loss in last 25 iteration(s): 0.1577 | Elapsed 10:04:37\n",
      "Epoch: 001/010 | Batch 35001/45709 | Average Loss in last 25 iteration(s): 0.1499 | Elapsed 10:05:01\n",
      "Epoch: 001/010 | Batch 35026/45709 | Average Loss in last 25 iteration(s): 0.1765 | Elapsed 10:05:30\n",
      "Epoch: 001/010 | Batch 35051/45709 | Average Loss in last 25 iteration(s): 0.1524 | Elapsed 10:05:58\n",
      "Epoch: 001/010 | Batch 35076/45709 | Average Loss in last 25 iteration(s): 0.1895 | Elapsed 10:06:25\n",
      "Epoch: 001/010 | Batch 35101/45709 | Average Loss in last 25 iteration(s): 0.1533 | Elapsed 10:06:49\n",
      "Epoch: 001/010 | Batch 35126/45709 | Average Loss in last 25 iteration(s): 0.1610 | Elapsed 10:07:14\n",
      "Epoch: 001/010 | Batch 35151/45709 | Average Loss in last 25 iteration(s): 0.2077 | Elapsed 10:07:35\n",
      "Epoch: 001/010 | Batch 35176/45709 | Average Loss in last 25 iteration(s): 0.1631 | Elapsed 10:07:57\n",
      "Epoch: 001/010 | Batch 35201/45709 | Average Loss in last 25 iteration(s): 0.1758 | Elapsed 10:08:24\n",
      "Epoch: 001/010 | Batch 35226/45709 | Average Loss in last 25 iteration(s): 0.1558 | Elapsed 10:08:52\n",
      "Epoch: 001/010 | Batch 35251/45709 | Average Loss in last 25 iteration(s): 0.2093 | Elapsed 10:09:18\n",
      "Epoch: 001/010 | Batch 35276/45709 | Average Loss in last 25 iteration(s): 0.1722 | Elapsed 10:09:42\n",
      "Epoch: 001/010 | Batch 35301/45709 | Average Loss in last 25 iteration(s): 0.1785 | Elapsed 10:10:07\n",
      "Epoch: 001/010 | Batch 35326/45709 | Average Loss in last 25 iteration(s): 0.1893 | Elapsed 10:10:30\n",
      "Epoch: 001/010 | Batch 35351/45709 | Average Loss in last 25 iteration(s): 0.1961 | Elapsed 10:10:51\n",
      "Epoch: 001/010 | Batch 35376/45709 | Average Loss in last 25 iteration(s): 0.2013 | Elapsed 10:11:14\n",
      "Epoch: 001/010 | Batch 35401/45709 | Average Loss in last 25 iteration(s): 0.1617 | Elapsed 10:11:47\n",
      "Epoch: 001/010 | Batch 35426/45709 | Average Loss in last 25 iteration(s): 0.1086 | Elapsed 10:12:13\n",
      "Epoch: 001/010 | Batch 35451/45709 | Average Loss in last 25 iteration(s): 0.1558 | Elapsed 10:12:41\n",
      "Epoch: 001/010 | Batch 35476/45709 | Average Loss in last 25 iteration(s): 0.2315 | Elapsed 10:13:05\n",
      "Epoch: 001/010 | Batch 35501/45709 | Average Loss in last 25 iteration(s): 0.1966 | Elapsed 10:13:30\n",
      "Epoch: 001/010 | Batch 35526/45709 | Average Loss in last 25 iteration(s): 0.2111 | Elapsed 10:13:53\n",
      "Epoch: 001/010 | Batch 35551/45709 | Average Loss in last 25 iteration(s): 0.1697 | Elapsed 10:14:20\n",
      "Epoch: 001/010 | Batch 35576/45709 | Average Loss in last 25 iteration(s): 0.1889 | Elapsed 10:14:49\n",
      "Epoch: 001/010 | Batch 35601/45709 | Average Loss in last 25 iteration(s): 0.1433 | Elapsed 10:15:15\n",
      "Epoch: 001/010 | Batch 35626/45709 | Average Loss in last 25 iteration(s): 0.1604 | Elapsed 10:15:39\n",
      "Epoch: 001/010 | Batch 35651/45709 | Average Loss in last 25 iteration(s): 0.1665 | Elapsed 10:16:04\n",
      "Epoch: 001/010 | Batch 35676/45709 | Average Loss in last 25 iteration(s): 0.2093 | Elapsed 10:16:29\n",
      "Epoch: 001/010 | Batch 35701/45709 | Average Loss in last 25 iteration(s): 0.1815 | Elapsed 10:16:52\n",
      "Epoch: 001/010 | Batch 35726/45709 | Average Loss in last 25 iteration(s): 0.1766 | Elapsed 10:17:22\n",
      "Epoch: 001/010 | Batch 35751/45709 | Average Loss in last 25 iteration(s): 0.1387 | Elapsed 10:17:48\n",
      "Epoch: 001/010 | Batch 35776/45709 | Average Loss in last 25 iteration(s): 0.1423 | Elapsed 10:18:15\n",
      "Epoch: 001/010 | Batch 35801/45709 | Average Loss in last 25 iteration(s): 0.1707 | Elapsed 10:18:42\n",
      "Epoch: 001/010 | Batch 35826/45709 | Average Loss in last 25 iteration(s): 0.1671 | Elapsed 10:19:07\n",
      "Epoch: 001/010 | Batch 35851/45709 | Average Loss in last 25 iteration(s): 0.2339 | Elapsed 10:19:31\n",
      "Epoch: 001/010 | Batch 35876/45709 | Average Loss in last 25 iteration(s): 0.1547 | Elapsed 10:19:58\n",
      "Epoch: 001/010 | Batch 35901/45709 | Average Loss in last 25 iteration(s): 0.1513 | Elapsed 10:20:25\n",
      "Epoch: 001/010 | Batch 35926/45709 | Average Loss in last 25 iteration(s): 0.1338 | Elapsed 10:20:51\n",
      "Epoch: 001/010 | Batch 35951/45709 | Average Loss in last 25 iteration(s): 0.2148 | Elapsed 10:21:17\n",
      "Epoch: 001/010 | Batch 35976/45709 | Average Loss in last 25 iteration(s): 0.1528 | Elapsed 10:21:43\n",
      "Epoch: 001/010 | Batch 36001/45709 | Average Loss in last 25 iteration(s): 0.1963 | Elapsed 10:22:07\n",
      "Epoch: 001/010 | Batch 36026/45709 | Average Loss in last 25 iteration(s): 0.1510 | Elapsed 10:22:35\n",
      "Epoch: 001/010 | Batch 36051/45709 | Average Loss in last 25 iteration(s): 0.1926 | Elapsed 10:23:01\n",
      "Epoch: 001/010 | Batch 36076/45709 | Average Loss in last 25 iteration(s): 0.1702 | Elapsed 10:23:27\n",
      "Epoch: 001/010 | Batch 36101/45709 | Average Loss in last 25 iteration(s): 0.2034 | Elapsed 10:23:54\n",
      "Epoch: 001/010 | Batch 36126/45709 | Average Loss in last 25 iteration(s): 0.1728 | Elapsed 10:24:21\n",
      "Epoch: 001/010 | Batch 36151/45709 | Average Loss in last 25 iteration(s): 0.2141 | Elapsed 10:24:43\n",
      "Epoch: 001/010 | Batch 36176/45709 | Average Loss in last 25 iteration(s): 0.1862 | Elapsed 10:25:11\n",
      "Epoch: 001/010 | Batch 36201/45709 | Average Loss in last 25 iteration(s): 0.2265 | Elapsed 10:25:40\n",
      "Epoch: 001/010 | Batch 36226/45709 | Average Loss in last 25 iteration(s): 0.1745 | Elapsed 10:26:07\n",
      "Epoch: 001/010 | Batch 36251/45709 | Average Loss in last 25 iteration(s): 0.1834 | Elapsed 10:26:31\n",
      "Epoch: 001/010 | Batch 36276/45709 | Average Loss in last 25 iteration(s): 0.1192 | Elapsed 10:26:57\n",
      "Epoch: 001/010 | Batch 36301/45709 | Average Loss in last 25 iteration(s): 0.1576 | Elapsed 10:27:20\n",
      "Epoch: 001/010 | Batch 36326/45709 | Average Loss in last 25 iteration(s): 0.1823 | Elapsed 10:27:48\n",
      "Epoch: 001/010 | Batch 36351/45709 | Average Loss in last 25 iteration(s): 0.1298 | Elapsed 10:28:16\n",
      "Epoch: 001/010 | Batch 36376/45709 | Average Loss in last 25 iteration(s): 0.2094 | Elapsed 10:28:41\n",
      "Epoch: 001/010 | Batch 36401/45709 | Average Loss in last 25 iteration(s): 0.1464 | Elapsed 10:29:06\n",
      "Epoch: 001/010 | Batch 36426/45709 | Average Loss in last 25 iteration(s): 0.1920 | Elapsed 10:29:32\n",
      "Epoch: 001/010 | Batch 36451/45709 | Average Loss in last 25 iteration(s): 0.2239 | Elapsed 10:29:56\n",
      "Epoch: 001/010 | Batch 36476/45709 | Average Loss in last 25 iteration(s): 0.1693 | Elapsed 10:30:20\n",
      "Epoch: 001/010 | Batch 36501/45709 | Average Loss in last 25 iteration(s): 0.1484 | Elapsed 10:30:50\n",
      "Epoch: 001/010 | Batch 36526/45709 | Average Loss in last 25 iteration(s): 0.1882 | Elapsed 10:31:16\n",
      "Epoch: 001/010 | Batch 36551/45709 | Average Loss in last 25 iteration(s): 0.1794 | Elapsed 10:31:42\n",
      "Epoch: 001/010 | Batch 36576/45709 | Average Loss in last 25 iteration(s): 0.1407 | Elapsed 10:32:08\n",
      "Epoch: 001/010 | Batch 36601/45709 | Average Loss in last 25 iteration(s): 0.1609 | Elapsed 10:32:32\n",
      "Epoch: 001/010 | Batch 36626/45709 | Average Loss in last 25 iteration(s): 0.1166 | Elapsed 10:32:55\n",
      "Epoch: 001/010 | Batch 36651/45709 | Average Loss in last 25 iteration(s): 0.1558 | Elapsed 10:33:22\n",
      "Epoch: 001/010 | Batch 36676/45709 | Average Loss in last 25 iteration(s): 0.1313 | Elapsed 10:33:50\n",
      "Epoch: 001/010 | Batch 36701/45709 | Average Loss in last 25 iteration(s): 0.1648 | Elapsed 10:34:16\n",
      "Epoch: 001/010 | Batch 36726/45709 | Average Loss in last 25 iteration(s): 0.1554 | Elapsed 10:34:41\n",
      "Epoch: 001/010 | Batch 36751/45709 | Average Loss in last 25 iteration(s): 0.1960 | Elapsed 10:35:07\n",
      "Epoch: 001/010 | Batch 36776/45709 | Average Loss in last 25 iteration(s): 0.1440 | Elapsed 10:35:31\n",
      "Epoch: 001/010 | Batch 36801/45709 | Average Loss in last 25 iteration(s): 0.1535 | Elapsed 10:35:56\n",
      "Epoch: 001/010 | Batch 36826/45709 | Average Loss in last 25 iteration(s): 0.1445 | Elapsed 10:36:24\n",
      "Epoch: 001/010 | Batch 36851/45709 | Average Loss in last 25 iteration(s): 0.1323 | Elapsed 10:36:51\n",
      "Epoch: 001/010 | Batch 36876/45709 | Average Loss in last 25 iteration(s): 0.1674 | Elapsed 10:37:17\n",
      "Epoch: 001/010 | Batch 36901/45709 | Average Loss in last 25 iteration(s): 0.1660 | Elapsed 10:37:42\n",
      "Epoch: 001/010 | Batch 36926/45709 | Average Loss in last 25 iteration(s): 0.1574 | Elapsed 10:38:08\n",
      "Epoch: 001/010 | Batch 36951/45709 | Average Loss in last 25 iteration(s): 0.2044 | Elapsed 10:38:30\n",
      "Epoch: 001/010 | Batch 36976/45709 | Average Loss in last 25 iteration(s): 0.1932 | Elapsed 10:38:57\n",
      "Epoch: 001/010 | Batch 37001/45709 | Average Loss in last 25 iteration(s): 0.1679 | Elapsed 10:39:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 37026/45709 | Average Loss in last 25 iteration(s): 0.1518 | Elapsed 10:39:51\n",
      "Epoch: 001/010 | Batch 37051/45709 | Average Loss in last 25 iteration(s): 0.1934 | Elapsed 10:40:17\n",
      "Epoch: 001/010 | Batch 37076/45709 | Average Loss in last 25 iteration(s): 0.1723 | Elapsed 10:40:43\n",
      "Epoch: 001/010 | Batch 37101/45709 | Average Loss in last 25 iteration(s): 0.1602 | Elapsed 10:41:06\n",
      "Epoch: 001/010 | Batch 37126/45709 | Average Loss in last 25 iteration(s): 0.1793 | Elapsed 10:41:35\n",
      "Epoch: 001/010 | Batch 37151/45709 | Average Loss in last 25 iteration(s): 0.1473 | Elapsed 10:42:02\n",
      "Epoch: 001/010 | Batch 37176/45709 | Average Loss in last 25 iteration(s): 0.1674 | Elapsed 10:42:28\n",
      "Epoch: 001/010 | Batch 37201/45709 | Average Loss in last 25 iteration(s): 0.1802 | Elapsed 10:42:53\n",
      "Epoch: 001/010 | Batch 37226/45709 | Average Loss in last 25 iteration(s): 0.1576 | Elapsed 10:43:19\n",
      "Epoch: 001/010 | Batch 37251/45709 | Average Loss in last 25 iteration(s): 0.1437 | Elapsed 10:43:45\n",
      "Epoch: 001/010 | Batch 37276/45709 | Average Loss in last 25 iteration(s): 0.1479 | Elapsed 10:44:08\n",
      "Epoch: 001/010 | Batch 37301/45709 | Average Loss in last 25 iteration(s): 0.1661 | Elapsed 10:44:36\n",
      "Epoch: 001/010 | Batch 37326/45709 | Average Loss in last 25 iteration(s): 0.1649 | Elapsed 10:45:05\n",
      "Epoch: 001/010 | Batch 37351/45709 | Average Loss in last 25 iteration(s): 0.1383 | Elapsed 10:45:29\n",
      "Epoch: 001/010 | Batch 37376/45709 | Average Loss in last 25 iteration(s): 0.1618 | Elapsed 10:45:56\n",
      "Epoch: 001/010 | Batch 37401/45709 | Average Loss in last 25 iteration(s): 0.1730 | Elapsed 10:46:21\n",
      "Epoch: 001/010 | Batch 37426/45709 | Average Loss in last 25 iteration(s): 0.1429 | Elapsed 10:46:44\n",
      "Epoch: 001/010 | Batch 37451/45709 | Average Loss in last 25 iteration(s): 0.1085 | Elapsed 10:47:09\n",
      "Epoch: 001/010 | Batch 37476/45709 | Average Loss in last 25 iteration(s): 0.1414 | Elapsed 10:47:36\n",
      "Epoch: 001/010 | Batch 37501/45709 | Average Loss in last 25 iteration(s): 0.1912 | Elapsed 10:48:02\n",
      "Epoch: 001/010 | Batch 37526/45709 | Average Loss in last 25 iteration(s): 0.1665 | Elapsed 10:48:30\n",
      "Epoch: 001/010 | Batch 37551/45709 | Average Loss in last 25 iteration(s): 0.1252 | Elapsed 10:48:56\n",
      "Epoch: 001/010 | Batch 37576/45709 | Average Loss in last 25 iteration(s): 0.1766 | Elapsed 10:49:18\n",
      "Epoch: 001/010 | Batch 37601/45709 | Average Loss in last 25 iteration(s): 0.1428 | Elapsed 10:49:44\n",
      "Epoch: 001/010 | Batch 37626/45709 | Average Loss in last 25 iteration(s): 0.1359 | Elapsed 10:50:13\n",
      "Epoch: 001/010 | Batch 37651/45709 | Average Loss in last 25 iteration(s): 0.1355 | Elapsed 10:50:38\n",
      "Epoch: 001/010 | Batch 37676/45709 | Average Loss in last 25 iteration(s): 0.1525 | Elapsed 10:51:05\n",
      "Epoch: 001/010 | Batch 37701/45709 | Average Loss in last 25 iteration(s): 0.1772 | Elapsed 10:51:30\n",
      "Epoch: 001/010 | Batch 37726/45709 | Average Loss in last 25 iteration(s): 0.1737 | Elapsed 10:51:54\n",
      "Epoch: 001/010 | Batch 37751/45709 | Average Loss in last 25 iteration(s): 0.1620 | Elapsed 10:52:17\n",
      "Epoch: 001/010 | Batch 37776/45709 | Average Loss in last 25 iteration(s): 0.1812 | Elapsed 10:52:45\n",
      "Epoch: 001/010 | Batch 37801/45709 | Average Loss in last 25 iteration(s): 0.1854 | Elapsed 10:53:12\n",
      "Epoch: 001/010 | Batch 37826/45709 | Average Loss in last 25 iteration(s): 0.1334 | Elapsed 10:53:39\n",
      "Epoch: 001/010 | Batch 37851/45709 | Average Loss in last 25 iteration(s): 0.1626 | Elapsed 10:54:06\n",
      "Epoch: 001/010 | Batch 37876/45709 | Average Loss in last 25 iteration(s): 0.1707 | Elapsed 10:54:32\n",
      "Epoch: 001/010 | Batch 37901/45709 | Average Loss in last 25 iteration(s): 0.1601 | Elapsed 10:54:53\n",
      "Epoch: 001/010 | Batch 37926/45709 | Average Loss in last 25 iteration(s): 0.1483 | Elapsed 10:55:20\n",
      "Epoch: 001/010 | Batch 37951/45709 | Average Loss in last 25 iteration(s): 0.1947 | Elapsed 10:55:48\n",
      "Epoch: 001/010 | Batch 37976/45709 | Average Loss in last 25 iteration(s): 0.1698 | Elapsed 10:56:13\n",
      "Epoch: 001/010 | Batch 38001/45709 | Average Loss in last 25 iteration(s): 0.2099 | Elapsed 10:56:41\n",
      "Epoch: 001/010 | Batch 38026/45709 | Average Loss in last 25 iteration(s): 0.1748 | Elapsed 10:57:06\n",
      "Epoch: 001/010 | Batch 38051/45709 | Average Loss in last 25 iteration(s): 0.1565 | Elapsed 10:57:30\n",
      "Epoch: 001/010 | Batch 38076/45709 | Average Loss in last 25 iteration(s): 0.1411 | Elapsed 10:57:53\n",
      "Epoch: 001/010 | Batch 38101/45709 | Average Loss in last 25 iteration(s): 0.1842 | Elapsed 10:58:22\n",
      "Epoch: 001/010 | Batch 38126/45709 | Average Loss in last 25 iteration(s): 0.1538 | Elapsed 10:58:49\n",
      "Epoch: 001/010 | Batch 38151/45709 | Average Loss in last 25 iteration(s): 0.1381 | Elapsed 10:59:14\n",
      "Epoch: 001/010 | Batch 38176/45709 | Average Loss in last 25 iteration(s): 0.1584 | Elapsed 10:59:40\n",
      "Epoch: 001/010 | Batch 38201/45709 | Average Loss in last 25 iteration(s): 0.2133 | Elapsed 11:00:05\n",
      "Epoch: 001/010 | Batch 38226/45709 | Average Loss in last 25 iteration(s): 0.1272 | Elapsed 11:00:27\n",
      "Epoch: 001/010 | Batch 38251/45709 | Average Loss in last 25 iteration(s): 0.1692 | Elapsed 11:00:55\n",
      "Epoch: 001/010 | Batch 38276/45709 | Average Loss in last 25 iteration(s): 0.1403 | Elapsed 11:01:22\n",
      "Epoch: 001/010 | Batch 38301/45709 | Average Loss in last 25 iteration(s): 0.1468 | Elapsed 11:01:48\n",
      "Epoch: 001/010 | Batch 38326/45709 | Average Loss in last 25 iteration(s): 0.1447 | Elapsed 11:02:13\n",
      "Epoch: 001/010 | Batch 38351/45709 | Average Loss in last 25 iteration(s): 0.1759 | Elapsed 11:02:38\n",
      "Epoch: 001/010 | Batch 38376/45709 | Average Loss in last 25 iteration(s): 0.1548 | Elapsed 11:03:02\n",
      "Epoch: 001/010 | Batch 38401/45709 | Average Loss in last 25 iteration(s): 0.2147 | Elapsed 11:03:25\n",
      "Epoch: 001/010 | Batch 38426/45709 | Average Loss in last 25 iteration(s): 0.1623 | Elapsed 11:03:54\n",
      "Epoch: 001/010 | Batch 38451/45709 | Average Loss in last 25 iteration(s): 0.1792 | Elapsed 11:04:21\n",
      "Epoch: 001/010 | Batch 38476/45709 | Average Loss in last 25 iteration(s): 0.1927 | Elapsed 11:04:48\n",
      "Epoch: 001/010 | Batch 38501/45709 | Average Loss in last 25 iteration(s): 0.1351 | Elapsed 11:05:15\n",
      "Epoch: 001/010 | Batch 38526/45709 | Average Loss in last 25 iteration(s): 0.1373 | Elapsed 11:05:39\n",
      "Epoch: 001/010 | Batch 38551/45709 | Average Loss in last 25 iteration(s): 0.1588 | Elapsed 11:06:02\n",
      "Epoch: 001/010 | Batch 38576/45709 | Average Loss in last 25 iteration(s): 0.1105 | Elapsed 11:06:31\n",
      "Epoch: 001/010 | Batch 38601/45709 | Average Loss in last 25 iteration(s): 0.1400 | Elapsed 11:06:59\n",
      "Epoch: 001/010 | Batch 38626/45709 | Average Loss in last 25 iteration(s): 0.1776 | Elapsed 11:07:26\n",
      "Epoch: 001/010 | Batch 38651/45709 | Average Loss in last 25 iteration(s): 0.1236 | Elapsed 11:07:53\n",
      "Epoch: 001/010 | Batch 38676/45709 | Average Loss in last 25 iteration(s): 0.1615 | Elapsed 11:08:17\n",
      "Epoch: 001/010 | Batch 38701/45709 | Average Loss in last 25 iteration(s): 0.1442 | Elapsed 11:08:40\n",
      "Epoch: 001/010 | Batch 38726/45709 | Average Loss in last 25 iteration(s): 0.2378 | Elapsed 11:09:05\n",
      "Epoch: 001/010 | Batch 38751/45709 | Average Loss in last 25 iteration(s): 0.1667 | Elapsed 11:09:31\n",
      "Epoch: 001/010 | Batch 38776/45709 | Average Loss in last 25 iteration(s): 0.1669 | Elapsed 11:09:59\n",
      "Epoch: 001/010 | Batch 38801/45709 | Average Loss in last 25 iteration(s): 0.1104 | Elapsed 11:10:25\n",
      "Epoch: 001/010 | Batch 38826/45709 | Average Loss in last 25 iteration(s): 0.1408 | Elapsed 11:10:51\n",
      "Epoch: 001/010 | Batch 38851/45709 | Average Loss in last 25 iteration(s): 0.1368 | Elapsed 11:11:16\n",
      "Epoch: 001/010 | Batch 38876/45709 | Average Loss in last 25 iteration(s): 0.1824 | Elapsed 11:11:39\n",
      "Epoch: 001/010 | Batch 38901/45709 | Average Loss in last 25 iteration(s): 0.1499 | Elapsed 11:12:07\n",
      "Epoch: 001/010 | Batch 38926/45709 | Average Loss in last 25 iteration(s): 0.1466 | Elapsed 11:12:36\n",
      "Epoch: 001/010 | Batch 38951/45709 | Average Loss in last 25 iteration(s): 0.1397 | Elapsed 11:13:02\n",
      "Epoch: 001/010 | Batch 38976/45709 | Average Loss in last 25 iteration(s): 0.1521 | Elapsed 11:13:28\n",
      "Epoch: 001/010 | Batch 39001/45709 | Average Loss in last 25 iteration(s): 0.1487 | Elapsed 11:13:54\n",
      "Epoch: 001/010 | Batch 39026/45709 | Average Loss in last 25 iteration(s): 0.1288 | Elapsed 11:14:16\n",
      "Epoch: 001/010 | Batch 39051/45709 | Average Loss in last 25 iteration(s): 0.1141 | Elapsed 11:14:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 39076/45709 | Average Loss in last 25 iteration(s): 0.1578 | Elapsed 11:15:10\n",
      "Epoch: 001/010 | Batch 39101/45709 | Average Loss in last 25 iteration(s): 0.1601 | Elapsed 11:15:37\n",
      "Epoch: 001/010 | Batch 39126/45709 | Average Loss in last 25 iteration(s): 0.2119 | Elapsed 11:16:03\n",
      "Epoch: 001/010 | Batch 39151/45709 | Average Loss in last 25 iteration(s): 0.1809 | Elapsed 11:16:29\n",
      "Epoch: 001/010 | Batch 39176/45709 | Average Loss in last 25 iteration(s): 0.1564 | Elapsed 11:16:52\n",
      "Epoch: 001/010 | Batch 39201/45709 | Average Loss in last 25 iteration(s): 0.1608 | Elapsed 11:17:19\n",
      "Epoch: 001/010 | Batch 39226/45709 | Average Loss in last 25 iteration(s): 0.1146 | Elapsed 11:17:48\n",
      "Epoch: 001/010 | Batch 39251/45709 | Average Loss in last 25 iteration(s): 0.1751 | Elapsed 11:18:15\n",
      "Epoch: 001/010 | Batch 39276/45709 | Average Loss in last 25 iteration(s): 0.1460 | Elapsed 11:18:41\n",
      "Epoch: 001/010 | Batch 39301/45709 | Average Loss in last 25 iteration(s): 0.1780 | Elapsed 11:19:07\n",
      "Epoch: 001/010 | Batch 39326/45709 | Average Loss in last 25 iteration(s): 0.1600 | Elapsed 11:19:29\n",
      "Epoch: 001/010 | Batch 39351/45709 | Average Loss in last 25 iteration(s): 0.1514 | Elapsed 11:19:54\n",
      "Epoch: 001/010 | Batch 39376/45709 | Average Loss in last 25 iteration(s): 0.1694 | Elapsed 11:20:23\n",
      "Epoch: 001/010 | Batch 39401/45709 | Average Loss in last 25 iteration(s): 0.1404 | Elapsed 11:20:49\n",
      "Epoch: 001/010 | Batch 39426/45709 | Average Loss in last 25 iteration(s): 0.1629 | Elapsed 11:21:15\n",
      "Epoch: 001/010 | Batch 39451/45709 | Average Loss in last 25 iteration(s): 0.1700 | Elapsed 11:21:41\n",
      "Epoch: 001/010 | Batch 39476/45709 | Average Loss in last 25 iteration(s): 0.1391 | Elapsed 11:22:06\n",
      "Epoch: 001/010 | Batch 39501/45709 | Average Loss in last 25 iteration(s): 0.1203 | Elapsed 11:22:29\n",
      "Epoch: 001/010 | Batch 39526/45709 | Average Loss in last 25 iteration(s): 0.1355 | Elapsed 11:22:58\n",
      "Epoch: 001/010 | Batch 39551/45709 | Average Loss in last 25 iteration(s): 0.1570 | Elapsed 11:23:26\n",
      "Epoch: 001/010 | Batch 39576/45709 | Average Loss in last 25 iteration(s): 0.1343 | Elapsed 11:23:52\n",
      "Epoch: 001/010 | Batch 39601/45709 | Average Loss in last 25 iteration(s): 0.1442 | Elapsed 11:24:18\n",
      "Epoch: 001/010 | Batch 39626/45709 | Average Loss in last 25 iteration(s): 0.1497 | Elapsed 11:24:43\n",
      "Epoch: 001/010 | Batch 39651/45709 | Average Loss in last 25 iteration(s): 0.1824 | Elapsed 11:25:06\n",
      "Epoch: 001/010 | Batch 39676/45709 | Average Loss in last 25 iteration(s): 0.1782 | Elapsed 11:25:33\n",
      "Epoch: 001/010 | Batch 39701/45709 | Average Loss in last 25 iteration(s): 0.1510 | Elapsed 11:25:58\n",
      "Epoch: 001/010 | Batch 39726/45709 | Average Loss in last 25 iteration(s): 0.1900 | Elapsed 11:26:23\n",
      "Epoch: 001/010 | Batch 39751/45709 | Average Loss in last 25 iteration(s): 0.1096 | Elapsed 11:26:48\n",
      "Epoch: 001/010 | Batch 39776/45709 | Average Loss in last 25 iteration(s): 0.1698 | Elapsed 11:27:14\n",
      "Epoch: 001/010 | Batch 39801/45709 | Average Loss in last 25 iteration(s): 0.1499 | Elapsed 11:27:40\n",
      "Epoch: 001/010 | Batch 39826/45709 | Average Loss in last 25 iteration(s): 0.1865 | Elapsed 11:28:02\n",
      "Epoch: 001/010 | Batch 39851/45709 | Average Loss in last 25 iteration(s): 0.1873 | Elapsed 11:28:30\n",
      "Epoch: 001/010 | Batch 39876/45709 | Average Loss in last 25 iteration(s): 0.1764 | Elapsed 11:28:59\n",
      "Epoch: 001/010 | Batch 39901/45709 | Average Loss in last 25 iteration(s): 0.1513 | Elapsed 11:29:24\n",
      "Epoch: 001/010 | Batch 39926/45709 | Average Loss in last 25 iteration(s): 0.1503 | Elapsed 11:29:50\n",
      "Epoch: 001/010 | Batch 39951/45709 | Average Loss in last 25 iteration(s): 0.1817 | Elapsed 11:30:15\n",
      "Epoch: 001/010 | Batch 39976/45709 | Average Loss in last 25 iteration(s): 0.1687 | Elapsed 11:30:37\n",
      "Epoch: 001/010 | Batch 40001/45709 | Average Loss in last 25 iteration(s): 0.1418 | Elapsed 11:31:06\n",
      "Epoch: 001/010 | Batch 40026/45709 | Average Loss in last 25 iteration(s): 0.1627 | Elapsed 11:31:34\n",
      "Epoch: 001/010 | Batch 40051/45709 | Average Loss in last 25 iteration(s): 0.1938 | Elapsed 11:32:02\n",
      "Epoch: 001/010 | Batch 40076/45709 | Average Loss in last 25 iteration(s): 0.1436 | Elapsed 11:32:28\n",
      "Epoch: 001/010 | Batch 40101/45709 | Average Loss in last 25 iteration(s): 0.1227 | Elapsed 11:32:53\n",
      "Epoch: 001/010 | Batch 40126/45709 | Average Loss in last 25 iteration(s): 0.1782 | Elapsed 11:33:17\n",
      "Epoch: 001/010 | Batch 40151/45709 | Average Loss in last 25 iteration(s): 0.1407 | Elapsed 11:33:44\n",
      "Epoch: 001/010 | Batch 40176/45709 | Average Loss in last 25 iteration(s): 0.1460 | Elapsed 11:34:10\n",
      "Epoch: 001/010 | Batch 40201/45709 | Average Loss in last 25 iteration(s): 0.1516 | Elapsed 11:34:37\n",
      "Epoch: 001/010 | Batch 40226/45709 | Average Loss in last 25 iteration(s): 0.1701 | Elapsed 11:35:02\n",
      "Epoch: 001/010 | Batch 40251/45709 | Average Loss in last 25 iteration(s): 0.1836 | Elapsed 11:35:28\n",
      "Epoch: 001/010 | Batch 40276/45709 | Average Loss in last 25 iteration(s): 0.1704 | Elapsed 11:35:52\n",
      "Epoch: 001/010 | Batch 40301/45709 | Average Loss in last 25 iteration(s): 0.1624 | Elapsed 11:36:15\n",
      "Epoch: 001/010 | Batch 40326/45709 | Average Loss in last 25 iteration(s): 0.1799 | Elapsed 11:36:41\n",
      "Epoch: 001/010 | Batch 40351/45709 | Average Loss in last 25 iteration(s): 0.2040 | Elapsed 11:37:09\n",
      "Epoch: 001/010 | Batch 40376/45709 | Average Loss in last 25 iteration(s): 0.1634 | Elapsed 11:37:32\n",
      "Epoch: 001/010 | Batch 40401/45709 | Average Loss in last 25 iteration(s): 0.1584 | Elapsed 11:37:57\n",
      "Epoch: 001/010 | Batch 40426/45709 | Average Loss in last 25 iteration(s): 0.1532 | Elapsed 11:38:22\n",
      "Epoch: 001/010 | Batch 40451/45709 | Average Loss in last 25 iteration(s): 0.1460 | Elapsed 11:38:47\n",
      "Epoch: 001/010 | Batch 40476/45709 | Average Loss in last 25 iteration(s): 0.1616 | Elapsed 11:39:11\n",
      "Epoch: 001/010 | Batch 40501/45709 | Average Loss in last 25 iteration(s): 0.1289 | Elapsed 11:39:40\n",
      "Epoch: 001/010 | Batch 40526/45709 | Average Loss in last 25 iteration(s): 0.1842 | Elapsed 11:40:07\n",
      "Epoch: 001/010 | Batch 40551/45709 | Average Loss in last 25 iteration(s): 0.1511 | Elapsed 11:40:31\n",
      "Epoch: 001/010 | Batch 40576/45709 | Average Loss in last 25 iteration(s): 0.1206 | Elapsed 11:40:57\n",
      "Epoch: 001/010 | Batch 40601/45709 | Average Loss in last 25 iteration(s): 0.1945 | Elapsed 11:41:24\n",
      "Epoch: 001/010 | Batch 40626/45709 | Average Loss in last 25 iteration(s): 0.1095 | Elapsed 11:41:48\n",
      "Epoch: 001/010 | Batch 40651/45709 | Average Loss in last 25 iteration(s): 0.1126 | Elapsed 11:42:13\n",
      "Epoch: 001/010 | Batch 40676/45709 | Average Loss in last 25 iteration(s): 0.1601 | Elapsed 11:42:40\n",
      "Epoch: 001/010 | Batch 40701/45709 | Average Loss in last 25 iteration(s): 0.1342 | Elapsed 11:43:07\n",
      "Epoch: 001/010 | Batch 40726/45709 | Average Loss in last 25 iteration(s): 0.1362 | Elapsed 11:43:33\n",
      "Epoch: 001/010 | Batch 40751/45709 | Average Loss in last 25 iteration(s): 0.1097 | Elapsed 11:44:00\n",
      "Epoch: 001/010 | Batch 40776/45709 | Average Loss in last 25 iteration(s): 0.1797 | Elapsed 11:44:25\n",
      "Epoch: 001/010 | Batch 40801/45709 | Average Loss in last 25 iteration(s): 0.1314 | Elapsed 11:44:48\n",
      "Epoch: 001/010 | Batch 40826/45709 | Average Loss in last 25 iteration(s): 0.1257 | Elapsed 11:45:18\n",
      "Epoch: 001/010 | Batch 40851/45709 | Average Loss in last 25 iteration(s): 0.1457 | Elapsed 11:45:44\n",
      "Epoch: 001/010 | Batch 40876/45709 | Average Loss in last 25 iteration(s): 0.1346 | Elapsed 11:46:10\n",
      "Epoch: 001/010 | Batch 40901/45709 | Average Loss in last 25 iteration(s): 0.0960 | Elapsed 11:46:34\n",
      "Epoch: 001/010 | Batch 40926/45709 | Average Loss in last 25 iteration(s): 0.1904 | Elapsed 11:47:00\n",
      "Epoch: 001/010 | Batch 40951/45709 | Average Loss in last 25 iteration(s): 0.1440 | Elapsed 11:47:22\n",
      "Epoch: 001/010 | Batch 40976/45709 | Average Loss in last 25 iteration(s): 0.1780 | Elapsed 11:47:46\n",
      "Epoch: 001/010 | Batch 41001/45709 | Average Loss in last 25 iteration(s): 0.1389 | Elapsed 11:48:14\n",
      "Epoch: 001/010 | Batch 41026/45709 | Average Loss in last 25 iteration(s): 0.1302 | Elapsed 11:48:41\n",
      "Epoch: 001/010 | Batch 41051/45709 | Average Loss in last 25 iteration(s): 0.1430 | Elapsed 11:49:07\n",
      "Epoch: 001/010 | Batch 41076/45709 | Average Loss in last 25 iteration(s): 0.1375 | Elapsed 11:49:33\n",
      "Epoch: 001/010 | Batch 41101/45709 | Average Loss in last 25 iteration(s): 0.1720 | Elapsed 11:49:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 41126/45709 | Average Loss in last 25 iteration(s): 0.1198 | Elapsed 11:50:20\n",
      "Epoch: 001/010 | Batch 41151/45709 | Average Loss in last 25 iteration(s): 0.1265 | Elapsed 11:50:48\n",
      "Epoch: 001/010 | Batch 41176/45709 | Average Loss in last 25 iteration(s): 0.1362 | Elapsed 11:51:15\n",
      "Epoch: 001/010 | Batch 41201/45709 | Average Loss in last 25 iteration(s): 0.1732 | Elapsed 11:51:42\n",
      "Epoch: 001/010 | Batch 41226/45709 | Average Loss in last 25 iteration(s): 0.1510 | Elapsed 11:52:08\n",
      "Epoch: 001/010 | Batch 41251/45709 | Average Loss in last 25 iteration(s): 0.1357 | Elapsed 11:52:33\n",
      "Epoch: 001/010 | Batch 41276/45709 | Average Loss in last 25 iteration(s): 0.1660 | Elapsed 11:52:55\n",
      "Epoch: 001/010 | Batch 41301/45709 | Average Loss in last 25 iteration(s): 0.1442 | Elapsed 11:53:22\n",
      "Epoch: 001/010 | Batch 41326/45709 | Average Loss in last 25 iteration(s): 0.1808 | Elapsed 11:53:50\n",
      "Epoch: 001/010 | Batch 41351/45709 | Average Loss in last 25 iteration(s): 0.1464 | Elapsed 11:54:16\n",
      "Epoch: 001/010 | Batch 41376/45709 | Average Loss in last 25 iteration(s): 0.1232 | Elapsed 11:54:42\n",
      "Epoch: 001/010 | Batch 41401/45709 | Average Loss in last 25 iteration(s): 0.1260 | Elapsed 11:55:08\n",
      "Epoch: 001/010 | Batch 41426/45709 | Average Loss in last 25 iteration(s): 0.1445 | Elapsed 11:55:31\n",
      "Epoch: 001/010 | Batch 41451/45709 | Average Loss in last 25 iteration(s): 0.1440 | Elapsed 11:55:56\n",
      "Epoch: 001/010 | Batch 41476/45709 | Average Loss in last 25 iteration(s): 0.1751 | Elapsed 11:56:23\n",
      "Epoch: 001/010 | Batch 41501/45709 | Average Loss in last 25 iteration(s): 0.1655 | Elapsed 11:56:51\n",
      "Epoch: 001/010 | Batch 41526/45709 | Average Loss in last 25 iteration(s): 0.1710 | Elapsed 11:57:16\n",
      "Epoch: 001/010 | Batch 41551/45709 | Average Loss in last 25 iteration(s): 0.1440 | Elapsed 11:57:43\n",
      "Epoch: 001/010 | Batch 41576/45709 | Average Loss in last 25 iteration(s): 0.1498 | Elapsed 11:58:09\n",
      "Epoch: 001/010 | Batch 41601/45709 | Average Loss in last 25 iteration(s): 0.1399 | Elapsed 11:58:32\n",
      "Epoch: 001/010 | Batch 41626/45709 | Average Loss in last 25 iteration(s): 0.1489 | Elapsed 11:58:59\n",
      "Epoch: 001/010 | Batch 41651/45709 | Average Loss in last 25 iteration(s): 0.1493 | Elapsed 11:59:26\n",
      "Epoch: 001/010 | Batch 41676/45709 | Average Loss in last 25 iteration(s): 0.1542 | Elapsed 11:59:51\n",
      "Epoch: 001/010 | Batch 41701/45709 | Average Loss in last 25 iteration(s): 0.1131 | Elapsed 12:00:18\n",
      "Epoch: 001/010 | Batch 41726/45709 | Average Loss in last 25 iteration(s): 0.1581 | Elapsed 12:00:43\n",
      "Epoch: 001/010 | Batch 41751/45709 | Average Loss in last 25 iteration(s): 0.1227 | Elapsed 12:01:05\n",
      "Epoch: 001/010 | Batch 41776/45709 | Average Loss in last 25 iteration(s): 0.2045 | Elapsed 12:01:33\n",
      "Epoch: 001/010 | Batch 41801/45709 | Average Loss in last 25 iteration(s): 0.1563 | Elapsed 12:01:59\n",
      "Epoch: 001/010 | Batch 41826/45709 | Average Loss in last 25 iteration(s): 0.1536 | Elapsed 12:02:26\n",
      "Epoch: 001/010 | Batch 41851/45709 | Average Loss in last 25 iteration(s): 0.1858 | Elapsed 12:02:52\n",
      "Epoch: 001/010 | Batch 41876/45709 | Average Loss in last 25 iteration(s): 0.1295 | Elapsed 12:03:16\n",
      "Epoch: 001/010 | Batch 41901/45709 | Average Loss in last 25 iteration(s): 0.1599 | Elapsed 12:03:42\n",
      "Epoch: 001/010 | Batch 41926/45709 | Average Loss in last 25 iteration(s): 0.1149 | Elapsed 12:04:04\n",
      "Epoch: 001/010 | Batch 41951/45709 | Average Loss in last 25 iteration(s): 0.1607 | Elapsed 12:04:31\n",
      "Epoch: 001/010 | Batch 41976/45709 | Average Loss in last 25 iteration(s): 0.1867 | Elapsed 12:04:58\n",
      "Epoch: 001/010 | Batch 42001/45709 | Average Loss in last 25 iteration(s): 0.1427 | Elapsed 12:05:25\n",
      "Epoch: 001/010 | Batch 42026/45709 | Average Loss in last 25 iteration(s): 0.1363 | Elapsed 12:05:52\n",
      "Epoch: 001/010 | Batch 42051/45709 | Average Loss in last 25 iteration(s): 0.1207 | Elapsed 12:06:18\n",
      "Epoch: 001/010 | Batch 42076/45709 | Average Loss in last 25 iteration(s): 0.1651 | Elapsed 12:06:42\n",
      "Epoch: 001/010 | Batch 42101/45709 | Average Loss in last 25 iteration(s): 0.1345 | Elapsed 12:07:09\n",
      "Epoch: 001/010 | Batch 42126/45709 | Average Loss in last 25 iteration(s): 0.1353 | Elapsed 12:07:36\n",
      "Epoch: 001/010 | Batch 42151/45709 | Average Loss in last 25 iteration(s): 0.1570 | Elapsed 12:08:01\n",
      "Epoch: 001/010 | Batch 42176/45709 | Average Loss in last 25 iteration(s): 0.1161 | Elapsed 12:08:28\n",
      "Epoch: 001/010 | Batch 42201/45709 | Average Loss in last 25 iteration(s): 0.1579 | Elapsed 12:08:53\n",
      "Epoch: 001/010 | Batch 42226/45709 | Average Loss in last 25 iteration(s): 0.1639 | Elapsed 12:09:18\n",
      "Epoch: 001/010 | Batch 42251/45709 | Average Loss in last 25 iteration(s): 0.1673 | Elapsed 12:09:40\n",
      "Epoch: 001/010 | Batch 42276/45709 | Average Loss in last 25 iteration(s): 0.1705 | Elapsed 12:10:09\n",
      "Epoch: 001/010 | Batch 42301/45709 | Average Loss in last 25 iteration(s): 0.1711 | Elapsed 12:10:35\n",
      "Epoch: 001/010 | Batch 42326/45709 | Average Loss in last 25 iteration(s): 0.1624 | Elapsed 12:11:00\n",
      "Epoch: 001/010 | Batch 42351/45709 | Average Loss in last 25 iteration(s): 0.1745 | Elapsed 12:11:27\n",
      "Epoch: 001/010 | Batch 42376/45709 | Average Loss in last 25 iteration(s): 0.1346 | Elapsed 12:11:52\n",
      "Epoch: 001/010 | Batch 42401/45709 | Average Loss in last 25 iteration(s): 0.1635 | Elapsed 12:12:14\n",
      "Epoch: 001/010 | Batch 42426/45709 | Average Loss in last 25 iteration(s): 0.1532 | Elapsed 12:12:40\n",
      "Epoch: 001/010 | Batch 42451/45709 | Average Loss in last 25 iteration(s): 0.1625 | Elapsed 12:13:07\n",
      "Epoch: 001/010 | Batch 42476/45709 | Average Loss in last 25 iteration(s): 0.1211 | Elapsed 12:13:34\n",
      "Epoch: 001/010 | Batch 42501/45709 | Average Loss in last 25 iteration(s): 0.1463 | Elapsed 12:14:01\n",
      "Epoch: 001/010 | Batch 42526/45709 | Average Loss in last 25 iteration(s): 0.1656 | Elapsed 12:14:27\n",
      "Epoch: 001/010 | Batch 42551/45709 | Average Loss in last 25 iteration(s): 0.1353 | Elapsed 12:14:50\n",
      "Epoch: 001/010 | Batch 42576/45709 | Average Loss in last 25 iteration(s): 0.1347 | Elapsed 12:15:14\n",
      "Epoch: 001/010 | Batch 42601/45709 | Average Loss in last 25 iteration(s): 0.1221 | Elapsed 12:15:42\n",
      "Epoch: 001/010 | Batch 42626/45709 | Average Loss in last 25 iteration(s): 0.1546 | Elapsed 12:16:11\n",
      "Epoch: 001/010 | Batch 42651/45709 | Average Loss in last 25 iteration(s): 0.1628 | Elapsed 12:16:36\n",
      "Epoch: 001/010 | Batch 42676/45709 | Average Loss in last 25 iteration(s): 0.1085 | Elapsed 12:17:02\n",
      "Epoch: 001/010 | Batch 42701/45709 | Average Loss in last 25 iteration(s): 0.1706 | Elapsed 12:17:27\n",
      "Epoch: 001/010 | Batch 42726/45709 | Average Loss in last 25 iteration(s): 0.1560 | Elapsed 12:17:50\n",
      "Epoch: 001/010 | Batch 42751/45709 | Average Loss in last 25 iteration(s): 0.1621 | Elapsed 12:18:15\n",
      "Epoch: 001/010 | Batch 42776/45709 | Average Loss in last 25 iteration(s): 0.1636 | Elapsed 12:18:44\n",
      "Epoch: 001/010 | Batch 42801/45709 | Average Loss in last 25 iteration(s): 0.1755 | Elapsed 12:19:10\n",
      "Epoch: 001/010 | Batch 42826/45709 | Average Loss in last 25 iteration(s): 0.1829 | Elapsed 12:19:38\n",
      "Epoch: 001/010 | Batch 42851/45709 | Average Loss in last 25 iteration(s): 0.1296 | Elapsed 12:20:03\n",
      "Epoch: 001/010 | Batch 42876/45709 | Average Loss in last 25 iteration(s): 0.1375 | Elapsed 12:20:26\n",
      "Epoch: 001/010 | Batch 42901/45709 | Average Loss in last 25 iteration(s): 0.1477 | Elapsed 12:20:54\n",
      "Epoch: 001/010 | Batch 42926/45709 | Average Loss in last 25 iteration(s): 0.1806 | Elapsed 12:21:23\n",
      "Epoch: 001/010 | Batch 42951/45709 | Average Loss in last 25 iteration(s): 0.1456 | Elapsed 12:21:49\n",
      "Epoch: 001/010 | Batch 42976/45709 | Average Loss in last 25 iteration(s): 0.1852 | Elapsed 12:22:15\n",
      "Epoch: 001/010 | Batch 43001/45709 | Average Loss in last 25 iteration(s): 0.1967 | Elapsed 12:22:40\n",
      "Epoch: 001/010 | Batch 43026/45709 | Average Loss in last 25 iteration(s): 0.1234 | Elapsed 12:23:04\n",
      "Epoch: 001/010 | Batch 43051/45709 | Average Loss in last 25 iteration(s): 0.1185 | Elapsed 12:23:30\n",
      "Epoch: 001/010 | Batch 43076/45709 | Average Loss in last 25 iteration(s): 0.0847 | Elapsed 12:23:58\n",
      "Epoch: 001/010 | Batch 43101/45709 | Average Loss in last 25 iteration(s): 0.1412 | Elapsed 12:24:24\n",
      "Epoch: 001/010 | Batch 43126/45709 | Average Loss in last 25 iteration(s): 0.1806 | Elapsed 12:24:50\n",
      "Epoch: 001/010 | Batch 43151/45709 | Average Loss in last 25 iteration(s): 0.1079 | Elapsed 12:25:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 43176/45709 | Average Loss in last 25 iteration(s): 0.1845 | Elapsed 12:25:41\n",
      "Epoch: 001/010 | Batch 43201/45709 | Average Loss in last 25 iteration(s): 0.1341 | Elapsed 12:26:04\n",
      "Epoch: 001/010 | Batch 43226/45709 | Average Loss in last 25 iteration(s): 0.1497 | Elapsed 12:26:31\n",
      "Epoch: 001/010 | Batch 43251/45709 | Average Loss in last 25 iteration(s): 0.1278 | Elapsed 12:26:58\n",
      "Epoch: 001/010 | Batch 43276/45709 | Average Loss in last 25 iteration(s): 0.1123 | Elapsed 12:27:23\n",
      "Epoch: 001/010 | Batch 43301/45709 | Average Loss in last 25 iteration(s): 0.1663 | Elapsed 12:27:51\n",
      "Epoch: 001/010 | Batch 43326/45709 | Average Loss in last 25 iteration(s): 0.1418 | Elapsed 12:28:18\n",
      "Epoch: 001/010 | Batch 43351/45709 | Average Loss in last 25 iteration(s): 0.1258 | Elapsed 12:28:40\n",
      "Epoch: 001/010 | Batch 43376/45709 | Average Loss in last 25 iteration(s): 0.1228 | Elapsed 12:29:07\n",
      "Epoch: 001/010 | Batch 43401/45709 | Average Loss in last 25 iteration(s): 0.1132 | Elapsed 12:29:35\n",
      "Epoch: 001/010 | Batch 43426/45709 | Average Loss in last 25 iteration(s): 0.1407 | Elapsed 12:30:02\n",
      "Epoch: 001/010 | Batch 43451/45709 | Average Loss in last 25 iteration(s): 0.1204 | Elapsed 12:30:27\n",
      "Epoch: 001/010 | Batch 43476/45709 | Average Loss in last 25 iteration(s): 0.1449 | Elapsed 12:30:54\n",
      "Epoch: 001/010 | Batch 43501/45709 | Average Loss in last 25 iteration(s): 0.1613 | Elapsed 12:31:18\n",
      "Epoch: 001/010 | Batch 43526/45709 | Average Loss in last 25 iteration(s): 0.1686 | Elapsed 12:31:44\n",
      "Epoch: 001/010 | Batch 43551/45709 | Average Loss in last 25 iteration(s): 0.1581 | Elapsed 12:32:11\n",
      "Epoch: 001/010 | Batch 43576/45709 | Average Loss in last 25 iteration(s): 0.1111 | Elapsed 12:32:37\n",
      "Epoch: 001/010 | Batch 43601/45709 | Average Loss in last 25 iteration(s): 0.1261 | Elapsed 12:33:05\n",
      "Epoch: 001/010 | Batch 43626/45709 | Average Loss in last 25 iteration(s): 0.1237 | Elapsed 12:33:30\n",
      "Epoch: 001/010 | Batch 43651/45709 | Average Loss in last 25 iteration(s): 0.1858 | Elapsed 12:33:56\n",
      "Epoch: 001/010 | Batch 43676/45709 | Average Loss in last 25 iteration(s): 0.1741 | Elapsed 12:34:19\n",
      "Epoch: 001/010 | Batch 43701/45709 | Average Loss in last 25 iteration(s): 0.1485 | Elapsed 12:34:47\n",
      "Epoch: 001/010 | Batch 43726/45709 | Average Loss in last 25 iteration(s): 0.1612 | Elapsed 12:35:13\n",
      "Epoch: 001/010 | Batch 43751/45709 | Average Loss in last 25 iteration(s): 0.1355 | Elapsed 12:35:40\n",
      "Epoch: 001/010 | Batch 43776/45709 | Average Loss in last 25 iteration(s): 0.1387 | Elapsed 12:36:06\n",
      "Epoch: 001/010 | Batch 43801/45709 | Average Loss in last 25 iteration(s): 0.1836 | Elapsed 12:36:33\n",
      "Epoch: 001/010 | Batch 43826/45709 | Average Loss in last 25 iteration(s): 0.1401 | Elapsed 12:36:54\n",
      "Epoch: 001/010 | Batch 43851/45709 | Average Loss in last 25 iteration(s): 0.1408 | Elapsed 12:37:18\n",
      "Epoch: 001/010 | Batch 43876/45709 | Average Loss in last 25 iteration(s): 0.0860 | Elapsed 12:37:46\n",
      "Epoch: 001/010 | Batch 43901/45709 | Average Loss in last 25 iteration(s): 0.1874 | Elapsed 12:38:14\n",
      "Epoch: 001/010 | Batch 43926/45709 | Average Loss in last 25 iteration(s): 0.1916 | Elapsed 12:38:41\n",
      "Epoch: 001/010 | Batch 43951/45709 | Average Loss in last 25 iteration(s): 0.1688 | Elapsed 12:39:07\n",
      "Epoch: 001/010 | Batch 43976/45709 | Average Loss in last 25 iteration(s): 0.1527 | Elapsed 12:39:31\n",
      "Epoch: 001/010 | Batch 44001/45709 | Average Loss in last 25 iteration(s): 0.1406 | Elapsed 12:39:54\n",
      "Epoch: 001/010 | Batch 44026/45709 | Average Loss in last 25 iteration(s): 0.1658 | Elapsed 12:40:23\n",
      "Epoch: 001/010 | Batch 44051/45709 | Average Loss in last 25 iteration(s): 0.1636 | Elapsed 12:40:49\n",
      "Epoch: 001/010 | Batch 44076/45709 | Average Loss in last 25 iteration(s): 0.1322 | Elapsed 12:41:13\n",
      "Epoch: 001/010 | Batch 44101/45709 | Average Loss in last 25 iteration(s): 0.1604 | Elapsed 12:41:41\n",
      "Epoch: 001/010 | Batch 44126/45709 | Average Loss in last 25 iteration(s): 0.1561 | Elapsed 12:42:06\n",
      "Epoch: 001/010 | Batch 44151/45709 | Average Loss in last 25 iteration(s): 0.1426 | Elapsed 12:42:29\n",
      "Epoch: 001/010 | Batch 44176/45709 | Average Loss in last 25 iteration(s): 0.1338 | Elapsed 12:42:54\n",
      "Epoch: 001/010 | Batch 44201/45709 | Average Loss in last 25 iteration(s): 0.1657 | Elapsed 12:43:23\n",
      "Epoch: 001/010 | Batch 44226/45709 | Average Loss in last 25 iteration(s): 0.1671 | Elapsed 12:43:48\n",
      "Epoch: 001/010 | Batch 44251/45709 | Average Loss in last 25 iteration(s): 0.1555 | Elapsed 12:44:14\n",
      "Epoch: 001/010 | Batch 44276/45709 | Average Loss in last 25 iteration(s): 0.1416 | Elapsed 12:44:40\n",
      "Epoch: 001/010 | Batch 44301/45709 | Average Loss in last 25 iteration(s): 0.1767 | Elapsed 12:45:04\n",
      "Epoch: 001/010 | Batch 44326/45709 | Average Loss in last 25 iteration(s): 0.1601 | Elapsed 12:45:30\n",
      "Epoch: 001/010 | Batch 44351/45709 | Average Loss in last 25 iteration(s): 0.1246 | Elapsed 12:45:56\n",
      "Epoch: 001/010 | Batch 44376/45709 | Average Loss in last 25 iteration(s): 0.1942 | Elapsed 12:46:22\n",
      "Epoch: 001/010 | Batch 44401/45709 | Average Loss in last 25 iteration(s): 0.1460 | Elapsed 12:46:49\n",
      "Epoch: 001/010 | Batch 44426/45709 | Average Loss in last 25 iteration(s): 0.1255 | Elapsed 12:47:15\n",
      "Epoch: 001/010 | Batch 44451/45709 | Average Loss in last 25 iteration(s): 0.1317 | Elapsed 12:47:40\n",
      "Epoch: 001/010 | Batch 44476/45709 | Average Loss in last 25 iteration(s): 0.1572 | Elapsed 12:48:02\n",
      "Epoch: 001/010 | Batch 44501/45709 | Average Loss in last 25 iteration(s): 0.1322 | Elapsed 12:48:30\n",
      "Epoch: 001/010 | Batch 44526/45709 | Average Loss in last 25 iteration(s): 0.1303 | Elapsed 12:48:57\n",
      "Epoch: 001/010 | Batch 44551/45709 | Average Loss in last 25 iteration(s): 0.1663 | Elapsed 12:49:25\n",
      "Epoch: 001/010 | Batch 44576/45709 | Average Loss in last 25 iteration(s): 0.1411 | Elapsed 12:49:49\n",
      "Epoch: 001/010 | Batch 44601/45709 | Average Loss in last 25 iteration(s): 0.1624 | Elapsed 12:50:16\n",
      "Epoch: 001/010 | Batch 44626/45709 | Average Loss in last 25 iteration(s): 0.1503 | Elapsed 12:50:38\n",
      "Epoch: 001/010 | Batch 44651/45709 | Average Loss in last 25 iteration(s): 0.1548 | Elapsed 12:51:05\n",
      "Epoch: 001/010 | Batch 44676/45709 | Average Loss in last 25 iteration(s): 0.1179 | Elapsed 12:51:32\n",
      "Epoch: 001/010 | Batch 44701/45709 | Average Loss in last 25 iteration(s): 0.1620 | Elapsed 12:52:00\n",
      "Epoch: 001/010 | Batch 44726/45709 | Average Loss in last 25 iteration(s): 0.1650 | Elapsed 12:52:25\n",
      "Epoch: 001/010 | Batch 44751/45709 | Average Loss in last 25 iteration(s): 0.1501 | Elapsed 12:52:50\n",
      "Epoch: 001/010 | Batch 44776/45709 | Average Loss in last 25 iteration(s): 0.1188 | Elapsed 12:53:15\n",
      "Epoch: 001/010 | Batch 44801/45709 | Average Loss in last 25 iteration(s): 0.1976 | Elapsed 12:53:40\n",
      "Epoch: 001/010 | Batch 44826/45709 | Average Loss in last 25 iteration(s): 0.1544 | Elapsed 12:54:08\n",
      "Epoch: 001/010 | Batch 44851/45709 | Average Loss in last 25 iteration(s): 0.1802 | Elapsed 12:54:33\n",
      "Epoch: 001/010 | Batch 44876/45709 | Average Loss in last 25 iteration(s): 0.1343 | Elapsed 12:55:00\n",
      "Epoch: 001/010 | Batch 44901/45709 | Average Loss in last 25 iteration(s): 0.1550 | Elapsed 12:55:25\n",
      "Epoch: 001/010 | Batch 44926/45709 | Average Loss in last 25 iteration(s): 0.1378 | Elapsed 12:55:51\n",
      "Epoch: 001/010 | Batch 44951/45709 | Average Loss in last 25 iteration(s): 0.1656 | Elapsed 12:56:14\n",
      "Epoch: 001/010 | Batch 44976/45709 | Average Loss in last 25 iteration(s): 0.1935 | Elapsed 12:56:42\n",
      "Epoch: 001/010 | Batch 45001/45709 | Average Loss in last 25 iteration(s): 0.1096 | Elapsed 12:57:09\n",
      "Epoch: 001/010 | Batch 45026/45709 | Average Loss in last 25 iteration(s): 0.1378 | Elapsed 12:57:34\n",
      "Epoch: 001/010 | Batch 45051/45709 | Average Loss in last 25 iteration(s): 0.1403 | Elapsed 12:58:00\n",
      "Epoch: 001/010 | Batch 45076/45709 | Average Loss in last 25 iteration(s): 0.1112 | Elapsed 12:58:24\n",
      "Epoch: 001/010 | Batch 45101/45709 | Average Loss in last 25 iteration(s): 0.1672 | Elapsed 12:58:47\n",
      "Epoch: 001/010 | Batch 45126/45709 | Average Loss in last 25 iteration(s): 0.1387 | Elapsed 12:59:14\n",
      "Epoch: 001/010 | Batch 45151/45709 | Average Loss in last 25 iteration(s): 0.1343 | Elapsed 12:59:40\n",
      "Epoch: 001/010 | Batch 45176/45709 | Average Loss in last 25 iteration(s): 0.1866 | Elapsed 13:00:07\n",
      "Epoch: 001/010 | Batch 45201/45709 | Average Loss in last 25 iteration(s): 0.1278 | Elapsed 13:00:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 45226/45709 | Average Loss in last 25 iteration(s): 0.2094 | Elapsed 13:01:00\n",
      "Epoch: 001/010 | Batch 45251/45709 | Average Loss in last 25 iteration(s): 0.1379 | Elapsed 13:01:24\n",
      "Epoch: 001/010 | Batch 45276/45709 | Average Loss in last 25 iteration(s): 0.1610 | Elapsed 13:01:47\n",
      "Epoch: 001/010 | Batch 45301/45709 | Average Loss in last 25 iteration(s): 0.1300 | Elapsed 13:02:17\n",
      "Epoch: 001/010 | Batch 45326/45709 | Average Loss in last 25 iteration(s): 0.1226 | Elapsed 13:02:43\n",
      "Epoch: 001/010 | Batch 45351/45709 | Average Loss in last 25 iteration(s): 0.1409 | Elapsed 13:03:08\n",
      "Epoch: 001/010 | Batch 45376/45709 | Average Loss in last 25 iteration(s): 0.1450 | Elapsed 13:03:34\n",
      "Epoch: 001/010 | Batch 45401/45709 | Average Loss in last 25 iteration(s): 0.1551 | Elapsed 13:03:59\n",
      "Epoch: 001/010 | Batch 45426/45709 | Average Loss in last 25 iteration(s): 0.1548 | Elapsed 13:04:22\n",
      "Epoch: 001/010 | Batch 45451/45709 | Average Loss in last 25 iteration(s): 0.1353 | Elapsed 13:04:49\n",
      "Epoch: 001/010 | Batch 45476/45709 | Average Loss in last 25 iteration(s): 0.1598 | Elapsed 13:05:15\n",
      "Epoch: 001/010 | Batch 45501/45709 | Average Loss in last 25 iteration(s): 0.1781 | Elapsed 13:05:42\n",
      "Epoch: 001/010 | Batch 45526/45709 | Average Loss in last 25 iteration(s): 0.1254 | Elapsed 13:06:08\n",
      "Epoch: 001/010 | Batch 45551/45709 | Average Loss in last 25 iteration(s): 0.1286 | Elapsed 13:06:33\n",
      "Epoch: 001/010 | Batch 45576/45709 | Average Loss in last 25 iteration(s): 0.1572 | Elapsed 13:06:57\n",
      "Epoch: 001/010 | Batch 45601/45709 | Average Loss in last 25 iteration(s): 0.1326 | Elapsed 13:07:21\n",
      "Epoch: 001/010 | Batch 45626/45709 | Average Loss in last 25 iteration(s): 0.1410 | Elapsed 13:07:49\n",
      "Epoch: 001/010 | Batch 45651/45709 | Average Loss in last 25 iteration(s): 0.1458 | Elapsed 13:08:16\n",
      "Epoch: 001/010 | Batch 45676/45709 | Average Loss in last 25 iteration(s): 0.1659 | Elapsed 13:08:43\n",
      "Epoch: 001/010 | Batch 45701/45709 | Average Loss in last 25 iteration(s): 0.1303 | Elapsed 13:09:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 45709/45709 [2:06:31<00:00,  6.03it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 95.91%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 2/5079 [00:00<07:40, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.12423044380968974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [14:03<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 94.69849395751953\n",
      "\n",
      "===== Epoch 2 / 10 =====\n",
      "Training ...\n",
      "Epoch: 002/010 | Batch 001/45709 | Average Loss in last 1 iteration(s): 0.0490 | Elapsed 0:00:01\n",
      "Epoch: 002/010 | Batch 026/45709 | Average Loss in last 25 iteration(s): 0.1369 | Elapsed 0:00:24\n",
      "Epoch: 002/010 | Batch 051/45709 | Average Loss in last 25 iteration(s): 0.1145 | Elapsed 0:00:50\n",
      "Epoch: 002/010 | Batch 076/45709 | Average Loss in last 25 iteration(s): 0.0979 | Elapsed 0:01:15\n",
      "Epoch: 002/010 | Batch 101/45709 | Average Loss in last 25 iteration(s): 0.1035 | Elapsed 0:01:43\n",
      "Epoch: 002/010 | Batch 126/45709 | Average Loss in last 25 iteration(s): 0.1414 | Elapsed 0:02:10\n",
      "Epoch: 002/010 | Batch 151/45709 | Average Loss in last 25 iteration(s): 0.1076 | Elapsed 0:02:37\n",
      "Epoch: 002/010 | Batch 176/45709 | Average Loss in last 25 iteration(s): 0.1016 | Elapsed 0:03:00\n",
      "Epoch: 002/010 | Batch 201/45709 | Average Loss in last 25 iteration(s): 0.1229 | Elapsed 0:03:25\n",
      "Epoch: 002/010 | Batch 226/45709 | Average Loss in last 25 iteration(s): 0.1369 | Elapsed 0:03:53\n",
      "Epoch: 002/010 | Batch 251/45709 | Average Loss in last 25 iteration(s): 0.0978 | Elapsed 0:04:19\n",
      "Epoch: 002/010 | Batch 276/45709 | Average Loss in last 25 iteration(s): 0.0923 | Elapsed 0:04:50\n",
      "Epoch: 002/010 | Batch 301/45709 | Average Loss in last 25 iteration(s): 0.1280 | Elapsed 0:05:15\n",
      "Epoch: 002/010 | Batch 326/45709 | Average Loss in last 25 iteration(s): 0.1531 | Elapsed 0:05:39\n",
      "Epoch: 002/010 | Batch 351/45709 | Average Loss in last 25 iteration(s): 0.1070 | Elapsed 0:06:05\n",
      "Epoch: 002/010 | Batch 376/45709 | Average Loss in last 25 iteration(s): 0.0761 | Elapsed 0:06:35\n",
      "Epoch: 002/010 | Batch 401/45709 | Average Loss in last 25 iteration(s): 0.0906 | Elapsed 0:07:04\n",
      "Epoch: 002/010 | Batch 426/45709 | Average Loss in last 25 iteration(s): 0.1215 | Elapsed 0:07:28\n",
      "Epoch: 002/010 | Batch 451/45709 | Average Loss in last 25 iteration(s): 0.0933 | Elapsed 0:07:55\n",
      "Epoch: 002/010 | Batch 476/45709 | Average Loss in last 25 iteration(s): 0.1110 | Elapsed 0:08:19\n",
      "Epoch: 002/010 | Batch 501/45709 | Average Loss in last 25 iteration(s): 0.1286 | Elapsed 0:08:42\n",
      "Epoch: 002/010 | Batch 526/45709 | Average Loss in last 25 iteration(s): 0.1186 | Elapsed 0:09:07\n",
      "Epoch: 002/010 | Batch 551/45709 | Average Loss in last 25 iteration(s): 0.1298 | Elapsed 0:09:35\n",
      "Epoch: 002/010 | Batch 576/45709 | Average Loss in last 25 iteration(s): 0.1197 | Elapsed 0:10:00\n",
      "Epoch: 002/010 | Batch 601/45709 | Average Loss in last 25 iteration(s): 0.1221 | Elapsed 0:10:26\n",
      "Epoch: 002/010 | Batch 626/45709 | Average Loss in last 25 iteration(s): 0.0803 | Elapsed 0:10:52\n",
      "Epoch: 002/010 | Batch 651/45709 | Average Loss in last 25 iteration(s): 0.1103 | Elapsed 0:11:16\n",
      "Epoch: 002/010 | Batch 676/45709 | Average Loss in last 25 iteration(s): 0.1075 | Elapsed 0:11:40\n",
      "Epoch: 002/010 | Batch 701/45709 | Average Loss in last 25 iteration(s): 0.1104 | Elapsed 0:12:07\n",
      "Epoch: 002/010 | Batch 726/45709 | Average Loss in last 25 iteration(s): 0.1093 | Elapsed 0:12:33\n",
      "Epoch: 002/010 | Batch 751/45709 | Average Loss in last 25 iteration(s): 0.1393 | Elapsed 0:13:01\n",
      "Epoch: 002/010 | Batch 776/45709 | Average Loss in last 25 iteration(s): 0.1003 | Elapsed 0:13:29\n",
      "Epoch: 002/010 | Batch 801/45709 | Average Loss in last 25 iteration(s): 0.1199 | Elapsed 0:13:54\n",
      "Epoch: 002/010 | Batch 826/45709 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 0:14:18\n",
      "Epoch: 002/010 | Batch 851/45709 | Average Loss in last 25 iteration(s): 0.1325 | Elapsed 0:14:47\n",
      "Epoch: 002/010 | Batch 876/45709 | Average Loss in last 25 iteration(s): 0.1450 | Elapsed 0:15:15\n",
      "Epoch: 002/010 | Batch 901/45709 | Average Loss in last 25 iteration(s): 0.1267 | Elapsed 0:15:41\n",
      "Epoch: 002/010 | Batch 926/45709 | Average Loss in last 25 iteration(s): 0.0998 | Elapsed 0:16:09\n",
      "Epoch: 002/010 | Batch 951/45709 | Average Loss in last 25 iteration(s): 0.0999 | Elapsed 0:16:35\n",
      "Epoch: 002/010 | Batch 976/45709 | Average Loss in last 25 iteration(s): 0.0535 | Elapsed 0:16:59\n",
      "Epoch: 002/010 | Batch 1001/45709 | Average Loss in last 25 iteration(s): 0.1351 | Elapsed 0:17:27\n",
      "Epoch: 002/010 | Batch 1026/45709 | Average Loss in last 25 iteration(s): 0.1062 | Elapsed 0:17:55\n",
      "Epoch: 002/010 | Batch 1051/45709 | Average Loss in last 25 iteration(s): 0.0609 | Elapsed 0:18:21\n",
      "Epoch: 002/010 | Batch 1076/45709 | Average Loss in last 25 iteration(s): 0.1278 | Elapsed 0:18:49\n",
      "Epoch: 002/010 | Batch 1101/45709 | Average Loss in last 25 iteration(s): 0.1099 | Elapsed 0:19:14\n",
      "Epoch: 002/010 | Batch 1126/45709 | Average Loss in last 25 iteration(s): 0.1344 | Elapsed 0:19:37\n",
      "Epoch: 002/010 | Batch 1151/45709 | Average Loss in last 25 iteration(s): 0.1520 | Elapsed 0:20:03\n",
      "Epoch: 002/010 | Batch 1176/45709 | Average Loss in last 25 iteration(s): 0.1139 | Elapsed 0:20:31\n",
      "Epoch: 002/010 | Batch 1201/45709 | Average Loss in last 25 iteration(s): 0.1593 | Elapsed 0:20:57\n",
      "Epoch: 002/010 | Batch 1226/45709 | Average Loss in last 25 iteration(s): 0.0950 | Elapsed 0:21:26\n",
      "Epoch: 002/010 | Batch 1251/45709 | Average Loss in last 25 iteration(s): 0.1408 | Elapsed 0:21:51\n",
      "Epoch: 002/010 | Batch 1276/45709 | Average Loss in last 25 iteration(s): 0.1211 | Elapsed 0:22:14\n",
      "Epoch: 002/010 | Batch 1301/45709 | Average Loss in last 25 iteration(s): 0.0833 | Elapsed 0:22:39\n",
      "Epoch: 002/010 | Batch 1326/45709 | Average Loss in last 25 iteration(s): 0.1170 | Elapsed 0:23:06\n",
      "Epoch: 002/010 | Batch 1351/45709 | Average Loss in last 25 iteration(s): 0.1125 | Elapsed 0:23:34\n",
      "Epoch: 002/010 | Batch 1376/45709 | Average Loss in last 25 iteration(s): 0.1054 | Elapsed 0:24:00\n",
      "Epoch: 002/010 | Batch 1401/45709 | Average Loss in last 25 iteration(s): 0.1172 | Elapsed 0:24:27\n",
      "Epoch: 002/010 | Batch 1426/45709 | Average Loss in last 25 iteration(s): 0.1457 | Elapsed 0:24:53\n",
      "Epoch: 002/010 | Batch 1451/45709 | Average Loss in last 25 iteration(s): 0.0882 | Elapsed 0:25:17\n",
      "Epoch: 002/010 | Batch 1476/45709 | Average Loss in last 25 iteration(s): 0.0801 | Elapsed 0:25:44\n",
      "Epoch: 002/010 | Batch 1501/45709 | Average Loss in last 25 iteration(s): 0.0873 | Elapsed 0:26:11\n",
      "Epoch: 002/010 | Batch 1526/45709 | Average Loss in last 25 iteration(s): 0.1047 | Elapsed 0:26:38\n",
      "Epoch: 002/010 | Batch 1551/45709 | Average Loss in last 25 iteration(s): 0.1071 | Elapsed 0:27:06\n",
      "Epoch: 002/010 | Batch 1576/45709 | Average Loss in last 25 iteration(s): 0.1231 | Elapsed 0:27:32\n",
      "Epoch: 002/010 | Batch 1601/45709 | Average Loss in last 25 iteration(s): 0.1294 | Elapsed 0:27:56\n",
      "Epoch: 002/010 | Batch 1626/45709 | Average Loss in last 25 iteration(s): 0.0982 | Elapsed 0:28:23\n",
      "Epoch: 002/010 | Batch 1651/45709 | Average Loss in last 25 iteration(s): 0.1010 | Elapsed 0:28:51\n",
      "Epoch: 002/010 | Batch 1676/45709 | Average Loss in last 25 iteration(s): 0.1171 | Elapsed 0:29:19\n",
      "Epoch: 002/010 | Batch 1701/45709 | Average Loss in last 25 iteration(s): 0.1689 | Elapsed 0:29:46\n",
      "Epoch: 002/010 | Batch 1726/45709 | Average Loss in last 25 iteration(s): 0.1100 | Elapsed 0:30:13\n",
      "Epoch: 002/010 | Batch 1751/45709 | Average Loss in last 25 iteration(s): 0.1708 | Elapsed 0:30:34\n",
      "Epoch: 002/010 | Batch 1776/45709 | Average Loss in last 25 iteration(s): 0.1218 | Elapsed 0:31:02\n",
      "Epoch: 002/010 | Batch 1801/45709 | Average Loss in last 25 iteration(s): 0.1216 | Elapsed 0:31:30\n",
      "Epoch: 002/010 | Batch 1826/45709 | Average Loss in last 25 iteration(s): 0.1039 | Elapsed 0:31:58\n",
      "Epoch: 002/010 | Batch 1851/45709 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 0:32:23\n",
      "Epoch: 002/010 | Batch 1876/45709 | Average Loss in last 25 iteration(s): 0.0896 | Elapsed 0:32:50\n",
      "Epoch: 002/010 | Batch 1901/45709 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 0:33:14\n",
      "Epoch: 002/010 | Batch 1926/45709 | Average Loss in last 25 iteration(s): 0.0749 | Elapsed 0:33:40\n",
      "Epoch: 002/010 | Batch 1951/45709 | Average Loss in last 25 iteration(s): 0.1205 | Elapsed 0:34:08\n",
      "Epoch: 002/010 | Batch 1976/45709 | Average Loss in last 25 iteration(s): 0.1111 | Elapsed 0:34:35\n",
      "Epoch: 002/010 | Batch 2001/45709 | Average Loss in last 25 iteration(s): 0.1241 | Elapsed 0:35:03\n",
      "Epoch: 002/010 | Batch 2026/45709 | Average Loss in last 25 iteration(s): 0.1383 | Elapsed 0:35:29\n",
      "Epoch: 002/010 | Batch 2051/45709 | Average Loss in last 25 iteration(s): 0.1066 | Elapsed 0:35:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 2076/45709 | Average Loss in last 25 iteration(s): 0.1437 | Elapsed 0:36:19\n",
      "Epoch: 002/010 | Batch 2101/45709 | Average Loss in last 25 iteration(s): 0.1074 | Elapsed 0:36:48\n",
      "Epoch: 002/010 | Batch 2126/45709 | Average Loss in last 25 iteration(s): 0.1132 | Elapsed 0:37:15\n",
      "Epoch: 002/010 | Batch 2151/45709 | Average Loss in last 25 iteration(s): 0.1161 | Elapsed 0:37:43\n",
      "Epoch: 002/010 | Batch 2176/45709 | Average Loss in last 25 iteration(s): 0.1250 | Elapsed 0:38:10\n",
      "Epoch: 002/010 | Batch 2201/45709 | Average Loss in last 25 iteration(s): 0.0974 | Elapsed 0:38:36\n",
      "Epoch: 002/010 | Batch 2226/45709 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 0:38:58\n",
      "Epoch: 002/010 | Batch 2251/45709 | Average Loss in last 25 iteration(s): 0.0970 | Elapsed 0:39:27\n",
      "Epoch: 002/010 | Batch 2276/45709 | Average Loss in last 25 iteration(s): 0.1217 | Elapsed 0:39:53\n",
      "Epoch: 002/010 | Batch 2301/45709 | Average Loss in last 25 iteration(s): 0.0987 | Elapsed 0:40:19\n",
      "Epoch: 002/010 | Batch 2326/45709 | Average Loss in last 25 iteration(s): 0.1340 | Elapsed 0:40:43\n",
      "Epoch: 002/010 | Batch 2351/45709 | Average Loss in last 25 iteration(s): 0.1176 | Elapsed 0:41:10\n",
      "Epoch: 002/010 | Batch 2376/45709 | Average Loss in last 25 iteration(s): 0.1463 | Elapsed 0:41:35\n",
      "Epoch: 002/010 | Batch 2401/45709 | Average Loss in last 25 iteration(s): 0.1104 | Elapsed 0:41:58\n",
      "Epoch: 002/010 | Batch 2426/45709 | Average Loss in last 25 iteration(s): 0.0874 | Elapsed 0:42:22\n",
      "Epoch: 002/010 | Batch 2451/45709 | Average Loss in last 25 iteration(s): 0.0711 | Elapsed 0:42:49\n",
      "Epoch: 002/010 | Batch 2476/45709 | Average Loss in last 25 iteration(s): 0.1077 | Elapsed 0:43:16\n",
      "Epoch: 002/010 | Batch 2501/45709 | Average Loss in last 25 iteration(s): 0.1057 | Elapsed 0:43:41\n",
      "Epoch: 002/010 | Batch 2526/45709 | Average Loss in last 25 iteration(s): 0.1105 | Elapsed 0:44:08\n",
      "Epoch: 002/010 | Batch 2551/45709 | Average Loss in last 25 iteration(s): 0.0583 | Elapsed 0:44:33\n",
      "Epoch: 002/010 | Batch 2576/45709 | Average Loss in last 25 iteration(s): 0.1154 | Elapsed 0:44:58\n",
      "Epoch: 002/010 | Batch 2601/45709 | Average Loss in last 25 iteration(s): 0.1419 | Elapsed 0:45:20\n",
      "Epoch: 002/010 | Batch 2626/45709 | Average Loss in last 25 iteration(s): 0.1283 | Elapsed 0:45:44\n",
      "Epoch: 002/010 | Batch 2651/45709 | Average Loss in last 25 iteration(s): 0.1355 | Elapsed 0:46:11\n",
      "Epoch: 002/010 | Batch 2676/45709 | Average Loss in last 25 iteration(s): 0.0903 | Elapsed 0:46:36\n",
      "Epoch: 002/010 | Batch 2701/45709 | Average Loss in last 25 iteration(s): 0.0804 | Elapsed 0:47:02\n",
      "Epoch: 002/010 | Batch 2726/45709 | Average Loss in last 25 iteration(s): 0.1079 | Elapsed 0:47:28\n",
      "Epoch: 002/010 | Batch 2751/45709 | Average Loss in last 25 iteration(s): 0.1179 | Elapsed 0:47:54\n",
      "Epoch: 002/010 | Batch 2776/45709 | Average Loss in last 25 iteration(s): 0.1053 | Elapsed 0:48:21\n",
      "Epoch: 002/010 | Batch 2801/45709 | Average Loss in last 25 iteration(s): 0.1693 | Elapsed 0:48:44\n",
      "Epoch: 002/010 | Batch 2826/45709 | Average Loss in last 25 iteration(s): 0.1347 | Elapsed 0:49:14\n",
      "Epoch: 002/010 | Batch 2851/45709 | Average Loss in last 25 iteration(s): 0.1075 | Elapsed 0:49:42\n",
      "Epoch: 002/010 | Batch 2876/45709 | Average Loss in last 25 iteration(s): 0.1136 | Elapsed 0:50:08\n",
      "Epoch: 002/010 | Batch 2901/45709 | Average Loss in last 25 iteration(s): 0.0871 | Elapsed 0:50:34\n",
      "Epoch: 002/010 | Batch 2926/45709 | Average Loss in last 25 iteration(s): 0.0859 | Elapsed 0:51:00\n",
      "Epoch: 002/010 | Batch 2951/45709 | Average Loss in last 25 iteration(s): 0.1049 | Elapsed 0:51:22\n",
      "Epoch: 002/010 | Batch 2976/45709 | Average Loss in last 25 iteration(s): 0.1058 | Elapsed 0:51:48\n",
      "Epoch: 002/010 | Batch 3001/45709 | Average Loss in last 25 iteration(s): 0.1020 | Elapsed 0:52:16\n",
      "Epoch: 002/010 | Batch 3026/45709 | Average Loss in last 25 iteration(s): 0.1066 | Elapsed 0:52:43\n",
      "Epoch: 002/010 | Batch 3051/45709 | Average Loss in last 25 iteration(s): 0.1343 | Elapsed 0:53:10\n",
      "Epoch: 002/010 | Batch 3076/45709 | Average Loss in last 25 iteration(s): 0.1186 | Elapsed 0:53:37\n",
      "Epoch: 002/010 | Batch 3101/45709 | Average Loss in last 25 iteration(s): 0.1406 | Elapsed 0:54:01\n",
      "Epoch: 002/010 | Batch 3126/45709 | Average Loss in last 25 iteration(s): 0.1109 | Elapsed 0:54:27\n",
      "Epoch: 002/010 | Batch 3151/45709 | Average Loss in last 25 iteration(s): 0.1387 | Elapsed 0:54:56\n",
      "Epoch: 002/010 | Batch 3176/45709 | Average Loss in last 25 iteration(s): 0.1218 | Elapsed 0:55:22\n",
      "Epoch: 002/010 | Batch 3201/45709 | Average Loss in last 25 iteration(s): 0.0984 | Elapsed 0:55:49\n",
      "Epoch: 002/010 | Batch 3226/45709 | Average Loss in last 25 iteration(s): 0.1598 | Elapsed 0:56:15\n",
      "Epoch: 002/010 | Batch 3251/45709 | Average Loss in last 25 iteration(s): 0.1267 | Elapsed 0:56:41\n",
      "Epoch: 002/010 | Batch 3276/45709 | Average Loss in last 25 iteration(s): 0.1234 | Elapsed 0:57:07\n",
      "Epoch: 002/010 | Batch 3301/45709 | Average Loss in last 25 iteration(s): 0.1248 | Elapsed 0:57:36\n",
      "Epoch: 002/010 | Batch 3326/45709 | Average Loss in last 25 iteration(s): 0.1221 | Elapsed 0:58:04\n",
      "Epoch: 002/010 | Batch 3351/45709 | Average Loss in last 25 iteration(s): 0.1394 | Elapsed 0:58:29\n",
      "Epoch: 002/010 | Batch 3376/45709 | Average Loss in last 25 iteration(s): 0.0932 | Elapsed 0:58:55\n",
      "Epoch: 002/010 | Batch 3401/45709 | Average Loss in last 25 iteration(s): 0.1279 | Elapsed 0:59:21\n",
      "Epoch: 002/010 | Batch 3426/45709 | Average Loss in last 25 iteration(s): 0.0871 | Elapsed 0:59:45\n",
      "Epoch: 002/010 | Batch 3451/45709 | Average Loss in last 25 iteration(s): 0.1263 | Elapsed 1:00:13\n",
      "Epoch: 002/010 | Batch 3476/45709 | Average Loss in last 25 iteration(s): 0.1203 | Elapsed 1:00:40\n",
      "Epoch: 002/010 | Batch 3501/45709 | Average Loss in last 25 iteration(s): 0.0984 | Elapsed 1:01:06\n",
      "Epoch: 002/010 | Batch 3526/45709 | Average Loss in last 25 iteration(s): 0.1315 | Elapsed 1:01:33\n",
      "Epoch: 002/010 | Batch 3551/45709 | Average Loss in last 25 iteration(s): 0.1166 | Elapsed 1:01:57\n",
      "Epoch: 002/010 | Batch 3576/45709 | Average Loss in last 25 iteration(s): 0.1278 | Elapsed 1:02:22\n",
      "Epoch: 002/010 | Batch 3601/45709 | Average Loss in last 25 iteration(s): 0.1369 | Elapsed 1:02:50\n",
      "Epoch: 002/010 | Batch 3626/45709 | Average Loss in last 25 iteration(s): 0.0873 | Elapsed 1:03:16\n",
      "Epoch: 002/010 | Batch 3651/45709 | Average Loss in last 25 iteration(s): 0.0873 | Elapsed 1:03:42\n",
      "Epoch: 002/010 | Batch 3676/45709 | Average Loss in last 25 iteration(s): 0.1209 | Elapsed 1:04:09\n",
      "Epoch: 002/010 | Batch 3701/45709 | Average Loss in last 25 iteration(s): 0.1123 | Elapsed 1:04:36\n",
      "Epoch: 002/010 | Batch 3726/45709 | Average Loss in last 25 iteration(s): 0.1267 | Elapsed 1:04:59\n",
      "Epoch: 002/010 | Batch 3751/45709 | Average Loss in last 25 iteration(s): 0.1175 | Elapsed 1:05:25\n",
      "Epoch: 002/010 | Batch 3776/45709 | Average Loss in last 25 iteration(s): 0.1109 | Elapsed 1:05:53\n",
      "Epoch: 002/010 | Batch 3801/45709 | Average Loss in last 25 iteration(s): 0.0985 | Elapsed 1:06:20\n",
      "Epoch: 002/010 | Batch 3826/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 1:06:47\n",
      "Epoch: 002/010 | Batch 3851/45709 | Average Loss in last 25 iteration(s): 0.1397 | Elapsed 1:07:13\n",
      "Epoch: 002/010 | Batch 3876/45709 | Average Loss in last 25 iteration(s): 0.1166 | Elapsed 1:07:39\n",
      "Epoch: 002/010 | Batch 3901/45709 | Average Loss in last 25 iteration(s): 0.1097 | Elapsed 1:08:02\n",
      "Epoch: 002/010 | Batch 3926/45709 | Average Loss in last 25 iteration(s): 0.0988 | Elapsed 1:08:30\n",
      "Epoch: 002/010 | Batch 3951/45709 | Average Loss in last 25 iteration(s): 0.1050 | Elapsed 1:08:58\n",
      "Epoch: 002/010 | Batch 3976/45709 | Average Loss in last 25 iteration(s): 0.1299 | Elapsed 1:09:22\n",
      "Epoch: 002/010 | Batch 4001/45709 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 1:09:49\n",
      "Epoch: 002/010 | Batch 4026/45709 | Average Loss in last 25 iteration(s): 0.0785 | Elapsed 1:10:16\n",
      "Epoch: 002/010 | Batch 4051/45709 | Average Loss in last 25 iteration(s): 0.1289 | Elapsed 1:10:38\n",
      "Epoch: 002/010 | Batch 4076/45709 | Average Loss in last 25 iteration(s): 0.0994 | Elapsed 1:11:06\n",
      "Epoch: 002/010 | Batch 4101/45709 | Average Loss in last 25 iteration(s): 0.0960 | Elapsed 1:11:33\n",
      "Epoch: 002/010 | Batch 4126/45709 | Average Loss in last 25 iteration(s): 0.1373 | Elapsed 1:12:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 4151/45709 | Average Loss in last 25 iteration(s): 0.0993 | Elapsed 1:12:26\n",
      "Epoch: 002/010 | Batch 4176/45709 | Average Loss in last 25 iteration(s): 0.1477 | Elapsed 1:12:53\n",
      "Epoch: 002/010 | Batch 4201/45709 | Average Loss in last 25 iteration(s): 0.1145 | Elapsed 1:13:18\n",
      "Epoch: 002/010 | Batch 4226/45709 | Average Loss in last 25 iteration(s): 0.0778 | Elapsed 1:13:41\n",
      "Epoch: 002/010 | Batch 4251/45709 | Average Loss in last 25 iteration(s): 0.1068 | Elapsed 1:14:12\n",
      "Epoch: 002/010 | Batch 4276/45709 | Average Loss in last 25 iteration(s): 0.1319 | Elapsed 1:14:38\n",
      "Epoch: 002/010 | Batch 4301/45709 | Average Loss in last 25 iteration(s): 0.1323 | Elapsed 1:15:04\n",
      "Epoch: 002/010 | Batch 4326/45709 | Average Loss in last 25 iteration(s): 0.0922 | Elapsed 1:15:31\n",
      "Epoch: 002/010 | Batch 4351/45709 | Average Loss in last 25 iteration(s): 0.1092 | Elapsed 1:15:56\n",
      "Epoch: 002/010 | Batch 4376/45709 | Average Loss in last 25 iteration(s): 0.1178 | Elapsed 1:16:20\n",
      "Epoch: 002/010 | Batch 4401/45709 | Average Loss in last 25 iteration(s): 0.1143 | Elapsed 1:16:47\n",
      "Epoch: 002/010 | Batch 4426/45709 | Average Loss in last 25 iteration(s): 0.1226 | Elapsed 1:17:17\n",
      "Epoch: 002/010 | Batch 4451/45709 | Average Loss in last 25 iteration(s): 0.1199 | Elapsed 1:17:45\n",
      "Epoch: 002/010 | Batch 4476/45709 | Average Loss in last 25 iteration(s): 0.0970 | Elapsed 1:18:12\n",
      "Epoch: 002/010 | Batch 4501/45709 | Average Loss in last 25 iteration(s): 0.1188 | Elapsed 1:18:38\n",
      "Epoch: 002/010 | Batch 4526/45709 | Average Loss in last 25 iteration(s): 0.1529 | Elapsed 1:19:00\n",
      "Epoch: 002/010 | Batch 4551/45709 | Average Loss in last 25 iteration(s): 0.0927 | Elapsed 1:19:28\n",
      "Epoch: 002/010 | Batch 4576/45709 | Average Loss in last 25 iteration(s): 0.1381 | Elapsed 1:19:56\n",
      "Epoch: 002/010 | Batch 4601/45709 | Average Loss in last 25 iteration(s): 0.1192 | Elapsed 1:20:21\n",
      "Epoch: 002/010 | Batch 4626/45709 | Average Loss in last 25 iteration(s): 0.1163 | Elapsed 1:20:47\n",
      "Epoch: 002/010 | Batch 4651/45709 | Average Loss in last 25 iteration(s): 0.0950 | Elapsed 1:21:15\n",
      "Epoch: 002/010 | Batch 4676/45709 | Average Loss in last 25 iteration(s): 0.1206 | Elapsed 1:21:40\n",
      "Epoch: 002/010 | Batch 4701/45709 | Average Loss in last 25 iteration(s): 0.1311 | Elapsed 1:22:03\n",
      "Epoch: 002/010 | Batch 4726/45709 | Average Loss in last 25 iteration(s): 0.0949 | Elapsed 1:22:31\n",
      "Epoch: 002/010 | Batch 4751/45709 | Average Loss in last 25 iteration(s): 0.1102 | Elapsed 1:22:58\n",
      "Epoch: 002/010 | Batch 4776/45709 | Average Loss in last 25 iteration(s): 0.0954 | Elapsed 1:23:23\n",
      "Epoch: 002/010 | Batch 4801/45709 | Average Loss in last 25 iteration(s): 0.1108 | Elapsed 1:23:51\n",
      "Epoch: 002/010 | Batch 4826/45709 | Average Loss in last 25 iteration(s): 0.0967 | Elapsed 1:24:17\n",
      "Epoch: 002/010 | Batch 4851/45709 | Average Loss in last 25 iteration(s): 0.1653 | Elapsed 1:24:40\n",
      "Epoch: 002/010 | Batch 4876/45709 | Average Loss in last 25 iteration(s): 0.1473 | Elapsed 1:25:07\n",
      "Epoch: 002/010 | Batch 4901/45709 | Average Loss in last 25 iteration(s): 0.1298 | Elapsed 1:25:35\n",
      "Epoch: 002/010 | Batch 4926/45709 | Average Loss in last 25 iteration(s): 0.0857 | Elapsed 1:26:02\n",
      "Epoch: 002/010 | Batch 4951/45709 | Average Loss in last 25 iteration(s): 0.1052 | Elapsed 1:26:27\n",
      "Epoch: 002/010 | Batch 4976/45709 | Average Loss in last 25 iteration(s): 0.0988 | Elapsed 1:26:53\n",
      "Epoch: 002/010 | Batch 5001/45709 | Average Loss in last 25 iteration(s): 0.1155 | Elapsed 1:27:18\n",
      "Epoch: 002/010 | Batch 5026/45709 | Average Loss in last 25 iteration(s): 0.0983 | Elapsed 1:27:43\n",
      "Epoch: 002/010 | Batch 5051/45709 | Average Loss in last 25 iteration(s): 0.0771 | Elapsed 1:28:11\n",
      "Epoch: 002/010 | Batch 5076/45709 | Average Loss in last 25 iteration(s): 0.1147 | Elapsed 1:28:38\n",
      "Epoch: 002/010 | Batch 5101/45709 | Average Loss in last 25 iteration(s): 0.1437 | Elapsed 1:29:06\n",
      "Epoch: 002/010 | Batch 5126/45709 | Average Loss in last 25 iteration(s): 0.1154 | Elapsed 1:29:31\n",
      "Epoch: 002/010 | Batch 5151/45709 | Average Loss in last 25 iteration(s): 0.1042 | Elapsed 1:29:57\n",
      "Epoch: 002/010 | Batch 5176/45709 | Average Loss in last 25 iteration(s): 0.1086 | Elapsed 1:30:21\n",
      "Epoch: 002/010 | Batch 5201/45709 | Average Loss in last 25 iteration(s): 0.1033 | Elapsed 1:30:49\n",
      "Epoch: 002/010 | Batch 5226/45709 | Average Loss in last 25 iteration(s): 0.0814 | Elapsed 1:31:16\n",
      "Epoch: 002/010 | Batch 5251/45709 | Average Loss in last 25 iteration(s): 0.1182 | Elapsed 1:31:43\n",
      "Epoch: 002/010 | Batch 5276/45709 | Average Loss in last 25 iteration(s): 0.1254 | Elapsed 1:32:08\n",
      "Epoch: 002/010 | Batch 5301/45709 | Average Loss in last 25 iteration(s): 0.1151 | Elapsed 1:32:34\n",
      "Epoch: 002/010 | Batch 5326/45709 | Average Loss in last 25 iteration(s): 0.0888 | Elapsed 1:32:58\n",
      "Epoch: 002/010 | Batch 5351/45709 | Average Loss in last 25 iteration(s): 0.1195 | Elapsed 1:33:23\n",
      "Epoch: 002/010 | Batch 5376/45709 | Average Loss in last 25 iteration(s): 0.1021 | Elapsed 1:33:52\n",
      "Epoch: 002/010 | Batch 5401/45709 | Average Loss in last 25 iteration(s): 0.1461 | Elapsed 1:34:19\n",
      "Epoch: 002/010 | Batch 5426/45709 | Average Loss in last 25 iteration(s): 0.1011 | Elapsed 1:34:45\n",
      "Epoch: 002/010 | Batch 5451/45709 | Average Loss in last 25 iteration(s): 0.1229 | Elapsed 1:35:13\n",
      "Epoch: 002/010 | Batch 5476/45709 | Average Loss in last 25 iteration(s): 0.1117 | Elapsed 1:35:38\n",
      "Epoch: 002/010 | Batch 5501/45709 | Average Loss in last 25 iteration(s): 0.1251 | Elapsed 1:36:02\n",
      "Epoch: 002/010 | Batch 5526/45709 | Average Loss in last 25 iteration(s): 0.1513 | Elapsed 1:36:31\n",
      "Epoch: 002/010 | Batch 5551/45709 | Average Loss in last 25 iteration(s): 0.1110 | Elapsed 1:36:57\n",
      "Epoch: 002/010 | Batch 5576/45709 | Average Loss in last 25 iteration(s): 0.1070 | Elapsed 1:37:25\n",
      "Epoch: 002/010 | Batch 5601/45709 | Average Loss in last 25 iteration(s): 0.0953 | Elapsed 1:37:53\n",
      "Epoch: 002/010 | Batch 5626/45709 | Average Loss in last 25 iteration(s): 0.1016 | Elapsed 1:38:18\n",
      "Epoch: 002/010 | Batch 5651/45709 | Average Loss in last 25 iteration(s): 0.1013 | Elapsed 1:38:42\n",
      "Epoch: 002/010 | Batch 5676/45709 | Average Loss in last 25 iteration(s): 0.0917 | Elapsed 1:39:09\n",
      "Epoch: 002/010 | Batch 5701/45709 | Average Loss in last 25 iteration(s): 0.0788 | Elapsed 1:39:35\n",
      "Epoch: 002/010 | Batch 5726/45709 | Average Loss in last 25 iteration(s): 0.1449 | Elapsed 1:40:02\n",
      "Epoch: 002/010 | Batch 5751/45709 | Average Loss in last 25 iteration(s): 0.0991 | Elapsed 1:40:30\n",
      "Epoch: 002/010 | Batch 5776/45709 | Average Loss in last 25 iteration(s): 0.1490 | Elapsed 1:40:56\n",
      "Epoch: 002/010 | Batch 5801/45709 | Average Loss in last 25 iteration(s): 0.1432 | Elapsed 1:41:19\n",
      "Epoch: 002/010 | Batch 5826/45709 | Average Loss in last 25 iteration(s): 0.1179 | Elapsed 1:41:45\n",
      "Epoch: 002/010 | Batch 5851/45709 | Average Loss in last 25 iteration(s): 0.1294 | Elapsed 1:42:13\n",
      "Epoch: 002/010 | Batch 5876/45709 | Average Loss in last 25 iteration(s): 0.1153 | Elapsed 1:42:40\n",
      "Epoch: 002/010 | Batch 5901/45709 | Average Loss in last 25 iteration(s): 0.1308 | Elapsed 1:43:08\n",
      "Epoch: 002/010 | Batch 5926/45709 | Average Loss in last 25 iteration(s): 0.1135 | Elapsed 1:43:34\n",
      "Epoch: 002/010 | Batch 5951/45709 | Average Loss in last 25 iteration(s): 0.1240 | Elapsed 1:43:59\n",
      "Epoch: 002/010 | Batch 5976/45709 | Average Loss in last 25 iteration(s): 0.1041 | Elapsed 1:44:26\n",
      "Epoch: 002/010 | Batch 6001/45709 | Average Loss in last 25 iteration(s): 0.0953 | Elapsed 1:44:54\n",
      "Epoch: 002/010 | Batch 6026/45709 | Average Loss in last 25 iteration(s): 0.1186 | Elapsed 1:45:19\n",
      "Epoch: 002/010 | Batch 6051/45709 | Average Loss in last 25 iteration(s): 0.1175 | Elapsed 1:45:46\n",
      "Epoch: 002/010 | Batch 6076/45709 | Average Loss in last 25 iteration(s): 0.1007 | Elapsed 1:46:14\n",
      "Epoch: 002/010 | Batch 6101/45709 | Average Loss in last 25 iteration(s): 0.0893 | Elapsed 1:46:38\n",
      "Epoch: 002/010 | Batch 6126/45709 | Average Loss in last 25 iteration(s): 0.1235 | Elapsed 1:47:02\n",
      "Epoch: 002/010 | Batch 6151/45709 | Average Loss in last 25 iteration(s): 0.0777 | Elapsed 1:47:31\n",
      "Epoch: 002/010 | Batch 6176/45709 | Average Loss in last 25 iteration(s): 0.0951 | Elapsed 1:47:58\n",
      "Epoch: 002/010 | Batch 6201/45709 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 1:48:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 6226/45709 | Average Loss in last 25 iteration(s): 0.0897 | Elapsed 1:48:51\n",
      "Epoch: 002/010 | Batch 6251/45709 | Average Loss in last 25 iteration(s): 0.0999 | Elapsed 1:49:17\n",
      "Epoch: 002/010 | Batch 6276/45709 | Average Loss in last 25 iteration(s): 0.1257 | Elapsed 1:49:40\n",
      "Epoch: 002/010 | Batch 6301/45709 | Average Loss in last 25 iteration(s): 0.1096 | Elapsed 1:50:06\n",
      "Epoch: 002/010 | Batch 6326/45709 | Average Loss in last 25 iteration(s): 0.1241 | Elapsed 1:50:34\n",
      "Epoch: 002/010 | Batch 6351/45709 | Average Loss in last 25 iteration(s): 0.1221 | Elapsed 1:51:03\n",
      "Epoch: 002/010 | Batch 6376/45709 | Average Loss in last 25 iteration(s): 0.1158 | Elapsed 1:51:29\n",
      "Epoch: 002/010 | Batch 6401/45709 | Average Loss in last 25 iteration(s): 0.1201 | Elapsed 1:51:55\n",
      "Epoch: 002/010 | Batch 6426/45709 | Average Loss in last 25 iteration(s): 0.1282 | Elapsed 1:52:19\n",
      "Epoch: 002/010 | Batch 6451/45709 | Average Loss in last 25 iteration(s): 0.1584 | Elapsed 1:52:48\n",
      "Epoch: 002/010 | Batch 6476/45709 | Average Loss in last 25 iteration(s): 0.1113 | Elapsed 1:53:10\n",
      "Epoch: 002/010 | Batch 6501/45709 | Average Loss in last 25 iteration(s): 0.1215 | Elapsed 1:53:38\n",
      "Epoch: 002/010 | Batch 6526/45709 | Average Loss in last 25 iteration(s): 0.0927 | Elapsed 1:54:06\n",
      "Epoch: 002/010 | Batch 6551/45709 | Average Loss in last 25 iteration(s): 0.1149 | Elapsed 1:54:32\n",
      "Epoch: 002/010 | Batch 6576/45709 | Average Loss in last 25 iteration(s): 0.1233 | Elapsed 1:54:56\n",
      "Epoch: 002/010 | Batch 6601/45709 | Average Loss in last 25 iteration(s): 0.1172 | Elapsed 1:55:24\n",
      "Epoch: 002/010 | Batch 6626/45709 | Average Loss in last 25 iteration(s): 0.1019 | Elapsed 1:55:53\n",
      "Epoch: 002/010 | Batch 6651/45709 | Average Loss in last 25 iteration(s): 0.0875 | Elapsed 1:56:17\n",
      "Epoch: 002/010 | Batch 6676/45709 | Average Loss in last 25 iteration(s): 0.0968 | Elapsed 1:56:45\n",
      "Epoch: 002/010 | Batch 6701/45709 | Average Loss in last 25 iteration(s): 0.1149 | Elapsed 1:57:11\n",
      "Epoch: 002/010 | Batch 6726/45709 | Average Loss in last 25 iteration(s): 0.0907 | Elapsed 1:57:36\n",
      "Epoch: 002/010 | Batch 6751/45709 | Average Loss in last 25 iteration(s): 0.0934 | Elapsed 1:57:59\n",
      "Epoch: 002/010 | Batch 6776/45709 | Average Loss in last 25 iteration(s): 0.1065 | Elapsed 1:58:28\n",
      "Epoch: 002/010 | Batch 6801/45709 | Average Loss in last 25 iteration(s): 0.1268 | Elapsed 1:58:54\n",
      "Epoch: 002/010 | Batch 6826/45709 | Average Loss in last 25 iteration(s): 0.1171 | Elapsed 1:59:20\n",
      "Epoch: 002/010 | Batch 6851/45709 | Average Loss in last 25 iteration(s): 0.1156 | Elapsed 1:59:47\n",
      "Epoch: 002/010 | Batch 6876/45709 | Average Loss in last 25 iteration(s): 0.1145 | Elapsed 2:00:14\n",
      "Epoch: 002/010 | Batch 6901/45709 | Average Loss in last 25 iteration(s): 0.1307 | Elapsed 2:00:38\n",
      "Epoch: 002/010 | Batch 6926/45709 | Average Loss in last 25 iteration(s): 0.0772 | Elapsed 2:01:07\n",
      "Epoch: 002/010 | Batch 6951/45709 | Average Loss in last 25 iteration(s): 0.1137 | Elapsed 2:01:36\n",
      "Epoch: 002/010 | Batch 6976/45709 | Average Loss in last 25 iteration(s): 0.0911 | Elapsed 2:02:02\n",
      "Epoch: 002/010 | Batch 7001/45709 | Average Loss in last 25 iteration(s): 0.1079 | Elapsed 2:02:29\n",
      "Epoch: 002/010 | Batch 7026/45709 | Average Loss in last 25 iteration(s): 0.1174 | Elapsed 2:02:56\n",
      "Epoch: 002/010 | Batch 7051/45709 | Average Loss in last 25 iteration(s): 0.1174 | Elapsed 2:03:18\n",
      "Epoch: 002/010 | Batch 7076/45709 | Average Loss in last 25 iteration(s): 0.1375 | Elapsed 2:03:47\n",
      "Epoch: 002/010 | Batch 7101/45709 | Average Loss in last 25 iteration(s): 0.1042 | Elapsed 2:04:15\n",
      "Epoch: 002/010 | Batch 7126/45709 | Average Loss in last 25 iteration(s): 0.1118 | Elapsed 2:04:43\n",
      "Epoch: 002/010 | Batch 7151/45709 | Average Loss in last 25 iteration(s): 0.1229 | Elapsed 2:05:10\n",
      "Epoch: 002/010 | Batch 7176/45709 | Average Loss in last 25 iteration(s): 0.1241 | Elapsed 2:05:36\n",
      "Epoch: 002/010 | Batch 7201/45709 | Average Loss in last 25 iteration(s): 0.0699 | Elapsed 2:06:00\n",
      "Epoch: 002/010 | Batch 7226/45709 | Average Loss in last 25 iteration(s): 0.1131 | Elapsed 2:06:29\n",
      "Epoch: 002/010 | Batch 7251/45709 | Average Loss in last 25 iteration(s): 0.1015 | Elapsed 2:06:55\n",
      "Epoch: 002/010 | Batch 7276/45709 | Average Loss in last 25 iteration(s): 0.1116 | Elapsed 2:07:22\n",
      "Epoch: 002/010 | Batch 7301/45709 | Average Loss in last 25 iteration(s): 0.0874 | Elapsed 2:07:49\n",
      "Epoch: 002/010 | Batch 7326/45709 | Average Loss in last 25 iteration(s): 0.1607 | Elapsed 2:08:16\n",
      "Epoch: 002/010 | Batch 7351/45709 | Average Loss in last 25 iteration(s): 0.1513 | Elapsed 2:08:40\n",
      "Epoch: 002/010 | Batch 7376/45709 | Average Loss in last 25 iteration(s): 0.1164 | Elapsed 2:09:09\n",
      "Epoch: 002/010 | Batch 7401/45709 | Average Loss in last 25 iteration(s): 0.0958 | Elapsed 2:09:36\n",
      "Epoch: 002/010 | Batch 7426/45709 | Average Loss in last 25 iteration(s): 0.1241 | Elapsed 2:10:03\n",
      "Epoch: 002/010 | Batch 7451/45709 | Average Loss in last 25 iteration(s): 0.1282 | Elapsed 2:10:30\n",
      "Epoch: 002/010 | Batch 7476/45709 | Average Loss in last 25 iteration(s): 0.1199 | Elapsed 2:10:57\n",
      "Epoch: 002/010 | Batch 7501/45709 | Average Loss in last 25 iteration(s): 0.1153 | Elapsed 2:11:20\n",
      "Epoch: 002/010 | Batch 7526/45709 | Average Loss in last 25 iteration(s): 0.1054 | Elapsed 2:11:48\n",
      "Epoch: 002/010 | Batch 7551/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 2:12:14\n",
      "Epoch: 002/010 | Batch 7576/45709 | Average Loss in last 25 iteration(s): 0.1135 | Elapsed 2:12:41\n",
      "Epoch: 002/010 | Batch 7601/45709 | Average Loss in last 25 iteration(s): 0.1333 | Elapsed 2:13:08\n",
      "Epoch: 002/010 | Batch 7626/45709 | Average Loss in last 25 iteration(s): 0.1165 | Elapsed 2:13:35\n",
      "Epoch: 002/010 | Batch 7651/45709 | Average Loss in last 25 iteration(s): 0.0687 | Elapsed 2:13:59\n",
      "Epoch: 002/010 | Batch 7676/45709 | Average Loss in last 25 iteration(s): 0.1239 | Elapsed 2:14:27\n",
      "Epoch: 002/010 | Batch 7701/45709 | Average Loss in last 25 iteration(s): 0.1494 | Elapsed 2:14:56\n",
      "Epoch: 002/010 | Batch 7726/45709 | Average Loss in last 25 iteration(s): 0.1118 | Elapsed 2:15:21\n",
      "Epoch: 002/010 | Batch 7751/45709 | Average Loss in last 25 iteration(s): 0.1207 | Elapsed 2:15:47\n",
      "Epoch: 002/010 | Batch 7776/45709 | Average Loss in last 25 iteration(s): 0.1102 | Elapsed 2:16:15\n",
      "Epoch: 002/010 | Batch 7801/45709 | Average Loss in last 25 iteration(s): 0.1073 | Elapsed 2:16:38\n",
      "Epoch: 002/010 | Batch 7826/45709 | Average Loss in last 25 iteration(s): 0.1316 | Elapsed 2:17:04\n",
      "Epoch: 002/010 | Batch 7851/45709 | Average Loss in last 25 iteration(s): 0.1298 | Elapsed 2:17:32\n",
      "Epoch: 002/010 | Batch 7876/45709 | Average Loss in last 25 iteration(s): 0.0937 | Elapsed 2:17:59\n",
      "Epoch: 002/010 | Batch 7901/45709 | Average Loss in last 25 iteration(s): 0.1103 | Elapsed 2:18:25\n",
      "Epoch: 002/010 | Batch 7926/45709 | Average Loss in last 25 iteration(s): 0.1189 | Elapsed 2:18:52\n",
      "Epoch: 002/010 | Batch 7951/45709 | Average Loss in last 25 iteration(s): 0.1163 | Elapsed 2:19:17\n",
      "Epoch: 002/010 | Batch 7976/45709 | Average Loss in last 25 iteration(s): 0.1149 | Elapsed 2:19:42\n",
      "Epoch: 002/010 | Batch 8001/45709 | Average Loss in last 25 iteration(s): 0.1403 | Elapsed 2:20:09\n",
      "Epoch: 002/010 | Batch 8026/45709 | Average Loss in last 25 iteration(s): 0.1102 | Elapsed 2:20:36\n",
      "Epoch: 002/010 | Batch 8051/45709 | Average Loss in last 25 iteration(s): 0.1266 | Elapsed 2:21:03\n",
      "Epoch: 002/010 | Batch 8076/45709 | Average Loss in last 25 iteration(s): 0.1076 | Elapsed 2:21:29\n",
      "Epoch: 002/010 | Batch 8101/45709 | Average Loss in last 25 iteration(s): 0.1364 | Elapsed 2:21:55\n",
      "Epoch: 002/010 | Batch 8126/45709 | Average Loss in last 25 iteration(s): 0.1264 | Elapsed 2:22:18\n",
      "Epoch: 002/010 | Batch 8151/45709 | Average Loss in last 25 iteration(s): 0.1063 | Elapsed 2:22:47\n",
      "Epoch: 002/010 | Batch 8176/45709 | Average Loss in last 25 iteration(s): 0.1266 | Elapsed 2:23:14\n",
      "Epoch: 002/010 | Batch 8201/45709 | Average Loss in last 25 iteration(s): 0.0947 | Elapsed 2:23:41\n",
      "Epoch: 002/010 | Batch 8226/45709 | Average Loss in last 25 iteration(s): 0.1258 | Elapsed 2:24:08\n",
      "Epoch: 002/010 | Batch 8251/45709 | Average Loss in last 25 iteration(s): 0.1177 | Elapsed 2:24:34\n",
      "Epoch: 002/010 | Batch 8276/45709 | Average Loss in last 25 iteration(s): 0.1022 | Elapsed 2:24:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 8301/45709 | Average Loss in last 25 iteration(s): 0.1169 | Elapsed 2:25:25\n",
      "Epoch: 002/010 | Batch 8326/45709 | Average Loss in last 25 iteration(s): 0.1230 | Elapsed 2:25:53\n",
      "Epoch: 002/010 | Batch 8351/45709 | Average Loss in last 25 iteration(s): 0.0888 | Elapsed 2:26:19\n",
      "Epoch: 002/010 | Batch 8376/45709 | Average Loss in last 25 iteration(s): 0.0848 | Elapsed 2:26:46\n",
      "Epoch: 002/010 | Batch 8401/45709 | Average Loss in last 25 iteration(s): 0.0937 | Elapsed 2:27:13\n",
      "Epoch: 002/010 | Batch 8426/45709 | Average Loss in last 25 iteration(s): 0.1168 | Elapsed 2:27:38\n",
      "Epoch: 002/010 | Batch 8451/45709 | Average Loss in last 25 iteration(s): 0.0835 | Elapsed 2:28:04\n",
      "Epoch: 002/010 | Batch 8476/45709 | Average Loss in last 25 iteration(s): 0.1242 | Elapsed 2:28:32\n",
      "Epoch: 002/010 | Batch 8501/45709 | Average Loss in last 25 iteration(s): 0.1008 | Elapsed 2:28:58\n",
      "Epoch: 002/010 | Batch 8526/45709 | Average Loss in last 25 iteration(s): 0.1025 | Elapsed 2:29:25\n",
      "Epoch: 002/010 | Batch 8551/45709 | Average Loss in last 25 iteration(s): 0.1314 | Elapsed 2:29:54\n",
      "Epoch: 002/010 | Batch 8576/45709 | Average Loss in last 25 iteration(s): 0.1148 | Elapsed 2:30:18\n",
      "Epoch: 002/010 | Batch 8601/45709 | Average Loss in last 25 iteration(s): 0.0945 | Elapsed 2:30:41\n",
      "Epoch: 002/010 | Batch 8626/45709 | Average Loss in last 25 iteration(s): 0.1004 | Elapsed 2:31:08\n",
      "Epoch: 002/010 | Batch 8651/45709 | Average Loss in last 25 iteration(s): 0.1108 | Elapsed 2:31:37\n",
      "Epoch: 002/010 | Batch 8676/45709 | Average Loss in last 25 iteration(s): 0.1115 | Elapsed 2:32:03\n",
      "Epoch: 002/010 | Batch 8701/45709 | Average Loss in last 25 iteration(s): 0.0940 | Elapsed 2:32:30\n",
      "Epoch: 002/010 | Batch 8726/45709 | Average Loss in last 25 iteration(s): 0.1141 | Elapsed 2:32:55\n",
      "Epoch: 002/010 | Batch 8751/45709 | Average Loss in last 25 iteration(s): 0.1455 | Elapsed 2:33:17\n",
      "Epoch: 002/010 | Batch 8776/45709 | Average Loss in last 25 iteration(s): 0.1044 | Elapsed 2:33:44\n",
      "Epoch: 002/010 | Batch 8801/45709 | Average Loss in last 25 iteration(s): 0.0889 | Elapsed 2:34:12\n",
      "Epoch: 002/010 | Batch 8826/45709 | Average Loss in last 25 iteration(s): 0.1067 | Elapsed 2:34:40\n",
      "Epoch: 002/010 | Batch 8851/45709 | Average Loss in last 25 iteration(s): 0.1057 | Elapsed 2:35:08\n",
      "Epoch: 002/010 | Batch 8876/45709 | Average Loss in last 25 iteration(s): 0.1058 | Elapsed 2:35:33\n",
      "Epoch: 002/010 | Batch 8901/45709 | Average Loss in last 25 iteration(s): 0.1170 | Elapsed 2:35:56\n",
      "Epoch: 002/010 | Batch 8926/45709 | Average Loss in last 25 iteration(s): 0.1009 | Elapsed 2:36:23\n",
      "Epoch: 002/010 | Batch 8951/45709 | Average Loss in last 25 iteration(s): 0.0802 | Elapsed 2:36:50\n",
      "Epoch: 002/010 | Batch 8976/45709 | Average Loss in last 25 iteration(s): 0.1428 | Elapsed 2:37:17\n",
      "Epoch: 002/010 | Batch 9001/45709 | Average Loss in last 25 iteration(s): 0.1037 | Elapsed 2:37:43\n",
      "Epoch: 002/010 | Batch 9026/45709 | Average Loss in last 25 iteration(s): 0.1100 | Elapsed 2:38:11\n",
      "Epoch: 002/010 | Batch 9051/45709 | Average Loss in last 25 iteration(s): 0.1168 | Elapsed 2:38:35\n",
      "Epoch: 002/010 | Batch 9076/45709 | Average Loss in last 25 iteration(s): 0.1176 | Elapsed 2:38:59\n",
      "Epoch: 002/010 | Batch 9101/45709 | Average Loss in last 25 iteration(s): 0.0630 | Elapsed 2:39:28\n",
      "Epoch: 002/010 | Batch 9126/45709 | Average Loss in last 25 iteration(s): 0.1668 | Elapsed 2:39:55\n",
      "Epoch: 002/010 | Batch 9151/45709 | Average Loss in last 25 iteration(s): 0.0973 | Elapsed 2:40:21\n",
      "Epoch: 002/010 | Batch 9176/45709 | Average Loss in last 25 iteration(s): 0.0938 | Elapsed 2:40:47\n",
      "Epoch: 002/010 | Batch 9201/45709 | Average Loss in last 25 iteration(s): 0.1098 | Elapsed 2:41:14\n",
      "Epoch: 002/010 | Batch 9226/45709 | Average Loss in last 25 iteration(s): 0.0962 | Elapsed 2:41:36\n",
      "Epoch: 002/010 | Batch 9251/45709 | Average Loss in last 25 iteration(s): 0.0975 | Elapsed 2:42:02\n",
      "Epoch: 002/010 | Batch 9276/45709 | Average Loss in last 25 iteration(s): 0.0966 | Elapsed 2:42:30\n",
      "Epoch: 002/010 | Batch 9301/45709 | Average Loss in last 25 iteration(s): 0.1453 | Elapsed 2:42:57\n",
      "Epoch: 002/010 | Batch 9326/45709 | Average Loss in last 25 iteration(s): 0.0982 | Elapsed 2:43:23\n",
      "Epoch: 002/010 | Batch 9351/45709 | Average Loss in last 25 iteration(s): 0.0924 | Elapsed 2:43:50\n",
      "Epoch: 002/010 | Batch 9376/45709 | Average Loss in last 25 iteration(s): 0.1401 | Elapsed 2:44:14\n",
      "Epoch: 002/010 | Batch 9401/45709 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 2:44:40\n",
      "Epoch: 002/010 | Batch 9426/45709 | Average Loss in last 25 iteration(s): 0.0945 | Elapsed 2:45:08\n",
      "Epoch: 002/010 | Batch 9451/45709 | Average Loss in last 25 iteration(s): 0.0960 | Elapsed 2:45:35\n",
      "Epoch: 002/010 | Batch 9476/45709 | Average Loss in last 25 iteration(s): 0.0839 | Elapsed 2:46:02\n",
      "Epoch: 002/010 | Batch 9501/45709 | Average Loss in last 25 iteration(s): 0.1413 | Elapsed 2:46:28\n",
      "Epoch: 002/010 | Batch 9526/45709 | Average Loss in last 25 iteration(s): 0.1090 | Elapsed 2:46:52\n",
      "Epoch: 002/010 | Batch 9551/45709 | Average Loss in last 25 iteration(s): 0.1050 | Elapsed 2:47:17\n",
      "Epoch: 002/010 | Batch 9576/45709 | Average Loss in last 25 iteration(s): 0.1218 | Elapsed 2:47:46\n",
      "Epoch: 002/010 | Batch 9601/45709 | Average Loss in last 25 iteration(s): 0.1375 | Elapsed 2:48:12\n",
      "Epoch: 002/010 | Batch 9626/45709 | Average Loss in last 25 iteration(s): 0.1277 | Elapsed 2:48:40\n",
      "Epoch: 002/010 | Batch 9651/45709 | Average Loss in last 25 iteration(s): 0.0938 | Elapsed 2:49:05\n",
      "Epoch: 002/010 | Batch 9676/45709 | Average Loss in last 25 iteration(s): 0.1565 | Elapsed 2:49:31\n",
      "Epoch: 002/010 | Batch 9701/45709 | Average Loss in last 25 iteration(s): 0.1322 | Elapsed 2:49:56\n",
      "Epoch: 002/010 | Batch 9726/45709 | Average Loss in last 25 iteration(s): 0.1049 | Elapsed 2:50:24\n",
      "Epoch: 002/010 | Batch 9751/45709 | Average Loss in last 25 iteration(s): 0.0970 | Elapsed 2:50:50\n",
      "Epoch: 002/010 | Batch 9776/45709 | Average Loss in last 25 iteration(s): 0.0865 | Elapsed 2:51:17\n",
      "Epoch: 002/010 | Batch 9801/45709 | Average Loss in last 25 iteration(s): 0.1288 | Elapsed 2:51:43\n",
      "Epoch: 002/010 | Batch 9826/45709 | Average Loss in last 25 iteration(s): 0.1237 | Elapsed 2:52:10\n",
      "Epoch: 002/010 | Batch 9851/45709 | Average Loss in last 25 iteration(s): 0.1218 | Elapsed 2:52:32\n",
      "Epoch: 002/010 | Batch 9876/45709 | Average Loss in last 25 iteration(s): 0.1320 | Elapsed 2:52:58\n",
      "Epoch: 002/010 | Batch 9901/45709 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 2:53:26\n",
      "Epoch: 002/010 | Batch 9926/45709 | Average Loss in last 25 iteration(s): 0.0752 | Elapsed 2:53:53\n",
      "Epoch: 002/010 | Batch 9951/45709 | Average Loss in last 25 iteration(s): 0.0975 | Elapsed 2:54:20\n",
      "Epoch: 002/010 | Batch 9976/45709 | Average Loss in last 25 iteration(s): 0.1042 | Elapsed 2:54:47\n",
      "Epoch: 002/010 | Batch 10001/45709 | Average Loss in last 25 iteration(s): 0.1133 | Elapsed 2:55:11\n",
      "Epoch: 002/010 | Batch 10026/45709 | Average Loss in last 25 iteration(s): 0.0791 | Elapsed 2:55:37\n",
      "Epoch: 002/010 | Batch 10051/45709 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 2:56:06\n",
      "Epoch: 002/010 | Batch 10076/45709 | Average Loss in last 25 iteration(s): 0.1041 | Elapsed 2:56:34\n",
      "Epoch: 002/010 | Batch 10101/45709 | Average Loss in last 25 iteration(s): 0.1041 | Elapsed 2:57:01\n",
      "Epoch: 002/010 | Batch 10126/45709 | Average Loss in last 25 iteration(s): 0.1162 | Elapsed 2:57:28\n",
      "Epoch: 002/010 | Batch 10151/45709 | Average Loss in last 25 iteration(s): 0.1528 | Elapsed 2:57:53\n",
      "Epoch: 002/010 | Batch 10176/45709 | Average Loss in last 25 iteration(s): 0.1226 | Elapsed 2:58:21\n",
      "Epoch: 002/010 | Batch 10201/45709 | Average Loss in last 25 iteration(s): 0.1052 | Elapsed 2:58:50\n",
      "Epoch: 002/010 | Batch 10226/45709 | Average Loss in last 25 iteration(s): 0.0940 | Elapsed 2:59:16\n",
      "Epoch: 002/010 | Batch 10251/45709 | Average Loss in last 25 iteration(s): 0.1089 | Elapsed 2:59:43\n",
      "Epoch: 002/010 | Batch 10276/45709 | Average Loss in last 25 iteration(s): 0.0992 | Elapsed 3:00:08\n",
      "Epoch: 002/010 | Batch 10301/45709 | Average Loss in last 25 iteration(s): 0.1360 | Elapsed 3:00:32\n",
      "Epoch: 002/010 | Batch 10326/45709 | Average Loss in last 25 iteration(s): 0.1285 | Elapsed 3:01:01\n",
      "Epoch: 002/010 | Batch 10351/45709 | Average Loss in last 25 iteration(s): 0.0796 | Elapsed 3:01:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 10376/45709 | Average Loss in last 25 iteration(s): 0.0909 | Elapsed 3:01:58\n",
      "Epoch: 002/010 | Batch 10401/45709 | Average Loss in last 25 iteration(s): 0.1307 | Elapsed 3:02:23\n",
      "Epoch: 002/010 | Batch 10426/45709 | Average Loss in last 25 iteration(s): 0.1010 | Elapsed 3:02:47\n",
      "Epoch: 002/010 | Batch 10451/45709 | Average Loss in last 25 iteration(s): 0.0883 | Elapsed 3:03:11\n",
      "Epoch: 002/010 | Batch 10476/45709 | Average Loss in last 25 iteration(s): 0.1009 | Elapsed 3:03:39\n",
      "Epoch: 002/010 | Batch 10501/45709 | Average Loss in last 25 iteration(s): 0.0799 | Elapsed 3:04:07\n",
      "Epoch: 002/010 | Batch 10526/45709 | Average Loss in last 25 iteration(s): 0.1116 | Elapsed 3:04:31\n",
      "Epoch: 002/010 | Batch 10551/45709 | Average Loss in last 25 iteration(s): 0.1021 | Elapsed 3:04:59\n",
      "Epoch: 002/010 | Batch 10576/45709 | Average Loss in last 25 iteration(s): 0.0945 | Elapsed 3:05:26\n",
      "Epoch: 002/010 | Batch 10601/45709 | Average Loss in last 25 iteration(s): 0.1641 | Elapsed 3:05:49\n",
      "Epoch: 002/010 | Batch 10626/45709 | Average Loss in last 25 iteration(s): 0.0892 | Elapsed 3:06:16\n",
      "Epoch: 002/010 | Batch 10651/45709 | Average Loss in last 25 iteration(s): 0.1201 | Elapsed 3:06:42\n",
      "Epoch: 002/010 | Batch 10676/45709 | Average Loss in last 25 iteration(s): 0.1136 | Elapsed 3:07:08\n",
      "Epoch: 002/010 | Batch 10701/45709 | Average Loss in last 25 iteration(s): 0.1056 | Elapsed 3:07:36\n",
      "Epoch: 002/010 | Batch 10726/45709 | Average Loss in last 25 iteration(s): 0.1385 | Elapsed 3:08:04\n",
      "Epoch: 002/010 | Batch 10751/45709 | Average Loss in last 25 iteration(s): 0.1264 | Elapsed 3:08:29\n",
      "Epoch: 002/010 | Batch 10776/45709 | Average Loss in last 25 iteration(s): 0.1317 | Elapsed 3:08:53\n",
      "Epoch: 002/010 | Batch 10801/45709 | Average Loss in last 25 iteration(s): 0.1293 | Elapsed 3:09:21\n",
      "Epoch: 002/010 | Batch 10826/45709 | Average Loss in last 25 iteration(s): 0.1130 | Elapsed 3:09:48\n",
      "Epoch: 002/010 | Batch 10851/45709 | Average Loss in last 25 iteration(s): 0.1071 | Elapsed 3:10:17\n",
      "Epoch: 002/010 | Batch 10876/45709 | Average Loss in last 25 iteration(s): 0.0924 | Elapsed 3:10:45\n",
      "Epoch: 002/010 | Batch 10901/45709 | Average Loss in last 25 iteration(s): 0.1357 | Elapsed 3:11:08\n",
      "Epoch: 002/010 | Batch 10926/45709 | Average Loss in last 25 iteration(s): 0.1024 | Elapsed 3:11:32\n",
      "Epoch: 002/010 | Batch 10951/45709 | Average Loss in last 25 iteration(s): 0.1403 | Elapsed 3:11:55\n",
      "Epoch: 002/010 | Batch 10976/45709 | Average Loss in last 25 iteration(s): 0.1468 | Elapsed 3:12:26\n",
      "Epoch: 002/010 | Batch 11001/45709 | Average Loss in last 25 iteration(s): 0.1207 | Elapsed 3:12:53\n",
      "Epoch: 002/010 | Batch 11026/45709 | Average Loss in last 25 iteration(s): 0.0747 | Elapsed 3:13:21\n",
      "Epoch: 002/010 | Batch 11051/45709 | Average Loss in last 25 iteration(s): 0.1190 | Elapsed 3:13:46\n",
      "Epoch: 002/010 | Batch 11076/45709 | Average Loss in last 25 iteration(s): 0.1220 | Elapsed 3:14:10\n",
      "Epoch: 002/010 | Batch 11101/45709 | Average Loss in last 25 iteration(s): 0.0835 | Elapsed 3:14:43\n",
      "Epoch: 002/010 | Batch 11126/45709 | Average Loss in last 25 iteration(s): 0.1165 | Elapsed 3:15:05\n",
      "Epoch: 002/010 | Batch 11151/45709 | Average Loss in last 25 iteration(s): 0.1368 | Elapsed 3:15:33\n",
      "Epoch: 002/010 | Batch 11176/45709 | Average Loss in last 25 iteration(s): 0.0919 | Elapsed 3:16:01\n",
      "Epoch: 002/010 | Batch 11201/45709 | Average Loss in last 25 iteration(s): 0.1200 | Elapsed 3:16:26\n",
      "Epoch: 002/010 | Batch 11226/45709 | Average Loss in last 25 iteration(s): 0.1031 | Elapsed 3:16:50\n",
      "Epoch: 002/010 | Batch 11251/45709 | Average Loss in last 25 iteration(s): 0.1395 | Elapsed 3:17:19\n",
      "Epoch: 002/010 | Batch 11276/45709 | Average Loss in last 25 iteration(s): 0.1296 | Elapsed 3:17:46\n",
      "Epoch: 002/010 | Batch 11301/45709 | Average Loss in last 25 iteration(s): 0.1090 | Elapsed 3:18:12\n",
      "Epoch: 002/010 | Batch 11326/45709 | Average Loss in last 25 iteration(s): 0.1060 | Elapsed 3:18:39\n",
      "Epoch: 002/010 | Batch 11351/45709 | Average Loss in last 25 iteration(s): 0.0938 | Elapsed 3:19:06\n",
      "Epoch: 002/010 | Batch 11376/45709 | Average Loss in last 25 iteration(s): 0.0982 | Elapsed 3:19:28\n",
      "Epoch: 002/010 | Batch 11401/45709 | Average Loss in last 25 iteration(s): 0.0895 | Elapsed 3:19:55\n",
      "Epoch: 002/010 | Batch 11426/45709 | Average Loss in last 25 iteration(s): 0.1524 | Elapsed 3:20:22\n",
      "Epoch: 002/010 | Batch 11451/45709 | Average Loss in last 25 iteration(s): 0.1398 | Elapsed 3:20:49\n",
      "Epoch: 002/010 | Batch 11476/45709 | Average Loss in last 25 iteration(s): 0.1240 | Elapsed 3:21:16\n",
      "Epoch: 002/010 | Batch 11501/45709 | Average Loss in last 25 iteration(s): 0.0905 | Elapsed 3:21:42\n",
      "Epoch: 002/010 | Batch 11526/45709 | Average Loss in last 25 iteration(s): 0.1088 | Elapsed 3:22:06\n",
      "Epoch: 002/010 | Batch 11551/45709 | Average Loss in last 25 iteration(s): 0.0941 | Elapsed 3:22:30\n",
      "Epoch: 002/010 | Batch 11576/45709 | Average Loss in last 25 iteration(s): 0.0980 | Elapsed 3:22:57\n",
      "Epoch: 002/010 | Batch 11601/45709 | Average Loss in last 25 iteration(s): 0.1061 | Elapsed 3:23:24\n",
      "Epoch: 002/010 | Batch 11626/45709 | Average Loss in last 25 iteration(s): 0.0827 | Elapsed 3:23:51\n",
      "Epoch: 002/010 | Batch 11651/45709 | Average Loss in last 25 iteration(s): 0.0929 | Elapsed 3:24:17\n",
      "Epoch: 002/010 | Batch 11676/45709 | Average Loss in last 25 iteration(s): 0.1428 | Elapsed 3:24:44\n",
      "Epoch: 002/010 | Batch 11701/45709 | Average Loss in last 25 iteration(s): 0.1181 | Elapsed 3:25:07\n",
      "Epoch: 002/010 | Batch 11726/45709 | Average Loss in last 25 iteration(s): 0.1305 | Elapsed 3:25:35\n",
      "Epoch: 002/010 | Batch 11751/45709 | Average Loss in last 25 iteration(s): 0.1074 | Elapsed 3:26:02\n",
      "Epoch: 002/010 | Batch 11776/45709 | Average Loss in last 25 iteration(s): 0.1026 | Elapsed 3:26:28\n",
      "Epoch: 002/010 | Batch 11801/45709 | Average Loss in last 25 iteration(s): 0.1029 | Elapsed 3:26:56\n",
      "Epoch: 002/010 | Batch 11826/45709 | Average Loss in last 25 iteration(s): 0.1469 | Elapsed 3:27:21\n",
      "Epoch: 002/010 | Batch 11851/45709 | Average Loss in last 25 iteration(s): 0.1247 | Elapsed 3:27:47\n",
      "Epoch: 002/010 | Batch 11876/45709 | Average Loss in last 25 iteration(s): 0.1111 | Elapsed 3:28:10\n",
      "Epoch: 002/010 | Batch 11901/45709 | Average Loss in last 25 iteration(s): 0.1107 | Elapsed 3:28:39\n",
      "Epoch: 002/010 | Batch 11926/45709 | Average Loss in last 25 iteration(s): 0.1182 | Elapsed 3:29:05\n",
      "Epoch: 002/010 | Batch 11951/45709 | Average Loss in last 25 iteration(s): 0.1495 | Elapsed 3:29:33\n",
      "Epoch: 002/010 | Batch 11976/45709 | Average Loss in last 25 iteration(s): 0.1276 | Elapsed 3:29:59\n",
      "Epoch: 002/010 | Batch 12001/45709 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 3:30:25\n",
      "Epoch: 002/010 | Batch 12026/45709 | Average Loss in last 25 iteration(s): 0.1238 | Elapsed 3:30:47\n",
      "Epoch: 002/010 | Batch 12051/45709 | Average Loss in last 25 iteration(s): 0.1308 | Elapsed 3:31:16\n",
      "Epoch: 002/010 | Batch 12076/45709 | Average Loss in last 25 iteration(s): 0.1041 | Elapsed 3:31:43\n",
      "Epoch: 002/010 | Batch 12101/45709 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 3:32:11\n",
      "Epoch: 002/010 | Batch 12126/45709 | Average Loss in last 25 iteration(s): 0.0967 | Elapsed 3:32:37\n",
      "Epoch: 002/010 | Batch 12151/45709 | Average Loss in last 25 iteration(s): 0.1170 | Elapsed 3:33:03\n",
      "Epoch: 002/010 | Batch 12176/45709 | Average Loss in last 25 iteration(s): 0.1010 | Elapsed 3:33:26\n",
      "Epoch: 002/010 | Batch 12201/45709 | Average Loss in last 25 iteration(s): 0.0758 | Elapsed 3:33:52\n",
      "Epoch: 002/010 | Batch 12226/45709 | Average Loss in last 25 iteration(s): 0.1013 | Elapsed 3:34:22\n",
      "Epoch: 002/010 | Batch 12251/45709 | Average Loss in last 25 iteration(s): 0.0940 | Elapsed 3:34:48\n",
      "Epoch: 002/010 | Batch 12276/45709 | Average Loss in last 25 iteration(s): 0.1530 | Elapsed 3:35:15\n",
      "Epoch: 002/010 | Batch 12301/45709 | Average Loss in last 25 iteration(s): 0.1301 | Elapsed 3:35:42\n",
      "Epoch: 002/010 | Batch 12326/45709 | Average Loss in last 25 iteration(s): 0.1397 | Elapsed 3:36:07\n",
      "Epoch: 002/010 | Batch 12351/45709 | Average Loss in last 25 iteration(s): 0.1123 | Elapsed 3:36:30\n",
      "Epoch: 002/010 | Batch 12376/45709 | Average Loss in last 25 iteration(s): 0.0974 | Elapsed 3:36:58\n",
      "Epoch: 002/010 | Batch 12401/45709 | Average Loss in last 25 iteration(s): 0.0962 | Elapsed 3:37:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 12426/45709 | Average Loss in last 25 iteration(s): 0.1281 | Elapsed 3:37:53\n",
      "Epoch: 002/010 | Batch 12451/45709 | Average Loss in last 25 iteration(s): 0.0965 | Elapsed 3:38:20\n",
      "Epoch: 002/010 | Batch 12476/45709 | Average Loss in last 25 iteration(s): 0.1086 | Elapsed 3:38:45\n",
      "Epoch: 002/010 | Batch 12501/45709 | Average Loss in last 25 iteration(s): 0.0850 | Elapsed 3:39:08\n",
      "Epoch: 002/010 | Batch 12526/45709 | Average Loss in last 25 iteration(s): 0.0910 | Elapsed 3:39:35\n",
      "Epoch: 002/010 | Batch 12551/45709 | Average Loss in last 25 iteration(s): 0.0865 | Elapsed 3:40:04\n",
      "Epoch: 002/010 | Batch 12576/45709 | Average Loss in last 25 iteration(s): 0.0725 | Elapsed 3:40:31\n",
      "Epoch: 002/010 | Batch 12601/45709 | Average Loss in last 25 iteration(s): 0.0779 | Elapsed 3:40:59\n",
      "Epoch: 002/010 | Batch 12626/45709 | Average Loss in last 25 iteration(s): 0.1359 | Elapsed 3:41:26\n",
      "Epoch: 002/010 | Batch 12651/45709 | Average Loss in last 25 iteration(s): 0.1127 | Elapsed 3:41:48\n",
      "Epoch: 002/010 | Batch 12676/45709 | Average Loss in last 25 iteration(s): 0.1184 | Elapsed 3:42:13\n",
      "Epoch: 002/010 | Batch 12701/45709 | Average Loss in last 25 iteration(s): 0.0974 | Elapsed 3:42:42\n",
      "Epoch: 002/010 | Batch 12726/45709 | Average Loss in last 25 iteration(s): 0.1061 | Elapsed 3:43:09\n",
      "Epoch: 002/010 | Batch 12751/45709 | Average Loss in last 25 iteration(s): 0.0829 | Elapsed 3:43:36\n",
      "Epoch: 002/010 | Batch 12776/45709 | Average Loss in last 25 iteration(s): 0.1221 | Elapsed 3:44:03\n",
      "Epoch: 002/010 | Batch 12801/45709 | Average Loss in last 25 iteration(s): 0.0931 | Elapsed 3:44:27\n",
      "Epoch: 002/010 | Batch 12826/45709 | Average Loss in last 25 iteration(s): 0.1251 | Elapsed 3:44:54\n",
      "Epoch: 002/010 | Batch 12851/45709 | Average Loss in last 25 iteration(s): 0.1373 | Elapsed 3:45:21\n",
      "Epoch: 002/010 | Batch 12876/45709 | Average Loss in last 25 iteration(s): 0.1322 | Elapsed 3:45:48\n",
      "Epoch: 002/010 | Batch 12901/45709 | Average Loss in last 25 iteration(s): 0.1280 | Elapsed 3:46:15\n",
      "Epoch: 002/010 | Batch 12926/45709 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 3:46:42\n",
      "Epoch: 002/010 | Batch 12951/45709 | Average Loss in last 25 iteration(s): 0.1047 | Elapsed 3:47:06\n",
      "Epoch: 002/010 | Batch 12976/45709 | Average Loss in last 25 iteration(s): 0.1145 | Elapsed 3:47:30\n",
      "Epoch: 002/010 | Batch 13001/45709 | Average Loss in last 25 iteration(s): 0.1042 | Elapsed 3:47:59\n",
      "Epoch: 002/010 | Batch 13026/45709 | Average Loss in last 25 iteration(s): 0.0965 | Elapsed 3:48:24\n",
      "Epoch: 002/010 | Batch 13051/45709 | Average Loss in last 25 iteration(s): 0.1086 | Elapsed 3:48:51\n",
      "Epoch: 002/010 | Batch 13076/45709 | Average Loss in last 25 iteration(s): 0.1050 | Elapsed 3:49:19\n",
      "Epoch: 002/010 | Batch 13101/45709 | Average Loss in last 25 iteration(s): 0.1075 | Elapsed 3:49:45\n",
      "Epoch: 002/010 | Batch 13126/45709 | Average Loss in last 25 iteration(s): 0.1373 | Elapsed 3:50:09\n",
      "Epoch: 002/010 | Batch 13151/45709 | Average Loss in last 25 iteration(s): 0.0787 | Elapsed 3:50:37\n",
      "Epoch: 002/010 | Batch 13176/45709 | Average Loss in last 25 iteration(s): 0.1017 | Elapsed 3:51:04\n",
      "Epoch: 002/010 | Batch 13201/45709 | Average Loss in last 25 iteration(s): 0.1228 | Elapsed 3:51:30\n",
      "Epoch: 002/010 | Batch 13226/45709 | Average Loss in last 25 iteration(s): 0.1198 | Elapsed 3:51:58\n",
      "Epoch: 002/010 | Batch 13251/45709 | Average Loss in last 25 iteration(s): 0.1051 | Elapsed 3:52:24\n",
      "Epoch: 002/010 | Batch 13276/45709 | Average Loss in last 25 iteration(s): 0.0911 | Elapsed 3:52:47\n",
      "Epoch: 002/010 | Batch 13301/45709 | Average Loss in last 25 iteration(s): 0.1291 | Elapsed 3:53:16\n",
      "Epoch: 002/010 | Batch 13326/45709 | Average Loss in last 25 iteration(s): 0.0994 | Elapsed 3:53:45\n",
      "Epoch: 002/010 | Batch 13351/45709 | Average Loss in last 25 iteration(s): 0.1514 | Elapsed 3:54:12\n",
      "Epoch: 002/010 | Batch 13376/45709 | Average Loss in last 25 iteration(s): 0.0975 | Elapsed 3:54:38\n",
      "Epoch: 002/010 | Batch 13401/45709 | Average Loss in last 25 iteration(s): 0.0624 | Elapsed 3:55:02\n",
      "Epoch: 002/010 | Batch 13426/45709 | Average Loss in last 25 iteration(s): 0.1641 | Elapsed 3:55:27\n",
      "Epoch: 002/010 | Batch 13451/45709 | Average Loss in last 25 iteration(s): 0.0895 | Elapsed 3:55:56\n",
      "Epoch: 002/010 | Batch 13476/45709 | Average Loss in last 25 iteration(s): 0.1271 | Elapsed 3:56:21\n",
      "Epoch: 002/010 | Batch 13501/45709 | Average Loss in last 25 iteration(s): 0.0987 | Elapsed 3:56:48\n",
      "Epoch: 002/010 | Batch 13526/45709 | Average Loss in last 25 iteration(s): 0.0742 | Elapsed 3:57:14\n",
      "Epoch: 002/010 | Batch 13551/45709 | Average Loss in last 25 iteration(s): 0.1111 | Elapsed 3:57:41\n",
      "Epoch: 002/010 | Batch 13576/45709 | Average Loss in last 25 iteration(s): 0.1588 | Elapsed 3:58:04\n",
      "Epoch: 002/010 | Batch 13601/45709 | Average Loss in last 25 iteration(s): 0.1053 | Elapsed 3:58:33\n",
      "Epoch: 002/010 | Batch 13626/45709 | Average Loss in last 25 iteration(s): 0.1365 | Elapsed 3:59:01\n",
      "Epoch: 002/010 | Batch 13651/45709 | Average Loss in last 25 iteration(s): 0.1106 | Elapsed 3:59:27\n",
      "Epoch: 002/010 | Batch 13676/45709 | Average Loss in last 25 iteration(s): 0.1124 | Elapsed 3:59:53\n",
      "Epoch: 002/010 | Batch 13701/45709 | Average Loss in last 25 iteration(s): 0.0809 | Elapsed 4:00:20\n",
      "Epoch: 002/010 | Batch 13726/45709 | Average Loss in last 25 iteration(s): 0.1019 | Elapsed 4:00:42\n",
      "Epoch: 002/010 | Batch 13751/45709 | Average Loss in last 25 iteration(s): 0.1072 | Elapsed 4:01:10\n",
      "Epoch: 002/010 | Batch 13776/45709 | Average Loss in last 25 iteration(s): 0.1026 | Elapsed 4:01:38\n",
      "Epoch: 002/010 | Batch 13801/45709 | Average Loss in last 25 iteration(s): 0.0882 | Elapsed 4:02:04\n",
      "Epoch: 002/010 | Batch 13826/45709 | Average Loss in last 25 iteration(s): 0.1043 | Elapsed 4:02:30\n",
      "Epoch: 002/010 | Batch 13851/45709 | Average Loss in last 25 iteration(s): 0.1178 | Elapsed 4:02:57\n",
      "Epoch: 002/010 | Batch 13876/45709 | Average Loss in last 25 iteration(s): 0.0952 | Elapsed 4:03:20\n",
      "Epoch: 002/010 | Batch 13901/45709 | Average Loss in last 25 iteration(s): 0.1161 | Elapsed 4:03:45\n",
      "Epoch: 002/010 | Batch 13926/45709 | Average Loss in last 25 iteration(s): 0.0973 | Elapsed 4:04:14\n",
      "Epoch: 002/010 | Batch 13951/45709 | Average Loss in last 25 iteration(s): 0.1007 | Elapsed 4:04:39\n",
      "Epoch: 002/010 | Batch 13976/45709 | Average Loss in last 25 iteration(s): 0.0976 | Elapsed 4:05:05\n",
      "Epoch: 002/010 | Batch 14001/45709 | Average Loss in last 25 iteration(s): 0.1103 | Elapsed 4:05:32\n",
      "Epoch: 002/010 | Batch 14026/45709 | Average Loss in last 25 iteration(s): 0.0889 | Elapsed 4:05:59\n",
      "Epoch: 002/010 | Batch 14051/45709 | Average Loss in last 25 iteration(s): 0.1389 | Elapsed 4:06:22\n",
      "Epoch: 002/010 | Batch 14076/45709 | Average Loss in last 25 iteration(s): 0.1322 | Elapsed 4:06:50\n",
      "Epoch: 002/010 | Batch 14101/45709 | Average Loss in last 25 iteration(s): 0.1255 | Elapsed 4:07:17\n",
      "Epoch: 002/010 | Batch 14126/45709 | Average Loss in last 25 iteration(s): 0.1185 | Elapsed 4:07:43\n",
      "Epoch: 002/010 | Batch 14151/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 4:08:12\n",
      "Epoch: 002/010 | Batch 14176/45709 | Average Loss in last 25 iteration(s): 0.1121 | Elapsed 4:08:37\n",
      "Epoch: 002/010 | Batch 14201/45709 | Average Loss in last 25 iteration(s): 0.0820 | Elapsed 4:09:01\n",
      "Epoch: 002/010 | Batch 14226/45709 | Average Loss in last 25 iteration(s): 0.0659 | Elapsed 4:09:28\n",
      "Epoch: 002/010 | Batch 14251/45709 | Average Loss in last 25 iteration(s): 0.1303 | Elapsed 4:09:57\n",
      "Epoch: 002/010 | Batch 14276/45709 | Average Loss in last 25 iteration(s): 0.0926 | Elapsed 4:10:24\n",
      "Epoch: 002/010 | Batch 14301/45709 | Average Loss in last 25 iteration(s): 0.1006 | Elapsed 4:10:50\n",
      "Epoch: 002/010 | Batch 14326/45709 | Average Loss in last 25 iteration(s): 0.1163 | Elapsed 4:11:16\n",
      "Epoch: 002/010 | Batch 14351/45709 | Average Loss in last 25 iteration(s): 0.1274 | Elapsed 4:11:38\n",
      "Epoch: 002/010 | Batch 14376/45709 | Average Loss in last 25 iteration(s): 0.0935 | Elapsed 4:12:05\n",
      "Epoch: 002/010 | Batch 14401/45709 | Average Loss in last 25 iteration(s): 0.0966 | Elapsed 4:12:35\n",
      "Epoch: 002/010 | Batch 14426/45709 | Average Loss in last 25 iteration(s): 0.1198 | Elapsed 4:13:01\n",
      "Epoch: 002/010 | Batch 14451/45709 | Average Loss in last 25 iteration(s): 0.1044 | Elapsed 4:13:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 14476/45709 | Average Loss in last 25 iteration(s): 0.1216 | Elapsed 4:13:52\n",
      "Epoch: 002/010 | Batch 14501/45709 | Average Loss in last 25 iteration(s): 0.0952 | Elapsed 4:14:15\n",
      "Epoch: 002/010 | Batch 14526/45709 | Average Loss in last 25 iteration(s): 0.1100 | Elapsed 4:14:41\n",
      "Epoch: 002/010 | Batch 14551/45709 | Average Loss in last 25 iteration(s): 0.1422 | Elapsed 4:15:10\n",
      "Epoch: 002/010 | Batch 14576/45709 | Average Loss in last 25 iteration(s): 0.1156 | Elapsed 4:15:36\n",
      "Epoch: 002/010 | Batch 14601/45709 | Average Loss in last 25 iteration(s): 0.0921 | Elapsed 4:16:02\n",
      "Epoch: 002/010 | Batch 14626/45709 | Average Loss in last 25 iteration(s): 0.1191 | Elapsed 4:16:27\n",
      "Epoch: 002/010 | Batch 14651/45709 | Average Loss in last 25 iteration(s): 0.0782 | Elapsed 4:16:53\n",
      "Epoch: 002/010 | Batch 14676/45709 | Average Loss in last 25 iteration(s): 0.1282 | Elapsed 4:17:16\n",
      "Epoch: 002/010 | Batch 14701/45709 | Average Loss in last 25 iteration(s): 0.1158 | Elapsed 4:17:46\n",
      "Epoch: 002/010 | Batch 14726/45709 | Average Loss in last 25 iteration(s): 0.1091 | Elapsed 4:18:11\n",
      "Epoch: 002/010 | Batch 14751/45709 | Average Loss in last 25 iteration(s): 0.0873 | Elapsed 4:18:37\n",
      "Epoch: 002/010 | Batch 14776/45709 | Average Loss in last 25 iteration(s): 0.1053 | Elapsed 4:19:02\n",
      "Epoch: 002/010 | Batch 14801/45709 | Average Loss in last 25 iteration(s): 0.0531 | Elapsed 4:19:29\n",
      "Epoch: 002/010 | Batch 14826/45709 | Average Loss in last 25 iteration(s): 0.1115 | Elapsed 4:19:52\n",
      "Epoch: 002/010 | Batch 14851/45709 | Average Loss in last 25 iteration(s): 0.1067 | Elapsed 4:20:19\n",
      "Epoch: 002/010 | Batch 14876/45709 | Average Loss in last 25 iteration(s): 0.1028 | Elapsed 4:20:48\n",
      "Epoch: 002/010 | Batch 14901/45709 | Average Loss in last 25 iteration(s): 0.1127 | Elapsed 4:21:14\n",
      "Epoch: 002/010 | Batch 14926/45709 | Average Loss in last 25 iteration(s): 0.1206 | Elapsed 4:21:41\n",
      "Epoch: 002/010 | Batch 14951/45709 | Average Loss in last 25 iteration(s): 0.0889 | Elapsed 4:22:06\n",
      "Epoch: 002/010 | Batch 14976/45709 | Average Loss in last 25 iteration(s): 0.1115 | Elapsed 4:22:31\n",
      "Epoch: 002/010 | Batch 15001/45709 | Average Loss in last 25 iteration(s): 0.1178 | Elapsed 4:22:56\n",
      "Epoch: 002/010 | Batch 15026/45709 | Average Loss in last 25 iteration(s): 0.1048 | Elapsed 4:23:26\n",
      "Epoch: 002/010 | Batch 15051/45709 | Average Loss in last 25 iteration(s): 0.1131 | Elapsed 4:23:53\n",
      "Epoch: 002/010 | Batch 15076/45709 | Average Loss in last 25 iteration(s): 0.1113 | Elapsed 4:24:19\n",
      "Epoch: 002/010 | Batch 15101/45709 | Average Loss in last 25 iteration(s): 0.1098 | Elapsed 4:24:45\n",
      "Epoch: 002/010 | Batch 15126/45709 | Average Loss in last 25 iteration(s): 0.1024 | Elapsed 4:25:10\n",
      "Epoch: 002/010 | Batch 15151/45709 | Average Loss in last 25 iteration(s): 0.0996 | Elapsed 4:25:33\n",
      "Epoch: 002/010 | Batch 15176/45709 | Average Loss in last 25 iteration(s): 0.0905 | Elapsed 4:26:02\n",
      "Epoch: 002/010 | Batch 15201/45709 | Average Loss in last 25 iteration(s): 0.1176 | Elapsed 4:26:31\n",
      "Epoch: 002/010 | Batch 15226/45709 | Average Loss in last 25 iteration(s): 0.1222 | Elapsed 4:26:57\n",
      "Epoch: 002/010 | Batch 15251/45709 | Average Loss in last 25 iteration(s): 0.1042 | Elapsed 4:27:24\n",
      "Epoch: 002/010 | Batch 15276/45709 | Average Loss in last 25 iteration(s): 0.1235 | Elapsed 4:27:50\n",
      "Epoch: 002/010 | Batch 15301/45709 | Average Loss in last 25 iteration(s): 0.1537 | Elapsed 4:28:12\n",
      "Epoch: 002/010 | Batch 15326/45709 | Average Loss in last 25 iteration(s): 0.1400 | Elapsed 4:28:40\n",
      "Epoch: 002/010 | Batch 15351/45709 | Average Loss in last 25 iteration(s): 0.0728 | Elapsed 4:29:08\n",
      "Epoch: 002/010 | Batch 15376/45709 | Average Loss in last 25 iteration(s): 0.0977 | Elapsed 4:29:35\n",
      "Epoch: 002/010 | Batch 15401/45709 | Average Loss in last 25 iteration(s): 0.0895 | Elapsed 4:30:03\n",
      "Epoch: 002/010 | Batch 15426/45709 | Average Loss in last 25 iteration(s): 0.1143 | Elapsed 4:30:30\n",
      "Epoch: 002/010 | Batch 15451/45709 | Average Loss in last 25 iteration(s): 0.1054 | Elapsed 4:30:53\n",
      "Epoch: 002/010 | Batch 15476/45709 | Average Loss in last 25 iteration(s): 0.1007 | Elapsed 4:31:21\n",
      "Epoch: 002/010 | Batch 15501/45709 | Average Loss in last 25 iteration(s): 0.1052 | Elapsed 4:31:49\n",
      "Epoch: 002/010 | Batch 15526/45709 | Average Loss in last 25 iteration(s): 0.1191 | Elapsed 4:32:14\n",
      "Epoch: 002/010 | Batch 15551/45709 | Average Loss in last 25 iteration(s): 0.1345 | Elapsed 4:32:42\n",
      "Epoch: 002/010 | Batch 15576/45709 | Average Loss in last 25 iteration(s): 0.1328 | Elapsed 4:33:09\n",
      "Epoch: 002/010 | Batch 15601/45709 | Average Loss in last 25 iteration(s): 0.0973 | Elapsed 4:33:33\n",
      "Epoch: 002/010 | Batch 15626/45709 | Average Loss in last 25 iteration(s): 0.1302 | Elapsed 4:33:59\n",
      "Epoch: 002/010 | Batch 15651/45709 | Average Loss in last 25 iteration(s): 0.1163 | Elapsed 4:34:27\n",
      "Epoch: 002/010 | Batch 15676/45709 | Average Loss in last 25 iteration(s): 0.1482 | Elapsed 4:34:55\n",
      "Epoch: 002/010 | Batch 15701/45709 | Average Loss in last 25 iteration(s): 0.0968 | Elapsed 4:35:24\n",
      "Epoch: 002/010 | Batch 15726/45709 | Average Loss in last 25 iteration(s): 0.0981 | Elapsed 4:35:49\n",
      "Epoch: 002/010 | Batch 15751/45709 | Average Loss in last 25 iteration(s): 0.0974 | Elapsed 4:36:12\n",
      "Epoch: 002/010 | Batch 15776/45709 | Average Loss in last 25 iteration(s): 0.1552 | Elapsed 4:36:42\n",
      "Epoch: 002/010 | Batch 15801/45709 | Average Loss in last 25 iteration(s): 0.0866 | Elapsed 4:37:11\n",
      "Epoch: 002/010 | Batch 15826/45709 | Average Loss in last 25 iteration(s): 0.0964 | Elapsed 4:37:42\n",
      "Epoch: 002/010 | Batch 15851/45709 | Average Loss in last 25 iteration(s): 0.0787 | Elapsed 4:38:08\n",
      "Epoch: 002/010 | Batch 15876/45709 | Average Loss in last 25 iteration(s): 0.0970 | Elapsed 4:38:30\n",
      "Epoch: 002/010 | Batch 15901/45709 | Average Loss in last 25 iteration(s): 0.1345 | Elapsed 4:38:54\n",
      "Epoch: 002/010 | Batch 15926/45709 | Average Loss in last 25 iteration(s): 0.1465 | Elapsed 4:39:22\n",
      "Epoch: 002/010 | Batch 15951/45709 | Average Loss in last 25 iteration(s): 0.1067 | Elapsed 4:39:52\n",
      "Epoch: 002/010 | Batch 15976/45709 | Average Loss in last 25 iteration(s): 0.0863 | Elapsed 4:40:20\n",
      "Epoch: 002/010 | Batch 16001/45709 | Average Loss in last 25 iteration(s): 0.0966 | Elapsed 4:40:46\n",
      "Epoch: 002/010 | Batch 16026/45709 | Average Loss in last 25 iteration(s): 0.0829 | Elapsed 4:41:10\n",
      "Epoch: 002/010 | Batch 16051/45709 | Average Loss in last 25 iteration(s): 0.0810 | Elapsed 4:41:37\n",
      "Epoch: 002/010 | Batch 16076/45709 | Average Loss in last 25 iteration(s): 0.0941 | Elapsed 4:42:01\n",
      "Epoch: 002/010 | Batch 16101/45709 | Average Loss in last 25 iteration(s): 0.1548 | Elapsed 4:42:31\n",
      "Epoch: 002/010 | Batch 16126/45709 | Average Loss in last 25 iteration(s): 0.1123 | Elapsed 4:42:57\n",
      "Epoch: 002/010 | Batch 16151/45709 | Average Loss in last 25 iteration(s): 0.1000 | Elapsed 4:43:25\n",
      "Epoch: 002/010 | Batch 16176/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 4:43:50\n",
      "Epoch: 002/010 | Batch 16201/45709 | Average Loss in last 25 iteration(s): 0.0990 | Elapsed 4:44:17\n",
      "Epoch: 002/010 | Batch 16226/45709 | Average Loss in last 25 iteration(s): 0.0924 | Elapsed 4:44:46\n",
      "Epoch: 002/010 | Batch 16251/45709 | Average Loss in last 25 iteration(s): 0.0661 | Elapsed 4:45:12\n",
      "Epoch: 002/010 | Batch 16276/45709 | Average Loss in last 25 iteration(s): 0.0954 | Elapsed 4:45:39\n",
      "Epoch: 002/010 | Batch 16301/45709 | Average Loss in last 25 iteration(s): 0.1267 | Elapsed 4:46:05\n",
      "Epoch: 002/010 | Batch 16326/45709 | Average Loss in last 25 iteration(s): 0.1185 | Elapsed 4:46:29\n",
      "Epoch: 002/010 | Batch 16351/45709 | Average Loss in last 25 iteration(s): 0.1023 | Elapsed 4:46:53\n",
      "Epoch: 002/010 | Batch 16376/45709 | Average Loss in last 25 iteration(s): 0.1172 | Elapsed 4:47:24\n",
      "Epoch: 002/010 | Batch 16401/45709 | Average Loss in last 25 iteration(s): 0.1027 | Elapsed 4:47:53\n",
      "Epoch: 002/010 | Batch 16426/45709 | Average Loss in last 25 iteration(s): 0.1284 | Elapsed 4:48:18\n",
      "Epoch: 002/010 | Batch 16451/45709 | Average Loss in last 25 iteration(s): 0.0964 | Elapsed 4:48:45\n",
      "Epoch: 002/010 | Batch 16476/45709 | Average Loss in last 25 iteration(s): 0.1031 | Elapsed 4:49:09\n",
      "Epoch: 002/010 | Batch 16501/45709 | Average Loss in last 25 iteration(s): 0.1476 | Elapsed 4:49:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 16526/45709 | Average Loss in last 25 iteration(s): 0.1028 | Elapsed 4:50:04\n",
      "Epoch: 002/010 | Batch 16551/45709 | Average Loss in last 25 iteration(s): 0.1112 | Elapsed 4:50:30\n",
      "Epoch: 002/010 | Batch 16576/45709 | Average Loss in last 25 iteration(s): 0.0938 | Elapsed 4:50:58\n",
      "Epoch: 002/010 | Batch 16601/45709 | Average Loss in last 25 iteration(s): 0.0944 | Elapsed 4:51:25\n",
      "Epoch: 002/010 | Batch 16626/45709 | Average Loss in last 25 iteration(s): 0.1151 | Elapsed 4:51:47\n",
      "Epoch: 002/010 | Batch 16651/45709 | Average Loss in last 25 iteration(s): 0.1211 | Elapsed 4:52:11\n",
      "Epoch: 002/010 | Batch 16676/45709 | Average Loss in last 25 iteration(s): 0.0953 | Elapsed 4:52:41\n",
      "Epoch: 002/010 | Batch 16701/45709 | Average Loss in last 25 iteration(s): 0.0925 | Elapsed 4:53:10\n",
      "Epoch: 002/010 | Batch 16726/45709 | Average Loss in last 25 iteration(s): 0.0739 | Elapsed 4:53:33\n",
      "Epoch: 002/010 | Batch 16751/45709 | Average Loss in last 25 iteration(s): 0.0911 | Elapsed 4:53:59\n",
      "Epoch: 002/010 | Batch 16776/45709 | Average Loss in last 25 iteration(s): 0.1777 | Elapsed 4:54:28\n",
      "Epoch: 002/010 | Batch 16801/45709 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 4:54:50\n",
      "Epoch: 002/010 | Batch 16826/45709 | Average Loss in last 25 iteration(s): 0.1226 | Elapsed 4:55:17\n",
      "Epoch: 002/010 | Batch 16851/45709 | Average Loss in last 25 iteration(s): 0.1374 | Elapsed 4:55:46\n",
      "Epoch: 002/010 | Batch 16876/45709 | Average Loss in last 25 iteration(s): 0.1247 | Elapsed 4:56:11\n",
      "Epoch: 002/010 | Batch 16901/45709 | Average Loss in last 25 iteration(s): 0.1148 | Elapsed 4:56:38\n",
      "Epoch: 002/010 | Batch 16926/45709 | Average Loss in last 25 iteration(s): 0.1023 | Elapsed 4:57:04\n",
      "Epoch: 002/010 | Batch 16951/45709 | Average Loss in last 25 iteration(s): 0.0966 | Elapsed 4:57:28\n",
      "Epoch: 002/010 | Batch 16976/45709 | Average Loss in last 25 iteration(s): 0.1140 | Elapsed 4:57:52\n",
      "Epoch: 002/010 | Batch 17001/45709 | Average Loss in last 25 iteration(s): 0.1394 | Elapsed 4:58:22\n",
      "Epoch: 002/010 | Batch 17026/45709 | Average Loss in last 25 iteration(s): 0.1396 | Elapsed 4:58:49\n",
      "Epoch: 002/010 | Batch 17051/45709 | Average Loss in last 25 iteration(s): 0.1308 | Elapsed 4:59:15\n",
      "Epoch: 002/010 | Batch 17076/45709 | Average Loss in last 25 iteration(s): 0.1084 | Elapsed 4:59:41\n",
      "Epoch: 002/010 | Batch 17101/45709 | Average Loss in last 25 iteration(s): 0.0697 | Elapsed 5:00:09\n",
      "Epoch: 002/010 | Batch 17126/45709 | Average Loss in last 25 iteration(s): 0.0856 | Elapsed 5:00:32\n",
      "Epoch: 002/010 | Batch 17151/45709 | Average Loss in last 25 iteration(s): 0.1236 | Elapsed 5:00:58\n",
      "Epoch: 002/010 | Batch 17176/45709 | Average Loss in last 25 iteration(s): 0.0847 | Elapsed 5:01:25\n",
      "Epoch: 002/010 | Batch 17201/45709 | Average Loss in last 25 iteration(s): 0.1284 | Elapsed 5:01:52\n",
      "Epoch: 002/010 | Batch 17226/45709 | Average Loss in last 25 iteration(s): 0.1399 | Elapsed 5:02:20\n",
      "Epoch: 002/010 | Batch 17251/45709 | Average Loss in last 25 iteration(s): 0.0982 | Elapsed 5:02:45\n",
      "Epoch: 002/010 | Batch 17276/45709 | Average Loss in last 25 iteration(s): 0.1269 | Elapsed 5:03:09\n",
      "Epoch: 002/010 | Batch 17301/45709 | Average Loss in last 25 iteration(s): 0.0959 | Elapsed 5:03:37\n",
      "Epoch: 002/010 | Batch 17326/45709 | Average Loss in last 25 iteration(s): 0.1237 | Elapsed 5:04:02\n",
      "Epoch: 002/010 | Batch 17351/45709 | Average Loss in last 25 iteration(s): 0.0854 | Elapsed 5:04:30\n",
      "Epoch: 002/010 | Batch 17376/45709 | Average Loss in last 25 iteration(s): 0.1365 | Elapsed 5:04:57\n",
      "Epoch: 002/010 | Batch 17401/45709 | Average Loss in last 25 iteration(s): 0.0870 | Elapsed 5:05:22\n",
      "Epoch: 002/010 | Batch 17426/45709 | Average Loss in last 25 iteration(s): 0.1000 | Elapsed 5:05:48\n",
      "Epoch: 002/010 | Batch 17451/45709 | Average Loss in last 25 iteration(s): 0.0875 | Elapsed 5:06:11\n",
      "Epoch: 002/010 | Batch 17476/45709 | Average Loss in last 25 iteration(s): 0.1073 | Elapsed 5:06:39\n",
      "Epoch: 002/010 | Batch 17501/45709 | Average Loss in last 25 iteration(s): 0.1383 | Elapsed 5:07:07\n",
      "Epoch: 002/010 | Batch 17526/45709 | Average Loss in last 25 iteration(s): 0.0860 | Elapsed 5:07:34\n",
      "Epoch: 002/010 | Batch 17551/45709 | Average Loss in last 25 iteration(s): 0.1242 | Elapsed 5:08:02\n",
      "Epoch: 002/010 | Batch 17576/45709 | Average Loss in last 25 iteration(s): 0.1047 | Elapsed 5:08:29\n",
      "Epoch: 002/010 | Batch 17601/45709 | Average Loss in last 25 iteration(s): 0.1048 | Elapsed 5:08:52\n",
      "Epoch: 002/010 | Batch 17626/45709 | Average Loss in last 25 iteration(s): 0.1090 | Elapsed 5:09:18\n",
      "Epoch: 002/010 | Batch 17651/45709 | Average Loss in last 25 iteration(s): 0.0962 | Elapsed 5:09:46\n",
      "Epoch: 002/010 | Batch 17676/45709 | Average Loss in last 25 iteration(s): 0.0700 | Elapsed 5:10:14\n",
      "Epoch: 002/010 | Batch 17701/45709 | Average Loss in last 25 iteration(s): 0.1191 | Elapsed 5:10:41\n",
      "Epoch: 002/010 | Batch 17726/45709 | Average Loss in last 25 iteration(s): 0.1238 | Elapsed 5:11:08\n",
      "Epoch: 002/010 | Batch 17751/45709 | Average Loss in last 25 iteration(s): 0.1067 | Elapsed 5:11:34\n",
      "Epoch: 002/010 | Batch 17776/45709 | Average Loss in last 25 iteration(s): 0.0941 | Elapsed 5:11:57\n",
      "Epoch: 002/010 | Batch 17801/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 5:12:26\n",
      "Epoch: 002/010 | Batch 17826/45709 | Average Loss in last 25 iteration(s): 0.0833 | Elapsed 5:12:53\n",
      "Epoch: 002/010 | Batch 17851/45709 | Average Loss in last 25 iteration(s): 0.0938 | Elapsed 5:13:20\n",
      "Epoch: 002/010 | Batch 17876/45709 | Average Loss in last 25 iteration(s): 0.0998 | Elapsed 5:13:46\n",
      "Epoch: 002/010 | Batch 17901/45709 | Average Loss in last 25 iteration(s): 0.1018 | Elapsed 5:14:10\n",
      "Epoch: 002/010 | Batch 17926/45709 | Average Loss in last 25 iteration(s): 0.0586 | Elapsed 5:14:40\n",
      "Epoch: 002/010 | Batch 17951/45709 | Average Loss in last 25 iteration(s): 0.1569 | Elapsed 5:15:05\n",
      "Epoch: 002/010 | Batch 17976/45709 | Average Loss in last 25 iteration(s): 0.1311 | Elapsed 5:15:34\n",
      "Epoch: 002/010 | Batch 18001/45709 | Average Loss in last 25 iteration(s): 0.0895 | Elapsed 5:16:01\n",
      "Epoch: 002/010 | Batch 18026/45709 | Average Loss in last 25 iteration(s): 0.1178 | Elapsed 5:16:27\n",
      "Epoch: 002/010 | Batch 18051/45709 | Average Loss in last 25 iteration(s): 0.0632 | Elapsed 5:16:48\n",
      "Epoch: 002/010 | Batch 18076/45709 | Average Loss in last 25 iteration(s): 0.1223 | Elapsed 5:17:20\n",
      "Epoch: 002/010 | Batch 18101/45709 | Average Loss in last 25 iteration(s): 0.0919 | Elapsed 5:17:49\n",
      "Epoch: 002/010 | Batch 18126/45709 | Average Loss in last 25 iteration(s): 0.1086 | Elapsed 5:18:14\n",
      "Epoch: 002/010 | Batch 18151/45709 | Average Loss in last 25 iteration(s): 0.1241 | Elapsed 5:18:37\n",
      "Epoch: 002/010 | Batch 18176/45709 | Average Loss in last 25 iteration(s): 0.0984 | Elapsed 5:19:05\n",
      "Epoch: 002/010 | Batch 18201/45709 | Average Loss in last 25 iteration(s): 0.1069 | Elapsed 5:19:28\n",
      "Epoch: 002/010 | Batch 18226/45709 | Average Loss in last 25 iteration(s): 0.1214 | Elapsed 5:19:56\n",
      "Epoch: 002/010 | Batch 18251/45709 | Average Loss in last 25 iteration(s): 0.1087 | Elapsed 5:20:27\n",
      "Epoch: 002/010 | Batch 18276/45709 | Average Loss in last 25 iteration(s): 0.0981 | Elapsed 5:20:53\n",
      "Epoch: 002/010 | Batch 18301/45709 | Average Loss in last 25 iteration(s): 0.0873 | Elapsed 5:21:17\n",
      "Epoch: 002/010 | Batch 18326/45709 | Average Loss in last 25 iteration(s): 0.0618 | Elapsed 5:21:44\n",
      "Epoch: 002/010 | Batch 18351/45709 | Average Loss in last 25 iteration(s): 0.1015 | Elapsed 5:22:09\n",
      "Epoch: 002/010 | Batch 18376/45709 | Average Loss in last 25 iteration(s): 0.0861 | Elapsed 5:22:33\n",
      "Epoch: 002/010 | Batch 18401/45709 | Average Loss in last 25 iteration(s): 0.1410 | Elapsed 5:23:04\n",
      "Epoch: 002/010 | Batch 18426/45709 | Average Loss in last 25 iteration(s): 0.0776 | Elapsed 5:23:30\n",
      "Epoch: 002/010 | Batch 18451/45709 | Average Loss in last 25 iteration(s): 0.0997 | Elapsed 5:24:00\n",
      "Epoch: 002/010 | Batch 18476/45709 | Average Loss in last 25 iteration(s): 0.0744 | Elapsed 5:24:27\n",
      "Epoch: 002/010 | Batch 18501/45709 | Average Loss in last 25 iteration(s): 0.0702 | Elapsed 5:24:51\n",
      "Epoch: 002/010 | Batch 18526/45709 | Average Loss in last 25 iteration(s): 0.1023 | Elapsed 5:25:20\n",
      "Epoch: 002/010 | Batch 18551/45709 | Average Loss in last 25 iteration(s): 0.1237 | Elapsed 5:25:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 18576/45709 | Average Loss in last 25 iteration(s): 0.0940 | Elapsed 5:26:19\n",
      "Epoch: 002/010 | Batch 18601/45709 | Average Loss in last 25 iteration(s): 0.1103 | Elapsed 5:26:46\n",
      "Epoch: 002/010 | Batch 18626/45709 | Average Loss in last 25 iteration(s): 0.0637 | Elapsed 5:27:09\n",
      "Epoch: 002/010 | Batch 18651/45709 | Average Loss in last 25 iteration(s): 0.1441 | Elapsed 5:27:37\n",
      "Epoch: 002/010 | Batch 18676/45709 | Average Loss in last 25 iteration(s): 0.1225 | Elapsed 5:27:59\n",
      "Epoch: 002/010 | Batch 18701/45709 | Average Loss in last 25 iteration(s): 0.1115 | Elapsed 5:28:27\n",
      "Epoch: 002/010 | Batch 18726/45709 | Average Loss in last 25 iteration(s): 0.0909 | Elapsed 5:28:58\n",
      "Epoch: 002/010 | Batch 18751/45709 | Average Loss in last 25 iteration(s): 0.0836 | Elapsed 5:29:26\n",
      "Epoch: 002/010 | Batch 18776/45709 | Average Loss in last 25 iteration(s): 0.0944 | Elapsed 5:29:50\n",
      "Epoch: 002/010 | Batch 18801/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 5:30:17\n",
      "Epoch: 002/010 | Batch 18826/45709 | Average Loss in last 25 iteration(s): 0.0939 | Elapsed 5:30:43\n",
      "Epoch: 002/010 | Batch 18851/45709 | Average Loss in last 25 iteration(s): 0.1389 | Elapsed 5:31:08\n",
      "Epoch: 002/010 | Batch 18876/45709 | Average Loss in last 25 iteration(s): 0.1133 | Elapsed 5:31:37\n",
      "Epoch: 002/010 | Batch 18901/45709 | Average Loss in last 25 iteration(s): 0.0824 | Elapsed 5:32:04\n",
      "Epoch: 002/010 | Batch 18926/45709 | Average Loss in last 25 iteration(s): 0.1246 | Elapsed 5:32:29\n",
      "Epoch: 002/010 | Batch 18951/45709 | Average Loss in last 25 iteration(s): 0.0762 | Elapsed 5:32:52\n",
      "Epoch: 002/010 | Batch 18976/45709 | Average Loss in last 25 iteration(s): 0.0853 | Elapsed 5:33:20\n",
      "Epoch: 002/010 | Batch 19001/45709 | Average Loss in last 25 iteration(s): 0.1078 | Elapsed 5:33:49\n",
      "Epoch: 002/010 | Batch 19026/45709 | Average Loss in last 25 iteration(s): 0.0837 | Elapsed 5:34:15\n",
      "Epoch: 002/010 | Batch 19051/45709 | Average Loss in last 25 iteration(s): 0.1205 | Elapsed 5:34:39\n",
      "Epoch: 002/010 | Batch 19076/45709 | Average Loss in last 25 iteration(s): 0.0919 | Elapsed 5:35:05\n",
      "Epoch: 002/010 | Batch 19101/45709 | Average Loss in last 25 iteration(s): 0.1357 | Elapsed 5:35:29\n",
      "Epoch: 002/010 | Batch 19126/45709 | Average Loss in last 25 iteration(s): 0.0851 | Elapsed 5:35:56\n",
      "Epoch: 002/010 | Batch 19151/45709 | Average Loss in last 25 iteration(s): 0.0693 | Elapsed 5:36:25\n",
      "Epoch: 002/010 | Batch 19176/45709 | Average Loss in last 25 iteration(s): 0.1109 | Elapsed 5:36:52\n",
      "Epoch: 002/010 | Batch 19201/45709 | Average Loss in last 25 iteration(s): 0.0807 | Elapsed 5:37:19\n",
      "Epoch: 002/010 | Batch 19226/45709 | Average Loss in last 25 iteration(s): 0.0937 | Elapsed 5:37:41\n",
      "Epoch: 002/010 | Batch 19251/45709 | Average Loss in last 25 iteration(s): 0.0950 | Elapsed 5:38:09\n",
      "Epoch: 002/010 | Batch 19276/45709 | Average Loss in last 25 iteration(s): 0.1084 | Elapsed 5:38:33\n",
      "Epoch: 002/010 | Batch 19301/45709 | Average Loss in last 25 iteration(s): 0.1202 | Elapsed 5:39:01\n",
      "Epoch: 002/010 | Batch 19326/45709 | Average Loss in last 25 iteration(s): 0.0952 | Elapsed 5:39:29\n",
      "Epoch: 002/010 | Batch 19351/45709 | Average Loss in last 25 iteration(s): 0.0823 | Elapsed 5:39:56\n",
      "Epoch: 002/010 | Batch 19376/45709 | Average Loss in last 25 iteration(s): 0.0969 | Elapsed 5:40:21\n",
      "Epoch: 002/010 | Batch 19401/45709 | Average Loss in last 25 iteration(s): 0.1179 | Elapsed 5:40:47\n",
      "Epoch: 002/010 | Batch 19426/45709 | Average Loss in last 25 iteration(s): 0.1214 | Elapsed 5:41:10\n",
      "Epoch: 002/010 | Batch 19451/45709 | Average Loss in last 25 iteration(s): 0.1120 | Elapsed 5:41:38\n",
      "Epoch: 002/010 | Batch 19476/45709 | Average Loss in last 25 iteration(s): 0.0983 | Elapsed 5:42:07\n",
      "Epoch: 002/010 | Batch 19501/45709 | Average Loss in last 25 iteration(s): 0.0918 | Elapsed 5:42:32\n",
      "Epoch: 002/010 | Batch 19526/45709 | Average Loss in last 25 iteration(s): 0.1105 | Elapsed 5:43:00\n",
      "Epoch: 002/010 | Batch 19551/45709 | Average Loss in last 25 iteration(s): 0.0808 | Elapsed 5:43:28\n",
      "Epoch: 002/010 | Batch 19576/45709 | Average Loss in last 25 iteration(s): 0.1033 | Elapsed 5:43:50\n",
      "Epoch: 002/010 | Batch 19601/45709 | Average Loss in last 25 iteration(s): 0.1167 | Elapsed 5:44:16\n",
      "Epoch: 002/010 | Batch 19626/45709 | Average Loss in last 25 iteration(s): 0.0917 | Elapsed 5:44:46\n",
      "Epoch: 002/010 | Batch 19651/45709 | Average Loss in last 25 iteration(s): 0.1002 | Elapsed 5:45:13\n",
      "Epoch: 002/010 | Batch 19676/45709 | Average Loss in last 25 iteration(s): 0.1212 | Elapsed 5:45:39\n",
      "Epoch: 002/010 | Batch 19701/45709 | Average Loss in last 25 iteration(s): 0.0977 | Elapsed 5:46:05\n",
      "Epoch: 002/010 | Batch 19726/45709 | Average Loss in last 25 iteration(s): 0.0743 | Elapsed 5:46:30\n",
      "Epoch: 002/010 | Batch 19751/45709 | Average Loss in last 25 iteration(s): 0.1166 | Elapsed 5:46:58\n",
      "Epoch: 002/010 | Batch 19776/45709 | Average Loss in last 25 iteration(s): 0.1289 | Elapsed 5:47:29\n",
      "Epoch: 002/010 | Batch 19801/45709 | Average Loss in last 25 iteration(s): 0.1014 | Elapsed 5:47:54\n",
      "Epoch: 002/010 | Batch 19826/45709 | Average Loss in last 25 iteration(s): 0.0921 | Elapsed 5:48:22\n",
      "Epoch: 002/010 | Batch 19851/45709 | Average Loss in last 25 iteration(s): 0.0794 | Elapsed 5:48:49\n",
      "Epoch: 002/010 | Batch 19876/45709 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 5:49:14\n",
      "Epoch: 002/010 | Batch 19901/45709 | Average Loss in last 25 iteration(s): 0.1121 | Elapsed 5:49:43\n",
      "Epoch: 002/010 | Batch 19926/45709 | Average Loss in last 25 iteration(s): 0.1186 | Elapsed 5:50:08\n",
      "Epoch: 002/010 | Batch 19951/45709 | Average Loss in last 25 iteration(s): 0.1025 | Elapsed 5:50:35\n",
      "Epoch: 002/010 | Batch 19976/45709 | Average Loss in last 25 iteration(s): 0.1147 | Elapsed 5:51:02\n",
      "Epoch: 002/010 | Batch 20001/45709 | Average Loss in last 25 iteration(s): 0.0865 | Elapsed 5:51:29\n",
      "Epoch: 002/010 | Batch 20026/45709 | Average Loss in last 25 iteration(s): 0.0730 | Elapsed 5:51:51\n",
      "Epoch: 002/010 | Batch 20051/45709 | Average Loss in last 25 iteration(s): 0.0694 | Elapsed 5:52:19\n",
      "Epoch: 002/010 | Batch 20076/45709 | Average Loss in last 25 iteration(s): 0.1319 | Elapsed 5:52:50\n",
      "Epoch: 002/010 | Batch 20101/45709 | Average Loss in last 25 iteration(s): 0.0985 | Elapsed 5:53:13\n",
      "Epoch: 002/010 | Batch 20126/45709 | Average Loss in last 25 iteration(s): 0.0951 | Elapsed 5:53:41\n",
      "Epoch: 002/010 | Batch 20151/45709 | Average Loss in last 25 iteration(s): 0.1324 | Elapsed 5:54:09\n",
      "Epoch: 002/010 | Batch 20176/45709 | Average Loss in last 25 iteration(s): 0.1039 | Elapsed 5:54:32\n",
      "Epoch: 002/010 | Batch 20201/45709 | Average Loss in last 25 iteration(s): 0.0627 | Elapsed 5:54:57\n",
      "Epoch: 002/010 | Batch 20226/45709 | Average Loss in last 25 iteration(s): 0.1113 | Elapsed 5:55:26\n",
      "Epoch: 002/010 | Batch 20251/45709 | Average Loss in last 25 iteration(s): 0.0908 | Elapsed 5:55:56\n",
      "Epoch: 002/010 | Batch 20276/45709 | Average Loss in last 25 iteration(s): 0.1195 | Elapsed 5:56:20\n",
      "Epoch: 002/010 | Batch 20301/45709 | Average Loss in last 25 iteration(s): 0.0996 | Elapsed 5:56:47\n",
      "Epoch: 002/010 | Batch 20326/45709 | Average Loss in last 25 iteration(s): 0.1006 | Elapsed 5:57:11\n",
      "Epoch: 002/010 | Batch 20351/45709 | Average Loss in last 25 iteration(s): 0.1153 | Elapsed 5:57:37\n",
      "Epoch: 002/010 | Batch 20376/45709 | Average Loss in last 25 iteration(s): 0.1270 | Elapsed 5:58:05\n",
      "Epoch: 002/010 | Batch 20401/45709 | Average Loss in last 25 iteration(s): 0.1300 | Elapsed 5:58:32\n",
      "Epoch: 002/010 | Batch 20426/45709 | Average Loss in last 25 iteration(s): 0.0972 | Elapsed 5:59:00\n",
      "Epoch: 002/010 | Batch 20451/45709 | Average Loss in last 25 iteration(s): 0.1082 | Elapsed 5:59:28\n",
      "Epoch: 002/010 | Batch 20476/45709 | Average Loss in last 25 iteration(s): 0.1340 | Elapsed 5:59:50\n",
      "Epoch: 002/010 | Batch 20501/45709 | Average Loss in last 25 iteration(s): 0.0975 | Elapsed 6:00:17\n",
      "Epoch: 002/010 | Batch 20526/45709 | Average Loss in last 25 iteration(s): 0.1085 | Elapsed 6:00:48\n",
      "Epoch: 002/010 | Batch 20551/45709 | Average Loss in last 25 iteration(s): 0.1155 | Elapsed 6:01:19\n",
      "Epoch: 002/010 | Batch 20576/45709 | Average Loss in last 25 iteration(s): 0.0819 | Elapsed 6:01:46\n",
      "Epoch: 002/010 | Batch 20601/45709 | Average Loss in last 25 iteration(s): 0.0691 | Elapsed 6:02:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 20626/45709 | Average Loss in last 25 iteration(s): 0.1007 | Elapsed 6:02:40\n",
      "Epoch: 002/010 | Batch 20651/45709 | Average Loss in last 25 iteration(s): 0.0937 | Elapsed 6:03:11\n",
      "Epoch: 002/010 | Batch 20676/45709 | Average Loss in last 25 iteration(s): 0.1491 | Elapsed 6:03:38\n",
      "Epoch: 002/010 | Batch 20701/45709 | Average Loss in last 25 iteration(s): 0.0663 | Elapsed 6:04:04\n",
      "Epoch: 002/010 | Batch 20726/45709 | Average Loss in last 25 iteration(s): 0.1011 | Elapsed 6:04:27\n",
      "Epoch: 002/010 | Batch 20751/45709 | Average Loss in last 25 iteration(s): 0.1180 | Elapsed 6:04:53\n",
      "Epoch: 002/010 | Batch 20776/45709 | Average Loss in last 25 iteration(s): 0.0757 | Elapsed 6:05:25\n",
      "Epoch: 002/010 | Batch 20801/45709 | Average Loss in last 25 iteration(s): 0.1226 | Elapsed 6:05:54\n",
      "Epoch: 002/010 | Batch 20826/45709 | Average Loss in last 25 iteration(s): 0.1011 | Elapsed 6:06:22\n",
      "Epoch: 002/010 | Batch 20851/45709 | Average Loss in last 25 iteration(s): 0.1197 | Elapsed 6:06:48\n",
      "Epoch: 002/010 | Batch 20876/45709 | Average Loss in last 25 iteration(s): 0.0972 | Elapsed 6:07:22\n",
      "Epoch: 002/010 | Batch 20901/45709 | Average Loss in last 25 iteration(s): 0.1038 | Elapsed 6:07:44\n",
      "Epoch: 002/010 | Batch 20926/45709 | Average Loss in last 25 iteration(s): 0.0766 | Elapsed 6:08:07\n",
      "Epoch: 002/010 | Batch 20951/45709 | Average Loss in last 25 iteration(s): 0.1361 | Elapsed 6:08:34\n",
      "Epoch: 002/010 | Batch 20976/45709 | Average Loss in last 25 iteration(s): 0.0578 | Elapsed 6:09:00\n",
      "Epoch: 002/010 | Batch 21001/45709 | Average Loss in last 25 iteration(s): 0.0802 | Elapsed 6:09:27\n",
      "Epoch: 002/010 | Batch 21026/45709 | Average Loss in last 25 iteration(s): 0.1377 | Elapsed 6:09:50\n",
      "Epoch: 002/010 | Batch 21051/45709 | Average Loss in last 25 iteration(s): 0.1272 | Elapsed 6:10:14\n",
      "Epoch: 002/010 | Batch 21076/45709 | Average Loss in last 25 iteration(s): 0.1084 | Elapsed 6:10:42\n",
      "Epoch: 002/010 | Batch 21101/45709 | Average Loss in last 25 iteration(s): 0.1282 | Elapsed 6:11:08\n",
      "Epoch: 002/010 | Batch 21126/45709 | Average Loss in last 25 iteration(s): 0.1211 | Elapsed 6:11:36\n",
      "Epoch: 002/010 | Batch 21151/45709 | Average Loss in last 25 iteration(s): 0.0901 | Elapsed 6:12:02\n",
      "Epoch: 002/010 | Batch 21176/45709 | Average Loss in last 25 iteration(s): 0.1170 | Elapsed 6:12:28\n",
      "Epoch: 002/010 | Batch 21201/45709 | Average Loss in last 25 iteration(s): 0.0930 | Elapsed 6:12:51\n",
      "Epoch: 002/010 | Batch 21226/45709 | Average Loss in last 25 iteration(s): 0.1182 | Elapsed 6:13:18\n",
      "Epoch: 002/010 | Batch 21251/45709 | Average Loss in last 25 iteration(s): 0.1223 | Elapsed 6:13:46\n",
      "Epoch: 002/010 | Batch 21276/45709 | Average Loss in last 25 iteration(s): 0.0922 | Elapsed 6:14:13\n",
      "Epoch: 002/010 | Batch 21301/45709 | Average Loss in last 25 iteration(s): 0.0998 | Elapsed 6:14:42\n",
      "Epoch: 002/010 | Batch 21326/45709 | Average Loss in last 25 iteration(s): 0.0772 | Elapsed 6:15:08\n",
      "Epoch: 002/010 | Batch 21351/45709 | Average Loss in last 25 iteration(s): 0.0948 | Elapsed 6:15:31\n",
      "Epoch: 002/010 | Batch 21376/45709 | Average Loss in last 25 iteration(s): 0.1143 | Elapsed 6:15:54\n",
      "Epoch: 002/010 | Batch 21401/45709 | Average Loss in last 25 iteration(s): 0.1391 | Elapsed 6:16:25\n",
      "Epoch: 002/010 | Batch 21426/45709 | Average Loss in last 25 iteration(s): 0.1195 | Elapsed 6:16:52\n",
      "Epoch: 002/010 | Batch 21451/45709 | Average Loss in last 25 iteration(s): 0.1008 | Elapsed 6:17:20\n",
      "Epoch: 002/010 | Batch 21476/45709 | Average Loss in last 25 iteration(s): 0.0852 | Elapsed 6:17:47\n",
      "Epoch: 002/010 | Batch 21501/45709 | Average Loss in last 25 iteration(s): 0.0848 | Elapsed 6:18:10\n",
      "Epoch: 002/010 | Batch 21526/45709 | Average Loss in last 25 iteration(s): 0.1301 | Elapsed 6:18:37\n",
      "Epoch: 002/010 | Batch 21551/45709 | Average Loss in last 25 iteration(s): 0.0931 | Elapsed 6:19:00\n",
      "Epoch: 002/010 | Batch 21576/45709 | Average Loss in last 25 iteration(s): 0.1005 | Elapsed 6:19:28\n",
      "Epoch: 002/010 | Batch 21601/45709 | Average Loss in last 25 iteration(s): 0.1136 | Elapsed 6:19:56\n",
      "Epoch: 002/010 | Batch 21626/45709 | Average Loss in last 25 iteration(s): 0.0810 | Elapsed 6:20:23\n",
      "Epoch: 002/010 | Batch 21651/45709 | Average Loss in last 25 iteration(s): 0.1095 | Elapsed 6:20:49\n",
      "Epoch: 002/010 | Batch 21676/45709 | Average Loss in last 25 iteration(s): 0.1293 | Elapsed 6:21:12\n",
      "Epoch: 002/010 | Batch 21701/45709 | Average Loss in last 25 iteration(s): 0.1384 | Elapsed 6:21:39\n",
      "Epoch: 002/010 | Batch 21726/45709 | Average Loss in last 25 iteration(s): 0.1169 | Elapsed 6:22:06\n",
      "Epoch: 002/010 | Batch 21751/45709 | Average Loss in last 25 iteration(s): 0.1544 | Elapsed 6:22:34\n",
      "Epoch: 002/010 | Batch 21776/45709 | Average Loss in last 25 iteration(s): 0.1021 | Elapsed 6:23:02\n",
      "Epoch: 002/010 | Batch 21801/45709 | Average Loss in last 25 iteration(s): 0.1072 | Elapsed 6:23:29\n",
      "Epoch: 002/010 | Batch 21826/45709 | Average Loss in last 25 iteration(s): 0.1068 | Elapsed 6:23:51\n",
      "Epoch: 002/010 | Batch 21851/45709 | Average Loss in last 25 iteration(s): 0.0983 | Elapsed 6:24:20\n",
      "Epoch: 002/010 | Batch 21876/45709 | Average Loss in last 25 iteration(s): 0.0907 | Elapsed 6:24:48\n",
      "Epoch: 002/010 | Batch 21901/45709 | Average Loss in last 25 iteration(s): 0.1179 | Elapsed 6:25:11\n",
      "Epoch: 002/010 | Batch 21926/45709 | Average Loss in last 25 iteration(s): 0.0964 | Elapsed 6:25:38\n",
      "Epoch: 002/010 | Batch 21951/45709 | Average Loss in last 25 iteration(s): 0.0728 | Elapsed 6:26:06\n",
      "Epoch: 002/010 | Batch 21976/45709 | Average Loss in last 25 iteration(s): 0.0911 | Elapsed 6:26:30\n",
      "Epoch: 002/010 | Batch 22001/45709 | Average Loss in last 25 iteration(s): 0.0795 | Elapsed 6:26:56\n",
      "Epoch: 002/010 | Batch 22026/45709 | Average Loss in last 25 iteration(s): 0.0955 | Elapsed 6:27:24\n",
      "Epoch: 002/010 | Batch 22051/45709 | Average Loss in last 25 iteration(s): 0.1174 | Elapsed 6:27:50\n",
      "Epoch: 002/010 | Batch 22076/45709 | Average Loss in last 25 iteration(s): 0.1163 | Elapsed 6:28:16\n",
      "Epoch: 002/010 | Batch 22101/45709 | Average Loss in last 25 iteration(s): 0.0838 | Elapsed 6:28:43\n",
      "Epoch: 002/010 | Batch 22126/45709 | Average Loss in last 25 iteration(s): 0.0835 | Elapsed 6:29:09\n",
      "Epoch: 002/010 | Batch 22151/45709 | Average Loss in last 25 iteration(s): 0.1001 | Elapsed 6:29:32\n",
      "Epoch: 002/010 | Batch 22176/45709 | Average Loss in last 25 iteration(s): 0.0844 | Elapsed 6:30:02\n",
      "Epoch: 002/010 | Batch 22201/45709 | Average Loss in last 25 iteration(s): 0.0985 | Elapsed 6:30:29\n",
      "Epoch: 002/010 | Batch 22226/45709 | Average Loss in last 25 iteration(s): 0.1345 | Elapsed 6:30:55\n",
      "Epoch: 002/010 | Batch 22251/45709 | Average Loss in last 25 iteration(s): 0.0772 | Elapsed 6:31:21\n",
      "Epoch: 002/010 | Batch 22276/45709 | Average Loss in last 25 iteration(s): 0.0852 | Elapsed 6:31:46\n",
      "Epoch: 002/010 | Batch 22301/45709 | Average Loss in last 25 iteration(s): 0.0810 | Elapsed 6:32:10\n",
      "Epoch: 002/010 | Batch 22326/45709 | Average Loss in last 25 iteration(s): 0.1128 | Elapsed 6:32:36\n",
      "Epoch: 002/010 | Batch 22351/45709 | Average Loss in last 25 iteration(s): 0.0832 | Elapsed 6:33:04\n",
      "Epoch: 002/010 | Batch 22376/45709 | Average Loss in last 25 iteration(s): 0.0874 | Elapsed 6:33:32\n",
      "Epoch: 002/010 | Batch 22401/45709 | Average Loss in last 25 iteration(s): 0.1280 | Elapsed 6:33:58\n",
      "Epoch: 002/010 | Batch 22426/45709 | Average Loss in last 25 iteration(s): 0.0840 | Elapsed 6:34:24\n",
      "Epoch: 002/010 | Batch 22451/45709 | Average Loss in last 25 iteration(s): 0.0838 | Elapsed 6:34:48\n",
      "Epoch: 002/010 | Batch 22476/45709 | Average Loss in last 25 iteration(s): 0.0997 | Elapsed 6:35:15\n",
      "Epoch: 002/010 | Batch 22501/45709 | Average Loss in last 25 iteration(s): 0.0892 | Elapsed 6:35:44\n",
      "Epoch: 002/010 | Batch 22526/45709 | Average Loss in last 25 iteration(s): 0.1072 | Elapsed 6:36:10\n",
      "Epoch: 002/010 | Batch 22551/45709 | Average Loss in last 25 iteration(s): 0.1263 | Elapsed 6:36:37\n",
      "Epoch: 002/010 | Batch 22576/45709 | Average Loss in last 25 iteration(s): 0.0923 | Elapsed 6:37:03\n",
      "Epoch: 002/010 | Batch 22601/45709 | Average Loss in last 25 iteration(s): 0.1170 | Elapsed 6:37:28\n",
      "Epoch: 002/010 | Batch 22626/45709 | Average Loss in last 25 iteration(s): 0.1252 | Elapsed 6:37:53\n",
      "Epoch: 002/010 | Batch 22651/45709 | Average Loss in last 25 iteration(s): 0.0859 | Elapsed 6:38:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 22676/45709 | Average Loss in last 25 iteration(s): 0.1101 | Elapsed 6:38:49\n",
      "Epoch: 002/010 | Batch 22701/45709 | Average Loss in last 25 iteration(s): 0.1035 | Elapsed 6:39:16\n",
      "Epoch: 002/010 | Batch 22726/45709 | Average Loss in last 25 iteration(s): 0.1122 | Elapsed 6:39:43\n",
      "Epoch: 002/010 | Batch 22751/45709 | Average Loss in last 25 iteration(s): 0.1109 | Elapsed 6:40:09\n",
      "Epoch: 002/010 | Batch 22776/45709 | Average Loss in last 25 iteration(s): 0.1027 | Elapsed 6:40:34\n",
      "Epoch: 002/010 | Batch 22801/45709 | Average Loss in last 25 iteration(s): 0.0919 | Elapsed 6:41:01\n",
      "Epoch: 002/010 | Batch 22826/45709 | Average Loss in last 25 iteration(s): 0.1369 | Elapsed 6:41:28\n",
      "Epoch: 002/010 | Batch 22851/45709 | Average Loss in last 25 iteration(s): 0.1244 | Elapsed 6:41:55\n",
      "Epoch: 002/010 | Batch 22876/45709 | Average Loss in last 25 iteration(s): 0.0709 | Elapsed 6:42:23\n",
      "Epoch: 002/010 | Batch 22901/45709 | Average Loss in last 25 iteration(s): 0.0800 | Elapsed 6:42:47\n",
      "Epoch: 002/010 | Batch 22926/45709 | Average Loss in last 25 iteration(s): 0.1190 | Elapsed 6:43:13\n",
      "Epoch: 002/010 | Batch 22951/45709 | Average Loss in last 25 iteration(s): 0.0566 | Elapsed 6:43:43\n",
      "Epoch: 002/010 | Batch 22976/45709 | Average Loss in last 25 iteration(s): 0.0636 | Elapsed 6:44:09\n",
      "Epoch: 002/010 | Batch 23001/45709 | Average Loss in last 25 iteration(s): 0.0740 | Elapsed 6:44:37\n",
      "Epoch: 002/010 | Batch 23026/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 6:45:03\n",
      "Epoch: 002/010 | Batch 23051/45709 | Average Loss in last 25 iteration(s): 0.1067 | Elapsed 6:45:28\n",
      "Epoch: 002/010 | Batch 23076/45709 | Average Loss in last 25 iteration(s): 0.0884 | Elapsed 6:45:52\n",
      "Epoch: 002/010 | Batch 23101/45709 | Average Loss in last 25 iteration(s): 0.0830 | Elapsed 6:46:22\n",
      "Epoch: 002/010 | Batch 23126/45709 | Average Loss in last 25 iteration(s): 0.1207 | Elapsed 6:46:49\n",
      "Epoch: 002/010 | Batch 23151/45709 | Average Loss in last 25 iteration(s): 0.0975 | Elapsed 6:47:17\n",
      "Epoch: 002/010 | Batch 23176/45709 | Average Loss in last 25 iteration(s): 0.0966 | Elapsed 6:47:42\n",
      "Epoch: 002/010 | Batch 23201/45709 | Average Loss in last 25 iteration(s): 0.0831 | Elapsed 6:48:07\n",
      "Epoch: 002/010 | Batch 23226/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 6:48:29\n",
      "Epoch: 002/010 | Batch 23251/45709 | Average Loss in last 25 iteration(s): 0.1089 | Elapsed 6:48:56\n",
      "Epoch: 002/010 | Batch 23276/45709 | Average Loss in last 25 iteration(s): 0.0729 | Elapsed 6:49:24\n",
      "Epoch: 002/010 | Batch 23301/45709 | Average Loss in last 25 iteration(s): 0.0648 | Elapsed 6:49:50\n",
      "Epoch: 002/010 | Batch 23326/45709 | Average Loss in last 25 iteration(s): 0.0692 | Elapsed 6:50:16\n",
      "Epoch: 002/010 | Batch 23351/45709 | Average Loss in last 25 iteration(s): 0.0929 | Elapsed 6:50:41\n",
      "Epoch: 002/010 | Batch 23376/45709 | Average Loss in last 25 iteration(s): 0.1033 | Elapsed 6:51:07\n",
      "Epoch: 002/010 | Batch 23401/45709 | Average Loss in last 25 iteration(s): 0.0965 | Elapsed 6:51:32\n",
      "Epoch: 002/010 | Batch 23426/45709 | Average Loss in last 25 iteration(s): 0.1036 | Elapsed 6:52:03\n",
      "Epoch: 002/010 | Batch 23451/45709 | Average Loss in last 25 iteration(s): 0.0807 | Elapsed 6:52:27\n",
      "Epoch: 002/010 | Batch 23476/45709 | Average Loss in last 25 iteration(s): 0.1161 | Elapsed 6:52:53\n",
      "Epoch: 002/010 | Batch 23501/45709 | Average Loss in last 25 iteration(s): 0.0774 | Elapsed 6:53:19\n",
      "Epoch: 002/010 | Batch 23526/45709 | Average Loss in last 25 iteration(s): 0.1027 | Elapsed 6:53:44\n",
      "Epoch: 002/010 | Batch 23551/45709 | Average Loss in last 25 iteration(s): 0.0913 | Elapsed 6:54:08\n",
      "Epoch: 002/010 | Batch 23576/45709 | Average Loss in last 25 iteration(s): 0.1173 | Elapsed 6:54:36\n",
      "Epoch: 002/010 | Batch 23601/45709 | Average Loss in last 25 iteration(s): 0.1178 | Elapsed 6:55:04\n",
      "Epoch: 002/010 | Batch 23626/45709 | Average Loss in last 25 iteration(s): 0.1051 | Elapsed 6:55:30\n",
      "Epoch: 002/010 | Batch 23651/45709 | Average Loss in last 25 iteration(s): 0.1101 | Elapsed 6:55:56\n",
      "Epoch: 002/010 | Batch 23676/45709 | Average Loss in last 25 iteration(s): 0.1105 | Elapsed 6:56:23\n",
      "Epoch: 002/010 | Batch 23701/45709 | Average Loss in last 25 iteration(s): 0.1556 | Elapsed 6:56:48\n",
      "Epoch: 002/010 | Batch 23726/45709 | Average Loss in last 25 iteration(s): 0.1150 | Elapsed 6:57:15\n",
      "Epoch: 002/010 | Batch 23751/45709 | Average Loss in last 25 iteration(s): 0.1020 | Elapsed 6:57:43\n",
      "Epoch: 002/010 | Batch 23776/45709 | Average Loss in last 25 iteration(s): 0.1058 | Elapsed 6:58:10\n",
      "Epoch: 002/010 | Batch 23801/45709 | Average Loss in last 25 iteration(s): 0.0864 | Elapsed 6:58:35\n",
      "Epoch: 002/010 | Batch 23826/45709 | Average Loss in last 25 iteration(s): 0.0854 | Elapsed 6:59:02\n",
      "Epoch: 002/010 | Batch 23851/45709 | Average Loss in last 25 iteration(s): 0.0779 | Elapsed 6:59:26\n",
      "Epoch: 002/010 | Batch 23876/45709 | Average Loss in last 25 iteration(s): 0.1132 | Elapsed 6:59:51\n",
      "Epoch: 002/010 | Batch 23901/45709 | Average Loss in last 25 iteration(s): 0.1170 | Elapsed 7:00:19\n",
      "Epoch: 002/010 | Batch 23926/45709 | Average Loss in last 25 iteration(s): 0.0709 | Elapsed 7:00:45\n",
      "Epoch: 002/010 | Batch 23951/45709 | Average Loss in last 25 iteration(s): 0.1213 | Elapsed 7:01:12\n",
      "Epoch: 002/010 | Batch 23976/45709 | Average Loss in last 25 iteration(s): 0.0796 | Elapsed 7:01:38\n",
      "Epoch: 002/010 | Batch 24001/45709 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 7:02:03\n",
      "Epoch: 002/010 | Batch 24026/45709 | Average Loss in last 25 iteration(s): 0.1199 | Elapsed 7:02:26\n",
      "Epoch: 002/010 | Batch 24051/45709 | Average Loss in last 25 iteration(s): 0.0901 | Elapsed 7:02:53\n",
      "Epoch: 002/010 | Batch 24076/45709 | Average Loss in last 25 iteration(s): 0.1125 | Elapsed 7:03:22\n",
      "Epoch: 002/010 | Batch 24101/45709 | Average Loss in last 25 iteration(s): 0.1096 | Elapsed 7:03:50\n",
      "Epoch: 002/010 | Batch 24126/45709 | Average Loss in last 25 iteration(s): 0.1001 | Elapsed 7:04:15\n",
      "Epoch: 002/010 | Batch 24151/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 7:04:41\n",
      "Epoch: 002/010 | Batch 24176/45709 | Average Loss in last 25 iteration(s): 0.0945 | Elapsed 7:05:05\n",
      "Epoch: 002/010 | Batch 24201/45709 | Average Loss in last 25 iteration(s): 0.1689 | Elapsed 7:05:33\n",
      "Epoch: 002/010 | Batch 24226/45709 | Average Loss in last 25 iteration(s): 0.1092 | Elapsed 7:06:03\n",
      "Epoch: 002/010 | Batch 24251/45709 | Average Loss in last 25 iteration(s): 0.0913 | Elapsed 7:06:30\n",
      "Epoch: 002/010 | Batch 24276/45709 | Average Loss in last 25 iteration(s): 0.1154 | Elapsed 7:06:57\n",
      "Epoch: 002/010 | Batch 24301/45709 | Average Loss in last 25 iteration(s): 0.1235 | Elapsed 7:07:23\n",
      "Epoch: 002/010 | Batch 24326/45709 | Average Loss in last 25 iteration(s): 0.0792 | Elapsed 7:07:48\n",
      "Epoch: 002/010 | Batch 24351/45709 | Average Loss in last 25 iteration(s): 0.0760 | Elapsed 7:08:14\n",
      "Epoch: 002/010 | Batch 24376/45709 | Average Loss in last 25 iteration(s): 0.0656 | Elapsed 7:08:43\n",
      "Epoch: 002/010 | Batch 24401/45709 | Average Loss in last 25 iteration(s): 0.0888 | Elapsed 7:09:11\n",
      "Epoch: 002/010 | Batch 24426/45709 | Average Loss in last 25 iteration(s): 0.1009 | Elapsed 7:09:36\n",
      "Epoch: 002/010 | Batch 24451/45709 | Average Loss in last 25 iteration(s): 0.0822 | Elapsed 7:10:04\n",
      "Epoch: 002/010 | Batch 24476/45709 | Average Loss in last 25 iteration(s): 0.1000 | Elapsed 7:10:27\n",
      "Epoch: 002/010 | Batch 24501/45709 | Average Loss in last 25 iteration(s): 0.0973 | Elapsed 7:10:53\n",
      "Epoch: 002/010 | Batch 24526/45709 | Average Loss in last 25 iteration(s): 0.1060 | Elapsed 7:11:23\n",
      "Epoch: 002/010 | Batch 24551/45709 | Average Loss in last 25 iteration(s): 0.0757 | Elapsed 7:11:49\n",
      "Epoch: 002/010 | Batch 24576/45709 | Average Loss in last 25 iteration(s): 0.1512 | Elapsed 7:12:16\n",
      "Epoch: 002/010 | Batch 24601/45709 | Average Loss in last 25 iteration(s): 0.0885 | Elapsed 7:12:40\n",
      "Epoch: 002/010 | Batch 24626/45709 | Average Loss in last 25 iteration(s): 0.1059 | Elapsed 7:13:04\n",
      "Epoch: 002/010 | Batch 24651/45709 | Average Loss in last 25 iteration(s): 0.1049 | Elapsed 7:13:30\n",
      "Epoch: 002/010 | Batch 24676/45709 | Average Loss in last 25 iteration(s): 0.1292 | Elapsed 7:13:58\n",
      "Epoch: 002/010 | Batch 24701/45709 | Average Loss in last 25 iteration(s): 0.0708 | Elapsed 7:14:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 24726/45709 | Average Loss in last 25 iteration(s): 0.1047 | Elapsed 7:14:53\n",
      "Epoch: 002/010 | Batch 24751/45709 | Average Loss in last 25 iteration(s): 0.1128 | Elapsed 7:15:20\n",
      "Epoch: 002/010 | Batch 24776/45709 | Average Loss in last 25 iteration(s): 0.1146 | Elapsed 7:15:45\n",
      "Epoch: 002/010 | Batch 24801/45709 | Average Loss in last 25 iteration(s): 0.1242 | Elapsed 7:16:09\n",
      "Epoch: 002/010 | Batch 24826/45709 | Average Loss in last 25 iteration(s): 0.1095 | Elapsed 7:16:36\n",
      "Epoch: 002/010 | Batch 24851/45709 | Average Loss in last 25 iteration(s): 0.0831 | Elapsed 7:17:05\n",
      "Epoch: 002/010 | Batch 24876/45709 | Average Loss in last 25 iteration(s): 0.1219 | Elapsed 7:17:32\n",
      "Epoch: 002/010 | Batch 24901/45709 | Average Loss in last 25 iteration(s): 0.1005 | Elapsed 7:17:58\n",
      "Epoch: 002/010 | Batch 24926/45709 | Average Loss in last 25 iteration(s): 0.0881 | Elapsed 7:18:24\n",
      "Epoch: 002/010 | Batch 24951/45709 | Average Loss in last 25 iteration(s): 0.0839 | Elapsed 7:18:47\n",
      "Epoch: 002/010 | Batch 24976/45709 | Average Loss in last 25 iteration(s): 0.0535 | Elapsed 7:19:17\n",
      "Epoch: 002/010 | Batch 25001/45709 | Average Loss in last 25 iteration(s): 0.1309 | Elapsed 7:19:44\n",
      "Epoch: 002/010 | Batch 25026/45709 | Average Loss in last 25 iteration(s): 0.0655 | Elapsed 7:20:10\n",
      "Epoch: 002/010 | Batch 25051/45709 | Average Loss in last 25 iteration(s): 0.0974 | Elapsed 7:20:35\n",
      "Epoch: 002/010 | Batch 25076/45709 | Average Loss in last 25 iteration(s): 0.1386 | Elapsed 7:21:01\n",
      "Epoch: 002/010 | Batch 25101/45709 | Average Loss in last 25 iteration(s): 0.1360 | Elapsed 7:21:25\n",
      "Epoch: 002/010 | Batch 25126/45709 | Average Loss in last 25 iteration(s): 0.0864 | Elapsed 7:21:53\n",
      "Epoch: 002/010 | Batch 25151/45709 | Average Loss in last 25 iteration(s): 0.1066 | Elapsed 7:22:20\n",
      "Epoch: 002/010 | Batch 25176/45709 | Average Loss in last 25 iteration(s): 0.0916 | Elapsed 7:22:47\n",
      "Epoch: 002/010 | Batch 25201/45709 | Average Loss in last 25 iteration(s): 0.1162 | Elapsed 7:23:14\n",
      "Epoch: 002/010 | Batch 25226/45709 | Average Loss in last 25 iteration(s): 0.0912 | Elapsed 7:23:40\n",
      "Epoch: 002/010 | Batch 25251/45709 | Average Loss in last 25 iteration(s): 0.0945 | Elapsed 7:24:04\n",
      "Epoch: 002/010 | Batch 25276/45709 | Average Loss in last 25 iteration(s): 0.1443 | Elapsed 7:24:30\n",
      "Epoch: 002/010 | Batch 25301/45709 | Average Loss in last 25 iteration(s): 0.1100 | Elapsed 7:25:00\n",
      "Epoch: 002/010 | Batch 25326/45709 | Average Loss in last 25 iteration(s): 0.1202 | Elapsed 7:25:26\n",
      "Epoch: 002/010 | Batch 25351/45709 | Average Loss in last 25 iteration(s): 0.1008 | Elapsed 7:25:54\n",
      "Epoch: 002/010 | Batch 25376/45709 | Average Loss in last 25 iteration(s): 0.0966 | Elapsed 7:26:19\n",
      "Epoch: 002/010 | Batch 25401/45709 | Average Loss in last 25 iteration(s): 0.0953 | Elapsed 7:26:43\n",
      "Epoch: 002/010 | Batch 25426/45709 | Average Loss in last 25 iteration(s): 0.0969 | Elapsed 7:27:08\n",
      "Epoch: 002/010 | Batch 25451/45709 | Average Loss in last 25 iteration(s): 0.0989 | Elapsed 7:27:37\n",
      "Epoch: 002/010 | Batch 25476/45709 | Average Loss in last 25 iteration(s): 0.0885 | Elapsed 7:28:03\n",
      "Epoch: 002/010 | Batch 25501/45709 | Average Loss in last 25 iteration(s): 0.0944 | Elapsed 7:28:30\n",
      "Epoch: 002/010 | Batch 25526/45709 | Average Loss in last 25 iteration(s): 0.1159 | Elapsed 7:28:56\n",
      "Epoch: 002/010 | Batch 25551/45709 | Average Loss in last 25 iteration(s): 0.1367 | Elapsed 7:29:24\n",
      "Epoch: 002/010 | Batch 25576/45709 | Average Loss in last 25 iteration(s): 0.0969 | Elapsed 7:29:48\n",
      "Epoch: 002/010 | Batch 25601/45709 | Average Loss in last 25 iteration(s): 0.1096 | Elapsed 7:30:15\n",
      "Epoch: 002/010 | Batch 25626/45709 | Average Loss in last 25 iteration(s): 0.1242 | Elapsed 7:30:43\n",
      "Epoch: 002/010 | Batch 25651/45709 | Average Loss in last 25 iteration(s): 0.1129 | Elapsed 7:31:10\n",
      "Epoch: 002/010 | Batch 25676/45709 | Average Loss in last 25 iteration(s): 0.1044 | Elapsed 7:31:34\n",
      "Epoch: 002/010 | Batch 25701/45709 | Average Loss in last 25 iteration(s): 0.0978 | Elapsed 7:32:00\n",
      "Epoch: 002/010 | Batch 25726/45709 | Average Loss in last 25 iteration(s): 0.0956 | Elapsed 7:32:23\n",
      "Epoch: 002/010 | Batch 25751/45709 | Average Loss in last 25 iteration(s): 0.1479 | Elapsed 7:32:51\n",
      "Epoch: 002/010 | Batch 25776/45709 | Average Loss in last 25 iteration(s): 0.1030 | Elapsed 7:33:20\n",
      "Epoch: 002/010 | Batch 25801/45709 | Average Loss in last 25 iteration(s): 0.1165 | Elapsed 7:33:47\n",
      "Epoch: 002/010 | Batch 25826/45709 | Average Loss in last 25 iteration(s): 0.0901 | Elapsed 7:34:15\n",
      "Epoch: 002/010 | Batch 25851/45709 | Average Loss in last 25 iteration(s): 0.1247 | Elapsed 7:34:42\n",
      "Epoch: 002/010 | Batch 25876/45709 | Average Loss in last 25 iteration(s): 0.0610 | Elapsed 7:35:05\n",
      "Epoch: 002/010 | Batch 25901/45709 | Average Loss in last 25 iteration(s): 0.0661 | Elapsed 7:35:31\n",
      "Epoch: 002/010 | Batch 25926/45709 | Average Loss in last 25 iteration(s): 0.0814 | Elapsed 7:36:00\n",
      "Epoch: 002/010 | Batch 25951/45709 | Average Loss in last 25 iteration(s): 0.1167 | Elapsed 7:36:26\n",
      "Epoch: 002/010 | Batch 25976/45709 | Average Loss in last 25 iteration(s): 0.0794 | Elapsed 7:36:52\n",
      "Epoch: 002/010 | Batch 26001/45709 | Average Loss in last 25 iteration(s): 0.1058 | Elapsed 7:37:19\n",
      "Epoch: 002/010 | Batch 26026/45709 | Average Loss in last 25 iteration(s): 0.0805 | Elapsed 7:37:43\n",
      "Epoch: 002/010 | Batch 26051/45709 | Average Loss in last 25 iteration(s): 0.0808 | Elapsed 7:38:10\n",
      "Epoch: 002/010 | Batch 26076/45709 | Average Loss in last 25 iteration(s): 0.0759 | Elapsed 7:38:40\n",
      "Epoch: 002/010 | Batch 26101/45709 | Average Loss in last 25 iteration(s): 0.0719 | Elapsed 7:39:06\n",
      "Epoch: 002/010 | Batch 26126/45709 | Average Loss in last 25 iteration(s): 0.1332 | Elapsed 7:39:32\n",
      "Epoch: 002/010 | Batch 26151/45709 | Average Loss in last 25 iteration(s): 0.0915 | Elapsed 7:39:59\n",
      "Epoch: 002/010 | Batch 26176/45709 | Average Loss in last 25 iteration(s): 0.1022 | Elapsed 7:40:23\n",
      "Epoch: 002/010 | Batch 26201/45709 | Average Loss in last 25 iteration(s): 0.0726 | Elapsed 7:40:49\n",
      "Epoch: 002/010 | Batch 26226/45709 | Average Loss in last 25 iteration(s): 0.0758 | Elapsed 7:41:18\n",
      "Epoch: 002/010 | Batch 26251/45709 | Average Loss in last 25 iteration(s): 0.0790 | Elapsed 7:41:44\n",
      "Epoch: 002/010 | Batch 26276/45709 | Average Loss in last 25 iteration(s): 0.0694 | Elapsed 7:42:12\n",
      "Epoch: 002/010 | Batch 26301/45709 | Average Loss in last 25 iteration(s): 0.1154 | Elapsed 7:42:37\n",
      "Epoch: 002/010 | Batch 26326/45709 | Average Loss in last 25 iteration(s): 0.0729 | Elapsed 7:43:02\n",
      "Epoch: 002/010 | Batch 26351/45709 | Average Loss in last 25 iteration(s): 0.0768 | Elapsed 7:43:26\n",
      "Epoch: 002/010 | Batch 26376/45709 | Average Loss in last 25 iteration(s): 0.1170 | Elapsed 7:43:53\n",
      "Epoch: 002/010 | Batch 26401/45709 | Average Loss in last 25 iteration(s): 0.1041 | Elapsed 7:44:20\n",
      "Epoch: 002/010 | Batch 26426/45709 | Average Loss in last 25 iteration(s): 0.1032 | Elapsed 7:44:47\n",
      "Epoch: 002/010 | Batch 26451/45709 | Average Loss in last 25 iteration(s): 0.0926 | Elapsed 7:45:12\n",
      "Epoch: 002/010 | Batch 26476/45709 | Average Loss in last 25 iteration(s): 0.0812 | Elapsed 7:45:39\n",
      "Epoch: 002/010 | Batch 26501/45709 | Average Loss in last 25 iteration(s): 0.0845 | Elapsed 7:46:02\n",
      "Epoch: 002/010 | Batch 26526/45709 | Average Loss in last 25 iteration(s): 0.0920 | Elapsed 7:46:30\n",
      "Epoch: 002/010 | Batch 26551/45709 | Average Loss in last 25 iteration(s): 0.0988 | Elapsed 7:46:58\n",
      "Epoch: 002/010 | Batch 26576/45709 | Average Loss in last 25 iteration(s): 0.1072 | Elapsed 7:47:26\n",
      "Epoch: 002/010 | Batch 26601/45709 | Average Loss in last 25 iteration(s): 0.1429 | Elapsed 7:47:52\n",
      "Epoch: 002/010 | Batch 26626/45709 | Average Loss in last 25 iteration(s): 0.1056 | Elapsed 7:48:18\n",
      "Epoch: 002/010 | Batch 26651/45709 | Average Loss in last 25 iteration(s): 0.1047 | Elapsed 7:48:41\n",
      "Epoch: 002/010 | Batch 26676/45709 | Average Loss in last 25 iteration(s): 0.0703 | Elapsed 7:49:05\n",
      "Epoch: 002/010 | Batch 26701/45709 | Average Loss in last 25 iteration(s): 0.0996 | Elapsed 7:49:34\n",
      "Epoch: 002/010 | Batch 26726/45709 | Average Loss in last 25 iteration(s): 0.0756 | Elapsed 7:50:01\n",
      "Epoch: 002/010 | Batch 26751/45709 | Average Loss in last 25 iteration(s): 0.0976 | Elapsed 7:50:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 26776/45709 | Average Loss in last 25 iteration(s): 0.0846 | Elapsed 7:50:55\n",
      "Epoch: 002/010 | Batch 26801/45709 | Average Loss in last 25 iteration(s): 0.1089 | Elapsed 7:51:20\n",
      "Epoch: 002/010 | Batch 26826/45709 | Average Loss in last 25 iteration(s): 0.0945 | Elapsed 7:51:43\n",
      "Epoch: 002/010 | Batch 26851/45709 | Average Loss in last 25 iteration(s): 0.1072 | Elapsed 7:52:09\n",
      "Epoch: 002/010 | Batch 26876/45709 | Average Loss in last 25 iteration(s): 0.1086 | Elapsed 7:52:40\n",
      "Epoch: 002/010 | Batch 26901/45709 | Average Loss in last 25 iteration(s): 0.1297 | Elapsed 7:53:07\n",
      "Epoch: 002/010 | Batch 26926/45709 | Average Loss in last 25 iteration(s): 0.0766 | Elapsed 7:53:34\n",
      "Epoch: 002/010 | Batch 26951/45709 | Average Loss in last 25 iteration(s): 0.0833 | Elapsed 7:54:00\n",
      "Epoch: 002/010 | Batch 26976/45709 | Average Loss in last 25 iteration(s): 0.1395 | Elapsed 7:54:25\n",
      "Epoch: 002/010 | Batch 27001/45709 | Average Loss in last 25 iteration(s): 0.0847 | Elapsed 7:54:53\n",
      "Epoch: 002/010 | Batch 27026/45709 | Average Loss in last 25 iteration(s): 0.0785 | Elapsed 7:55:21\n",
      "Epoch: 002/010 | Batch 27051/45709 | Average Loss in last 25 iteration(s): 0.0901 | Elapsed 7:55:48\n",
      "Epoch: 002/010 | Batch 27076/45709 | Average Loss in last 25 iteration(s): 0.1100 | Elapsed 7:56:15\n",
      "Epoch: 002/010 | Batch 27101/45709 | Average Loss in last 25 iteration(s): 0.1071 | Elapsed 7:56:41\n",
      "Epoch: 002/010 | Batch 27126/45709 | Average Loss in last 25 iteration(s): 0.0798 | Elapsed 7:57:05\n",
      "Epoch: 002/010 | Batch 27151/45709 | Average Loss in last 25 iteration(s): 0.0789 | Elapsed 7:57:34\n",
      "Epoch: 002/010 | Batch 27176/45709 | Average Loss in last 25 iteration(s): 0.1307 | Elapsed 7:57:59\n",
      "Epoch: 002/010 | Batch 27201/45709 | Average Loss in last 25 iteration(s): 0.0737 | Elapsed 7:58:26\n",
      "Epoch: 002/010 | Batch 27226/45709 | Average Loss in last 25 iteration(s): 0.0694 | Elapsed 7:58:53\n",
      "Epoch: 002/010 | Batch 27251/45709 | Average Loss in last 25 iteration(s): 0.1217 | Elapsed 7:59:18\n",
      "Epoch: 002/010 | Batch 27276/45709 | Average Loss in last 25 iteration(s): 0.1017 | Elapsed 7:59:43\n",
      "Epoch: 002/010 | Batch 27301/45709 | Average Loss in last 25 iteration(s): 0.0924 | Elapsed 8:00:09\n",
      "Epoch: 002/010 | Batch 27326/45709 | Average Loss in last 25 iteration(s): 0.1032 | Elapsed 8:00:39\n",
      "Epoch: 002/010 | Batch 27351/45709 | Average Loss in last 25 iteration(s): 0.0883 | Elapsed 8:01:05\n",
      "Epoch: 002/010 | Batch 27376/45709 | Average Loss in last 25 iteration(s): 0.1033 | Elapsed 8:01:31\n",
      "Epoch: 002/010 | Batch 27401/45709 | Average Loss in last 25 iteration(s): 0.0859 | Elapsed 8:01:57\n",
      "Epoch: 002/010 | Batch 27426/45709 | Average Loss in last 25 iteration(s): 0.1280 | Elapsed 8:02:19\n",
      "Epoch: 002/010 | Batch 27451/45709 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 8:02:48\n",
      "Epoch: 002/010 | Batch 27476/45709 | Average Loss in last 25 iteration(s): 0.0688 | Elapsed 8:03:16\n",
      "Epoch: 002/010 | Batch 27501/45709 | Average Loss in last 25 iteration(s): 0.0910 | Elapsed 8:03:42\n",
      "Epoch: 002/010 | Batch 27526/45709 | Average Loss in last 25 iteration(s): 0.1185 | Elapsed 8:04:11\n",
      "Epoch: 002/010 | Batch 27551/45709 | Average Loss in last 25 iteration(s): 0.0951 | Elapsed 8:04:36\n",
      "Epoch: 002/010 | Batch 27576/45709 | Average Loss in last 25 iteration(s): 0.0850 | Elapsed 8:04:59\n",
      "Epoch: 002/010 | Batch 27601/45709 | Average Loss in last 25 iteration(s): 0.1278 | Elapsed 8:05:28\n",
      "Epoch: 002/010 | Batch 27626/45709 | Average Loss in last 25 iteration(s): 0.0996 | Elapsed 8:05:57\n",
      "Epoch: 002/010 | Batch 27651/45709 | Average Loss in last 25 iteration(s): 0.1351 | Elapsed 8:06:23\n",
      "Epoch: 002/010 | Batch 27676/45709 | Average Loss in last 25 iteration(s): 0.1056 | Elapsed 8:06:50\n",
      "Epoch: 002/010 | Batch 27701/45709 | Average Loss in last 25 iteration(s): 0.0876 | Elapsed 8:07:17\n",
      "Epoch: 002/010 | Batch 27726/45709 | Average Loss in last 25 iteration(s): 0.1111 | Elapsed 8:07:41\n",
      "Epoch: 002/010 | Batch 27751/45709 | Average Loss in last 25 iteration(s): 0.1071 | Elapsed 8:08:10\n",
      "Epoch: 002/010 | Batch 27776/45709 | Average Loss in last 25 iteration(s): 0.1047 | Elapsed 8:08:38\n",
      "Epoch: 002/010 | Batch 27801/45709 | Average Loss in last 25 iteration(s): 0.0664 | Elapsed 8:09:06\n",
      "Epoch: 002/010 | Batch 27826/45709 | Average Loss in last 25 iteration(s): 0.1128 | Elapsed 8:09:32\n",
      "Epoch: 002/010 | Batch 27851/45709 | Average Loss in last 25 iteration(s): 0.1123 | Elapsed 8:09:56\n",
      "Epoch: 002/010 | Batch 27876/45709 | Average Loss in last 25 iteration(s): 0.1021 | Elapsed 8:10:19\n",
      "Epoch: 002/010 | Batch 27901/45709 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 8:10:48\n",
      "Epoch: 002/010 | Batch 27926/45709 | Average Loss in last 25 iteration(s): 0.0709 | Elapsed 8:11:16\n",
      "Epoch: 002/010 | Batch 27951/45709 | Average Loss in last 25 iteration(s): 0.0851 | Elapsed 8:11:44\n",
      "Epoch: 002/010 | Batch 27976/45709 | Average Loss in last 25 iteration(s): 0.0767 | Elapsed 8:12:11\n",
      "Epoch: 002/010 | Batch 28001/45709 | Average Loss in last 25 iteration(s): 0.0994 | Elapsed 8:12:34\n",
      "Epoch: 002/010 | Batch 28026/45709 | Average Loss in last 25 iteration(s): 0.1009 | Elapsed 8:12:59\n",
      "Epoch: 002/010 | Batch 28051/45709 | Average Loss in last 25 iteration(s): 0.1147 | Elapsed 8:13:24\n",
      "Epoch: 002/010 | Batch 28076/45709 | Average Loss in last 25 iteration(s): 0.1010 | Elapsed 8:13:52\n",
      "Epoch: 002/010 | Batch 28101/45709 | Average Loss in last 25 iteration(s): 0.1024 | Elapsed 8:14:19\n",
      "Epoch: 002/010 | Batch 28126/45709 | Average Loss in last 25 iteration(s): 0.0838 | Elapsed 8:14:48\n",
      "Epoch: 002/010 | Batch 28151/45709 | Average Loss in last 25 iteration(s): 0.0857 | Elapsed 8:15:14\n",
      "Epoch: 002/010 | Batch 28176/45709 | Average Loss in last 25 iteration(s): 0.0884 | Elapsed 8:15:39\n",
      "Epoch: 002/010 | Batch 28201/45709 | Average Loss in last 25 iteration(s): 0.1181 | Elapsed 8:16:03\n",
      "Epoch: 002/010 | Batch 28226/45709 | Average Loss in last 25 iteration(s): 0.0823 | Elapsed 8:16:31\n",
      "Epoch: 002/010 | Batch 28251/45709 | Average Loss in last 25 iteration(s): 0.0720 | Elapsed 8:16:59\n",
      "Epoch: 002/010 | Batch 28276/45709 | Average Loss in last 25 iteration(s): 0.0915 | Elapsed 8:17:25\n",
      "Epoch: 002/010 | Batch 28301/45709 | Average Loss in last 25 iteration(s): 0.0976 | Elapsed 8:17:52\n",
      "Epoch: 002/010 | Batch 28326/45709 | Average Loss in last 25 iteration(s): 0.0816 | Elapsed 8:18:18\n",
      "Epoch: 002/010 | Batch 28351/45709 | Average Loss in last 25 iteration(s): 0.1347 | Elapsed 8:18:41\n",
      "Epoch: 002/010 | Batch 28376/45709 | Average Loss in last 25 iteration(s): 0.0852 | Elapsed 8:19:09\n",
      "Epoch: 002/010 | Batch 28401/45709 | Average Loss in last 25 iteration(s): 0.1096 | Elapsed 8:19:39\n",
      "Epoch: 002/010 | Batch 28426/45709 | Average Loss in last 25 iteration(s): 0.1266 | Elapsed 8:20:08\n",
      "Epoch: 002/010 | Batch 28451/45709 | Average Loss in last 25 iteration(s): 0.1338 | Elapsed 8:20:34\n",
      "Epoch: 002/010 | Batch 28476/45709 | Average Loss in last 25 iteration(s): 0.1419 | Elapsed 8:21:00\n",
      "Epoch: 002/010 | Batch 28501/45709 | Average Loss in last 25 iteration(s): 0.1354 | Elapsed 8:21:23\n",
      "Epoch: 002/010 | Batch 28526/45709 | Average Loss in last 25 iteration(s): 0.0684 | Elapsed 8:21:50\n",
      "Epoch: 002/010 | Batch 28551/45709 | Average Loss in last 25 iteration(s): 0.0814 | Elapsed 8:22:20\n",
      "Epoch: 002/010 | Batch 28576/45709 | Average Loss in last 25 iteration(s): 0.0848 | Elapsed 8:22:45\n",
      "Epoch: 002/010 | Batch 28601/45709 | Average Loss in last 25 iteration(s): 0.0606 | Elapsed 8:23:12\n",
      "Epoch: 002/010 | Batch 28626/45709 | Average Loss in last 25 iteration(s): 0.0623 | Elapsed 8:23:38\n",
      "Epoch: 002/010 | Batch 28651/45709 | Average Loss in last 25 iteration(s): 0.0921 | Elapsed 8:24:01\n",
      "Epoch: 002/010 | Batch 28676/45709 | Average Loss in last 25 iteration(s): 0.1064 | Elapsed 8:24:27\n",
      "Epoch: 002/010 | Batch 28701/45709 | Average Loss in last 25 iteration(s): 0.0742 | Elapsed 8:24:56\n",
      "Epoch: 002/010 | Batch 28726/45709 | Average Loss in last 25 iteration(s): 0.0849 | Elapsed 8:25:22\n",
      "Epoch: 002/010 | Batch 28751/45709 | Average Loss in last 25 iteration(s): 0.1057 | Elapsed 8:25:49\n",
      "Epoch: 002/010 | Batch 28776/45709 | Average Loss in last 25 iteration(s): 0.1136 | Elapsed 8:26:15\n",
      "Epoch: 002/010 | Batch 28801/45709 | Average Loss in last 25 iteration(s): 0.0872 | Elapsed 8:26:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 28826/45709 | Average Loss in last 25 iteration(s): 0.1083 | Elapsed 8:27:09\n",
      "Epoch: 002/010 | Batch 28851/45709 | Average Loss in last 25 iteration(s): 0.0994 | Elapsed 8:27:36\n",
      "Epoch: 002/010 | Batch 28876/45709 | Average Loss in last 25 iteration(s): 0.1077 | Elapsed 8:28:03\n",
      "Epoch: 002/010 | Batch 28901/45709 | Average Loss in last 25 iteration(s): 0.1024 | Elapsed 8:28:31\n",
      "Epoch: 002/010 | Batch 28926/45709 | Average Loss in last 25 iteration(s): 0.1364 | Elapsed 8:28:57\n",
      "Epoch: 002/010 | Batch 28951/45709 | Average Loss in last 25 iteration(s): 0.0896 | Elapsed 8:29:21\n",
      "Epoch: 002/010 | Batch 28976/45709 | Average Loss in last 25 iteration(s): 0.0744 | Elapsed 8:29:46\n",
      "Epoch: 002/010 | Batch 29001/45709 | Average Loss in last 25 iteration(s): 0.0764 | Elapsed 8:30:13\n",
      "Epoch: 002/010 | Batch 29026/45709 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 8:30:39\n",
      "Epoch: 002/010 | Batch 29051/45709 | Average Loss in last 25 iteration(s): 0.0948 | Elapsed 8:31:07\n",
      "Epoch: 002/010 | Batch 29076/45709 | Average Loss in last 25 iteration(s): 0.0928 | Elapsed 8:31:33\n",
      "Epoch: 002/010 | Batch 29101/45709 | Average Loss in last 25 iteration(s): 0.0912 | Elapsed 8:31:59\n",
      "Epoch: 002/010 | Batch 29126/45709 | Average Loss in last 25 iteration(s): 0.0864 | Elapsed 8:32:22\n",
      "Epoch: 002/010 | Batch 29151/45709 | Average Loss in last 25 iteration(s): 0.1217 | Elapsed 8:32:49\n",
      "Epoch: 002/010 | Batch 29176/45709 | Average Loss in last 25 iteration(s): 0.0914 | Elapsed 8:33:15\n",
      "Epoch: 002/010 | Batch 29201/45709 | Average Loss in last 25 iteration(s): 0.0642 | Elapsed 8:33:43\n",
      "Epoch: 002/010 | Batch 29226/45709 | Average Loss in last 25 iteration(s): 0.1342 | Elapsed 8:34:11\n",
      "Epoch: 002/010 | Batch 29251/45709 | Average Loss in last 25 iteration(s): 0.1185 | Elapsed 8:34:37\n",
      "Epoch: 002/010 | Batch 29276/45709 | Average Loss in last 25 iteration(s): 0.1134 | Elapsed 8:35:01\n",
      "Epoch: 002/010 | Batch 29301/45709 | Average Loss in last 25 iteration(s): 0.0821 | Elapsed 8:35:28\n",
      "Epoch: 002/010 | Batch 29326/45709 | Average Loss in last 25 iteration(s): 0.1041 | Elapsed 8:35:56\n",
      "Epoch: 002/010 | Batch 29351/45709 | Average Loss in last 25 iteration(s): 0.0856 | Elapsed 8:36:23\n",
      "Epoch: 002/010 | Batch 29376/45709 | Average Loss in last 25 iteration(s): 0.1216 | Elapsed 8:36:50\n",
      "Epoch: 002/010 | Batch 29401/45709 | Average Loss in last 25 iteration(s): 0.0951 | Elapsed 8:37:15\n",
      "Epoch: 002/010 | Batch 29426/45709 | Average Loss in last 25 iteration(s): 0.0983 | Elapsed 8:37:39\n",
      "Epoch: 002/010 | Batch 29451/45709 | Average Loss in last 25 iteration(s): 0.1086 | Elapsed 8:38:03\n",
      "Epoch: 002/010 | Batch 29476/45709 | Average Loss in last 25 iteration(s): 0.0778 | Elapsed 8:38:32\n",
      "Epoch: 002/010 | Batch 29501/45709 | Average Loss in last 25 iteration(s): 0.0956 | Elapsed 8:38:58\n",
      "Epoch: 002/010 | Batch 29526/45709 | Average Loss in last 25 iteration(s): 0.0943 | Elapsed 8:39:23\n",
      "Epoch: 002/010 | Batch 29551/45709 | Average Loss in last 25 iteration(s): 0.0861 | Elapsed 8:39:48\n",
      "Epoch: 002/010 | Batch 29576/45709 | Average Loss in last 25 iteration(s): 0.1099 | Elapsed 8:40:16\n",
      "Epoch: 002/010 | Batch 29601/45709 | Average Loss in last 25 iteration(s): 0.1042 | Elapsed 8:40:39\n",
      "Epoch: 002/010 | Batch 29626/45709 | Average Loss in last 25 iteration(s): 0.0929 | Elapsed 8:41:05\n",
      "Epoch: 002/010 | Batch 29651/45709 | Average Loss in last 25 iteration(s): 0.1075 | Elapsed 8:41:33\n",
      "Epoch: 002/010 | Batch 29676/45709 | Average Loss in last 25 iteration(s): 0.1034 | Elapsed 8:42:00\n",
      "Epoch: 002/010 | Batch 29701/45709 | Average Loss in last 25 iteration(s): 0.1072 | Elapsed 8:42:26\n",
      "Epoch: 002/010 | Batch 29726/45709 | Average Loss in last 25 iteration(s): 0.1095 | Elapsed 8:42:54\n",
      "Epoch: 002/010 | Batch 29751/45709 | Average Loss in last 25 iteration(s): 0.0729 | Elapsed 8:43:18\n",
      "Epoch: 002/010 | Batch 29776/45709 | Average Loss in last 25 iteration(s): 0.0896 | Elapsed 8:43:44\n",
      "Epoch: 002/010 | Batch 29801/45709 | Average Loss in last 25 iteration(s): 0.0876 | Elapsed 8:44:11\n",
      "Epoch: 002/010 | Batch 29826/45709 | Average Loss in last 25 iteration(s): 0.0871 | Elapsed 8:44:39\n",
      "Epoch: 002/010 | Batch 29851/45709 | Average Loss in last 25 iteration(s): 0.1016 | Elapsed 8:45:04\n",
      "Epoch: 002/010 | Batch 29876/45709 | Average Loss in last 25 iteration(s): 0.0939 | Elapsed 8:45:31\n",
      "Epoch: 002/010 | Batch 29901/45709 | Average Loss in last 25 iteration(s): 0.0782 | Elapsed 8:45:56\n",
      "Epoch: 002/010 | Batch 29926/45709 | Average Loss in last 25 iteration(s): 0.0846 | Elapsed 8:46:19\n",
      "Epoch: 002/010 | Batch 29951/45709 | Average Loss in last 25 iteration(s): 0.1018 | Elapsed 8:46:47\n",
      "Epoch: 002/010 | Batch 29976/45709 | Average Loss in last 25 iteration(s): 0.0920 | Elapsed 8:47:16\n",
      "Epoch: 002/010 | Batch 30001/45709 | Average Loss in last 25 iteration(s): 0.1134 | Elapsed 8:47:41\n",
      "Epoch: 002/010 | Batch 30026/45709 | Average Loss in last 25 iteration(s): 0.0894 | Elapsed 8:48:08\n",
      "Epoch: 002/010 | Batch 30051/45709 | Average Loss in last 25 iteration(s): 0.1359 | Elapsed 8:48:33\n",
      "Epoch: 002/010 | Batch 30076/45709 | Average Loss in last 25 iteration(s): 0.1008 | Elapsed 8:48:56\n",
      "Epoch: 002/010 | Batch 30101/45709 | Average Loss in last 25 iteration(s): 0.0787 | Elapsed 8:49:22\n",
      "Epoch: 002/010 | Batch 30126/45709 | Average Loss in last 25 iteration(s): 0.0902 | Elapsed 8:49:51\n",
      "Epoch: 002/010 | Batch 30151/45709 | Average Loss in last 25 iteration(s): 0.1231 | Elapsed 8:50:18\n",
      "Epoch: 002/010 | Batch 30176/45709 | Average Loss in last 25 iteration(s): 0.0747 | Elapsed 8:50:45\n",
      "Epoch: 002/010 | Batch 30201/45709 | Average Loss in last 25 iteration(s): 0.0928 | Elapsed 8:51:12\n",
      "Epoch: 002/010 | Batch 30226/45709 | Average Loss in last 25 iteration(s): 0.0988 | Elapsed 8:51:38\n",
      "Epoch: 002/010 | Batch 30251/45709 | Average Loss in last 25 iteration(s): 0.0967 | Elapsed 8:52:02\n",
      "Epoch: 002/010 | Batch 30276/45709 | Average Loss in last 25 iteration(s): 0.1039 | Elapsed 8:52:29\n",
      "Epoch: 002/010 | Batch 30301/45709 | Average Loss in last 25 iteration(s): 0.0866 | Elapsed 8:52:57\n",
      "Epoch: 002/010 | Batch 30326/45709 | Average Loss in last 25 iteration(s): 0.0832 | Elapsed 8:53:24\n",
      "Epoch: 002/010 | Batch 30351/45709 | Average Loss in last 25 iteration(s): 0.0719 | Elapsed 8:53:51\n",
      "Epoch: 002/010 | Batch 30376/45709 | Average Loss in last 25 iteration(s): 0.0983 | Elapsed 8:54:17\n",
      "Epoch: 002/010 | Batch 30401/45709 | Average Loss in last 25 iteration(s): 0.0794 | Elapsed 8:54:41\n",
      "Epoch: 002/010 | Batch 30426/45709 | Average Loss in last 25 iteration(s): 0.1056 | Elapsed 8:55:08\n",
      "Epoch: 002/010 | Batch 30451/45709 | Average Loss in last 25 iteration(s): 0.0842 | Elapsed 8:55:37\n",
      "Epoch: 002/010 | Batch 30476/45709 | Average Loss in last 25 iteration(s): 0.1100 | Elapsed 8:56:04\n",
      "Epoch: 002/010 | Batch 30501/45709 | Average Loss in last 25 iteration(s): 0.1346 | Elapsed 8:56:31\n",
      "Epoch: 002/010 | Batch 30526/45709 | Average Loss in last 25 iteration(s): 0.0770 | Elapsed 8:56:57\n",
      "Epoch: 002/010 | Batch 30551/45709 | Average Loss in last 25 iteration(s): 0.0703 | Elapsed 8:57:20\n",
      "Epoch: 002/010 | Batch 30576/45709 | Average Loss in last 25 iteration(s): 0.1051 | Elapsed 8:57:49\n",
      "Epoch: 002/010 | Batch 30601/45709 | Average Loss in last 25 iteration(s): 0.0781 | Elapsed 8:58:16\n",
      "Epoch: 002/010 | Batch 30626/45709 | Average Loss in last 25 iteration(s): 0.1124 | Elapsed 8:58:43\n",
      "Epoch: 002/010 | Batch 30651/45709 | Average Loss in last 25 iteration(s): 0.1167 | Elapsed 8:59:09\n",
      "Epoch: 002/010 | Batch 30676/45709 | Average Loss in last 25 iteration(s): 0.1106 | Elapsed 8:59:35\n",
      "Epoch: 002/010 | Batch 30701/45709 | Average Loss in last 25 iteration(s): 0.0560 | Elapsed 8:59:59\n",
      "Epoch: 002/010 | Batch 30726/45709 | Average Loss in last 25 iteration(s): 0.1064 | Elapsed 9:00:29\n",
      "Epoch: 002/010 | Batch 30751/45709 | Average Loss in last 25 iteration(s): 0.0677 | Elapsed 9:00:57\n",
      "Epoch: 002/010 | Batch 30776/45709 | Average Loss in last 25 iteration(s): 0.0861 | Elapsed 9:01:23\n",
      "Epoch: 002/010 | Batch 30801/45709 | Average Loss in last 25 iteration(s): 0.0846 | Elapsed 9:01:50\n",
      "Epoch: 002/010 | Batch 30826/45709 | Average Loss in last 25 iteration(s): 0.0995 | Elapsed 9:02:15\n",
      "Epoch: 002/010 | Batch 30851/45709 | Average Loss in last 25 iteration(s): 0.0862 | Elapsed 9:02:39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 30876/45709 | Average Loss in last 25 iteration(s): 0.1040 | Elapsed 9:03:04\n",
      "Epoch: 002/010 | Batch 30901/45709 | Average Loss in last 25 iteration(s): 0.0887 | Elapsed 9:03:34\n",
      "Epoch: 002/010 | Batch 30926/45709 | Average Loss in last 25 iteration(s): 0.0730 | Elapsed 9:04:02\n",
      "Epoch: 002/010 | Batch 30951/45709 | Average Loss in last 25 iteration(s): 0.1146 | Elapsed 9:04:28\n",
      "Epoch: 002/010 | Batch 30976/45709 | Average Loss in last 25 iteration(s): 0.0720 | Elapsed 9:04:54\n",
      "Epoch: 002/010 | Batch 31001/45709 | Average Loss in last 25 iteration(s): 0.1075 | Elapsed 9:05:19\n",
      "Epoch: 002/010 | Batch 31026/45709 | Average Loss in last 25 iteration(s): 0.1326 | Elapsed 9:05:43\n",
      "Epoch: 002/010 | Batch 31051/45709 | Average Loss in last 25 iteration(s): 0.0753 | Elapsed 9:06:11\n",
      "Epoch: 002/010 | Batch 31076/45709 | Average Loss in last 25 iteration(s): 0.1060 | Elapsed 9:06:40\n",
      "Epoch: 002/010 | Batch 31101/45709 | Average Loss in last 25 iteration(s): 0.1127 | Elapsed 9:07:06\n",
      "Epoch: 002/010 | Batch 31126/45709 | Average Loss in last 25 iteration(s): 0.1006 | Elapsed 9:07:34\n",
      "Epoch: 002/010 | Batch 31151/45709 | Average Loss in last 25 iteration(s): 0.1270 | Elapsed 9:08:00\n",
      "Epoch: 002/010 | Batch 31176/45709 | Average Loss in last 25 iteration(s): 0.0834 | Elapsed 9:08:23\n",
      "Epoch: 002/010 | Batch 31201/45709 | Average Loss in last 25 iteration(s): 0.0865 | Elapsed 9:08:51\n",
      "Epoch: 002/010 | Batch 31226/45709 | Average Loss in last 25 iteration(s): 0.0889 | Elapsed 9:09:18\n",
      "Epoch: 002/010 | Batch 31251/45709 | Average Loss in last 25 iteration(s): 0.0705 | Elapsed 9:09:47\n",
      "Epoch: 002/010 | Batch 31276/45709 | Average Loss in last 25 iteration(s): 0.1058 | Elapsed 9:10:15\n",
      "Epoch: 002/010 | Batch 31301/45709 | Average Loss in last 25 iteration(s): 0.1316 | Elapsed 9:10:40\n",
      "Epoch: 002/010 | Batch 31326/45709 | Average Loss in last 25 iteration(s): 0.1383 | Elapsed 9:11:03\n",
      "Epoch: 002/010 | Batch 31351/45709 | Average Loss in last 25 iteration(s): 0.0816 | Elapsed 9:11:32\n",
      "Epoch: 002/010 | Batch 31376/45709 | Average Loss in last 25 iteration(s): 0.1162 | Elapsed 9:12:00\n",
      "Epoch: 002/010 | Batch 31401/45709 | Average Loss in last 25 iteration(s): 0.0843 | Elapsed 9:12:26\n",
      "Epoch: 002/010 | Batch 31426/45709 | Average Loss in last 25 iteration(s): 0.0754 | Elapsed 9:12:53\n",
      "Epoch: 002/010 | Batch 31451/45709 | Average Loss in last 25 iteration(s): 0.0871 | Elapsed 9:13:18\n",
      "Epoch: 002/010 | Batch 31476/45709 | Average Loss in last 25 iteration(s): 0.0984 | Elapsed 9:13:41\n",
      "Epoch: 002/010 | Batch 31501/45709 | Average Loss in last 25 iteration(s): 0.0945 | Elapsed 9:14:09\n",
      "Epoch: 002/010 | Batch 31526/45709 | Average Loss in last 25 iteration(s): 0.0790 | Elapsed 9:14:37\n",
      "Epoch: 002/010 | Batch 31551/45709 | Average Loss in last 25 iteration(s): 0.0972 | Elapsed 9:15:06\n",
      "Epoch: 002/010 | Batch 31576/45709 | Average Loss in last 25 iteration(s): 0.0755 | Elapsed 9:15:31\n",
      "Epoch: 002/010 | Batch 31601/45709 | Average Loss in last 25 iteration(s): 0.0914 | Elapsed 9:15:57\n",
      "Epoch: 002/010 | Batch 31626/45709 | Average Loss in last 25 iteration(s): 0.1019 | Elapsed 9:16:20\n",
      "Epoch: 002/010 | Batch 31651/45709 | Average Loss in last 25 iteration(s): 0.1208 | Elapsed 9:16:49\n",
      "Epoch: 002/010 | Batch 31676/45709 | Average Loss in last 25 iteration(s): 0.1218 | Elapsed 9:17:17\n",
      "Epoch: 002/010 | Batch 31701/45709 | Average Loss in last 25 iteration(s): 0.0920 | Elapsed 9:17:43\n",
      "Epoch: 002/010 | Batch 31726/45709 | Average Loss in last 25 iteration(s): 0.0968 | Elapsed 9:18:11\n",
      "Epoch: 002/010 | Batch 31751/45709 | Average Loss in last 25 iteration(s): 0.0971 | Elapsed 9:18:36\n",
      "Epoch: 002/010 | Batch 31776/45709 | Average Loss in last 25 iteration(s): 0.1067 | Elapsed 9:19:00\n",
      "Epoch: 002/010 | Batch 31801/45709 | Average Loss in last 25 iteration(s): 0.1077 | Elapsed 9:19:29\n",
      "Epoch: 002/010 | Batch 31826/45709 | Average Loss in last 25 iteration(s): 0.1073 | Elapsed 9:19:56\n",
      "Epoch: 002/010 | Batch 31851/45709 | Average Loss in last 25 iteration(s): 0.1330 | Elapsed 9:20:22\n",
      "Epoch: 002/010 | Batch 31876/45709 | Average Loss in last 25 iteration(s): 0.0638 | Elapsed 9:20:48\n",
      "Epoch: 002/010 | Batch 31901/45709 | Average Loss in last 25 iteration(s): 0.0920 | Elapsed 9:21:13\n",
      "Epoch: 002/010 | Batch 31926/45709 | Average Loss in last 25 iteration(s): 0.0858 | Elapsed 9:21:38\n",
      "Epoch: 002/010 | Batch 31951/45709 | Average Loss in last 25 iteration(s): 0.0901 | Elapsed 9:22:01\n",
      "Epoch: 002/010 | Batch 31976/45709 | Average Loss in last 25 iteration(s): 0.0790 | Elapsed 9:22:30\n",
      "Epoch: 002/010 | Batch 32001/45709 | Average Loss in last 25 iteration(s): 0.0971 | Elapsed 9:22:59\n",
      "Epoch: 002/010 | Batch 32026/45709 | Average Loss in last 25 iteration(s): 0.0978 | Elapsed 9:23:25\n",
      "Epoch: 002/010 | Batch 32051/45709 | Average Loss in last 25 iteration(s): 0.0960 | Elapsed 9:23:50\n",
      "Epoch: 002/010 | Batch 32076/45709 | Average Loss in last 25 iteration(s): 0.0850 | Elapsed 9:24:16\n",
      "Epoch: 002/010 | Batch 32101/45709 | Average Loss in last 25 iteration(s): 0.0769 | Elapsed 9:24:39\n",
      "Epoch: 002/010 | Batch 32126/45709 | Average Loss in last 25 iteration(s): 0.1121 | Elapsed 9:25:09\n",
      "Epoch: 002/010 | Batch 32151/45709 | Average Loss in last 25 iteration(s): 0.0943 | Elapsed 9:25:36\n",
      "Epoch: 002/010 | Batch 32176/45709 | Average Loss in last 25 iteration(s): 0.0832 | Elapsed 9:26:04\n",
      "Epoch: 002/010 | Batch 32201/45709 | Average Loss in last 25 iteration(s): 0.0708 | Elapsed 9:26:30\n",
      "Epoch: 002/010 | Batch 32226/45709 | Average Loss in last 25 iteration(s): 0.1033 | Elapsed 9:26:55\n",
      "Epoch: 002/010 | Batch 32251/45709 | Average Loss in last 25 iteration(s): 0.0973 | Elapsed 9:27:18\n",
      "Epoch: 002/010 | Batch 32276/45709 | Average Loss in last 25 iteration(s): 0.1081 | Elapsed 9:27:48\n",
      "Epoch: 002/010 | Batch 32301/45709 | Average Loss in last 25 iteration(s): 0.0558 | Elapsed 9:28:15\n",
      "Epoch: 002/010 | Batch 32326/45709 | Average Loss in last 25 iteration(s): 0.0899 | Elapsed 9:28:43\n",
      "Epoch: 002/010 | Batch 32351/45709 | Average Loss in last 25 iteration(s): 0.1179 | Elapsed 9:29:09\n",
      "Epoch: 002/010 | Batch 32376/45709 | Average Loss in last 25 iteration(s): 0.1113 | Elapsed 9:29:34\n",
      "Epoch: 002/010 | Batch 32401/45709 | Average Loss in last 25 iteration(s): 0.0634 | Elapsed 9:29:59\n",
      "Epoch: 002/010 | Batch 32426/45709 | Average Loss in last 25 iteration(s): 0.0916 | Elapsed 9:30:27\n",
      "Epoch: 002/010 | Batch 32451/45709 | Average Loss in last 25 iteration(s): 0.0828 | Elapsed 9:30:54\n",
      "Epoch: 002/010 | Batch 32476/45709 | Average Loss in last 25 iteration(s): 0.0819 | Elapsed 9:31:21\n",
      "Epoch: 002/010 | Batch 32501/45709 | Average Loss in last 25 iteration(s): 0.0906 | Elapsed 9:31:48\n",
      "Epoch: 002/010 | Batch 32526/45709 | Average Loss in last 25 iteration(s): 0.0758 | Elapsed 9:32:13\n",
      "Epoch: 002/010 | Batch 32551/45709 | Average Loss in last 25 iteration(s): 0.0920 | Elapsed 9:32:36\n",
      "Epoch: 002/010 | Batch 32576/45709 | Average Loss in last 25 iteration(s): 0.0703 | Elapsed 9:33:03\n",
      "Epoch: 002/010 | Batch 32601/45709 | Average Loss in last 25 iteration(s): 0.1064 | Elapsed 9:33:31\n",
      "Epoch: 002/010 | Batch 32626/45709 | Average Loss in last 25 iteration(s): 0.0872 | Elapsed 9:33:59\n",
      "Epoch: 002/010 | Batch 32651/45709 | Average Loss in last 25 iteration(s): 0.0793 | Elapsed 9:34:27\n",
      "Epoch: 002/010 | Batch 32676/45709 | Average Loss in last 25 iteration(s): 0.0998 | Elapsed 9:34:52\n",
      "Epoch: 002/010 | Batch 32701/45709 | Average Loss in last 25 iteration(s): 0.1074 | Elapsed 9:35:16\n",
      "Epoch: 002/010 | Batch 32726/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 9:35:43\n",
      "Epoch: 002/010 | Batch 32751/45709 | Average Loss in last 25 iteration(s): 0.0759 | Elapsed 9:36:09\n",
      "Epoch: 002/010 | Batch 32776/45709 | Average Loss in last 25 iteration(s): 0.1071 | Elapsed 9:36:36\n",
      "Epoch: 002/010 | Batch 32801/45709 | Average Loss in last 25 iteration(s): 0.1044 | Elapsed 9:37:03\n",
      "Epoch: 002/010 | Batch 32826/45709 | Average Loss in last 25 iteration(s): 0.0957 | Elapsed 9:37:30\n",
      "Epoch: 002/010 | Batch 32851/45709 | Average Loss in last 25 iteration(s): 0.1004 | Elapsed 9:37:54\n",
      "Epoch: 002/010 | Batch 32876/45709 | Average Loss in last 25 iteration(s): 0.0834 | Elapsed 9:38:20\n",
      "Epoch: 002/010 | Batch 32901/45709 | Average Loss in last 25 iteration(s): 0.1214 | Elapsed 9:38:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 32926/45709 | Average Loss in last 25 iteration(s): 0.0823 | Elapsed 9:39:18\n",
      "Epoch: 002/010 | Batch 32951/45709 | Average Loss in last 25 iteration(s): 0.0917 | Elapsed 9:39:44\n",
      "Epoch: 002/010 | Batch 32976/45709 | Average Loss in last 25 iteration(s): 0.1088 | Elapsed 9:40:10\n",
      "Epoch: 002/010 | Batch 33001/45709 | Average Loss in last 25 iteration(s): 0.0870 | Elapsed 9:40:35\n",
      "Epoch: 002/010 | Batch 33026/45709 | Average Loss in last 25 iteration(s): 0.0870 | Elapsed 9:41:00\n",
      "Epoch: 002/010 | Batch 33051/45709 | Average Loss in last 25 iteration(s): 0.1144 | Elapsed 9:41:28\n",
      "Epoch: 002/010 | Batch 33076/45709 | Average Loss in last 25 iteration(s): 0.0786 | Elapsed 9:41:55\n",
      "Epoch: 002/010 | Batch 33101/45709 | Average Loss in last 25 iteration(s): 0.0582 | Elapsed 9:42:22\n",
      "Epoch: 002/010 | Batch 33126/45709 | Average Loss in last 25 iteration(s): 0.0913 | Elapsed 9:42:47\n",
      "Epoch: 002/010 | Batch 33151/45709 | Average Loss in last 25 iteration(s): 0.0962 | Elapsed 9:43:14\n",
      "Epoch: 002/010 | Batch 33176/45709 | Average Loss in last 25 iteration(s): 0.1008 | Elapsed 9:43:37\n",
      "Epoch: 002/010 | Batch 33201/45709 | Average Loss in last 25 iteration(s): 0.0896 | Elapsed 9:44:03\n",
      "Epoch: 002/010 | Batch 33226/45709 | Average Loss in last 25 iteration(s): 0.0980 | Elapsed 9:44:31\n",
      "Epoch: 002/010 | Batch 33251/45709 | Average Loss in last 25 iteration(s): 0.0851 | Elapsed 9:44:58\n",
      "Epoch: 002/010 | Batch 33276/45709 | Average Loss in last 25 iteration(s): 0.0855 | Elapsed 9:45:25\n",
      "Epoch: 002/010 | Batch 33301/45709 | Average Loss in last 25 iteration(s): 0.1023 | Elapsed 9:45:51\n",
      "Epoch: 002/010 | Batch 33326/45709 | Average Loss in last 25 iteration(s): 0.1067 | Elapsed 9:46:13\n",
      "Epoch: 002/010 | Batch 33351/45709 | Average Loss in last 25 iteration(s): 0.0750 | Elapsed 9:46:42\n",
      "Epoch: 002/010 | Batch 33376/45709 | Average Loss in last 25 iteration(s): 0.1026 | Elapsed 9:47:10\n",
      "Epoch: 002/010 | Batch 33401/45709 | Average Loss in last 25 iteration(s): 0.0666 | Elapsed 9:47:35\n",
      "Epoch: 002/010 | Batch 33426/45709 | Average Loss in last 25 iteration(s): 0.1195 | Elapsed 9:48:03\n",
      "Epoch: 002/010 | Batch 33451/45709 | Average Loss in last 25 iteration(s): 0.1164 | Elapsed 9:48:29\n",
      "Epoch: 002/010 | Batch 33476/45709 | Average Loss in last 25 iteration(s): 0.1142 | Elapsed 9:48:53\n",
      "Epoch: 002/010 | Batch 33501/45709 | Average Loss in last 25 iteration(s): 0.1083 | Elapsed 9:49:21\n",
      "Epoch: 002/010 | Batch 33526/45709 | Average Loss in last 25 iteration(s): 0.0722 | Elapsed 9:49:49\n",
      "Epoch: 002/010 | Batch 33551/45709 | Average Loss in last 25 iteration(s): 0.0769 | Elapsed 9:50:15\n",
      "Epoch: 002/010 | Batch 33576/45709 | Average Loss in last 25 iteration(s): 0.0929 | Elapsed 9:50:41\n",
      "Epoch: 002/010 | Batch 33601/45709 | Average Loss in last 25 iteration(s): 0.0926 | Elapsed 9:51:08\n",
      "Epoch: 002/010 | Batch 33626/45709 | Average Loss in last 25 iteration(s): 0.1004 | Elapsed 9:51:32\n",
      "Epoch: 002/010 | Batch 33651/45709 | Average Loss in last 25 iteration(s): 0.0832 | Elapsed 9:51:59\n",
      "Epoch: 002/010 | Batch 33676/45709 | Average Loss in last 25 iteration(s): 0.0637 | Elapsed 9:52:27\n",
      "Epoch: 002/010 | Batch 33701/45709 | Average Loss in last 25 iteration(s): 0.1486 | Elapsed 9:52:54\n",
      "Epoch: 002/010 | Batch 33726/45709 | Average Loss in last 25 iteration(s): 0.0984 | Elapsed 9:53:19\n",
      "Epoch: 002/010 | Batch 33751/45709 | Average Loss in last 25 iteration(s): 0.1077 | Elapsed 9:53:46\n",
      "Epoch: 002/010 | Batch 33776/45709 | Average Loss in last 25 iteration(s): 0.0710 | Elapsed 9:54:10\n",
      "Epoch: 002/010 | Batch 33801/45709 | Average Loss in last 25 iteration(s): 0.0783 | Elapsed 9:54:38\n",
      "Epoch: 002/010 | Batch 33826/45709 | Average Loss in last 25 iteration(s): 0.0805 | Elapsed 9:55:05\n",
      "Epoch: 002/010 | Batch 33851/45709 | Average Loss in last 25 iteration(s): 0.0938 | Elapsed 9:55:31\n",
      "Epoch: 002/010 | Batch 33876/45709 | Average Loss in last 25 iteration(s): 0.1024 | Elapsed 9:55:59\n",
      "Epoch: 002/010 | Batch 33901/45709 | Average Loss in last 25 iteration(s): 0.0941 | Elapsed 9:56:26\n",
      "Epoch: 002/010 | Batch 33926/45709 | Average Loss in last 25 iteration(s): 0.1011 | Elapsed 9:56:49\n",
      "Epoch: 002/010 | Batch 33951/45709 | Average Loss in last 25 iteration(s): 0.0981 | Elapsed 9:57:17\n",
      "Epoch: 002/010 | Batch 33976/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 9:57:45\n",
      "Epoch: 002/010 | Batch 34001/45709 | Average Loss in last 25 iteration(s): 0.0870 | Elapsed 9:58:09\n",
      "Epoch: 002/010 | Batch 34026/45709 | Average Loss in last 25 iteration(s): 0.0578 | Elapsed 9:58:36\n",
      "Epoch: 002/010 | Batch 34051/45709 | Average Loss in last 25 iteration(s): 0.0841 | Elapsed 9:59:04\n",
      "Epoch: 002/010 | Batch 34076/45709 | Average Loss in last 25 iteration(s): 0.0950 | Elapsed 9:59:29\n",
      "Epoch: 002/010 | Batch 34101/45709 | Average Loss in last 25 iteration(s): 0.0944 | Elapsed 9:59:53\n",
      "Epoch: 002/010 | Batch 34126/45709 | Average Loss in last 25 iteration(s): 0.1185 | Elapsed 10:00:23\n",
      "Epoch: 002/010 | Batch 34151/45709 | Average Loss in last 25 iteration(s): 0.1248 | Elapsed 10:00:49\n",
      "Epoch: 002/010 | Batch 34176/45709 | Average Loss in last 25 iteration(s): 0.1287 | Elapsed 10:01:15\n",
      "Epoch: 002/010 | Batch 34201/45709 | Average Loss in last 25 iteration(s): 0.1121 | Elapsed 10:01:41\n",
      "Epoch: 002/010 | Batch 34226/45709 | Average Loss in last 25 iteration(s): 0.0806 | Elapsed 10:02:07\n",
      "Epoch: 002/010 | Batch 34251/45709 | Average Loss in last 25 iteration(s): 0.0989 | Elapsed 10:02:29\n",
      "Epoch: 002/010 | Batch 34276/45709 | Average Loss in last 25 iteration(s): 0.0622 | Elapsed 10:02:57\n",
      "Epoch: 002/010 | Batch 34301/45709 | Average Loss in last 25 iteration(s): 0.1021 | Elapsed 10:03:24\n",
      "Epoch: 002/010 | Batch 34326/45709 | Average Loss in last 25 iteration(s): 0.1042 | Elapsed 10:03:51\n",
      "Epoch: 002/010 | Batch 34351/45709 | Average Loss in last 25 iteration(s): 0.0827 | Elapsed 10:04:20\n",
      "Epoch: 002/010 | Batch 34376/45709 | Average Loss in last 25 iteration(s): 0.0880 | Elapsed 10:04:46\n",
      "Epoch: 002/010 | Batch 34401/45709 | Average Loss in last 25 iteration(s): 0.0974 | Elapsed 10:05:10\n",
      "Epoch: 002/010 | Batch 34426/45709 | Average Loss in last 25 iteration(s): 0.0955 | Elapsed 10:05:36\n",
      "Epoch: 002/010 | Batch 34451/45709 | Average Loss in last 25 iteration(s): 0.1218 | Elapsed 10:06:04\n",
      "Epoch: 002/010 | Batch 34476/45709 | Average Loss in last 25 iteration(s): 0.0935 | Elapsed 10:06:31\n",
      "Epoch: 002/010 | Batch 34501/45709 | Average Loss in last 25 iteration(s): 0.0838 | Elapsed 10:06:56\n",
      "Epoch: 002/010 | Batch 34526/45709 | Average Loss in last 25 iteration(s): 0.0808 | Elapsed 10:07:24\n",
      "Epoch: 002/010 | Batch 34551/45709 | Average Loss in last 25 iteration(s): 0.1066 | Elapsed 10:07:49\n",
      "Epoch: 002/010 | Batch 34576/45709 | Average Loss in last 25 iteration(s): 0.0811 | Elapsed 10:08:12\n",
      "Epoch: 002/010 | Batch 34601/45709 | Average Loss in last 25 iteration(s): 0.1134 | Elapsed 10:08:41\n",
      "Epoch: 002/010 | Batch 34626/45709 | Average Loss in last 25 iteration(s): 0.1012 | Elapsed 10:09:09\n",
      "Epoch: 002/010 | Batch 34651/45709 | Average Loss in last 25 iteration(s): 0.1055 | Elapsed 10:09:36\n",
      "Epoch: 002/010 | Batch 34676/45709 | Average Loss in last 25 iteration(s): 0.1051 | Elapsed 10:10:02\n",
      "Epoch: 002/010 | Batch 34701/45709 | Average Loss in last 25 iteration(s): 0.1036 | Elapsed 10:10:28\n",
      "Epoch: 002/010 | Batch 34726/45709 | Average Loss in last 25 iteration(s): 0.0653 | Elapsed 10:10:53\n",
      "Epoch: 002/010 | Batch 34751/45709 | Average Loss in last 25 iteration(s): 0.0998 | Elapsed 10:11:20\n",
      "Epoch: 002/010 | Batch 34776/45709 | Average Loss in last 25 iteration(s): 0.0738 | Elapsed 10:11:48\n",
      "Epoch: 002/010 | Batch 34801/45709 | Average Loss in last 25 iteration(s): 0.0720 | Elapsed 10:12:15\n",
      "Epoch: 002/010 | Batch 34826/45709 | Average Loss in last 25 iteration(s): 0.0865 | Elapsed 10:12:40\n",
      "Epoch: 002/010 | Batch 34851/45709 | Average Loss in last 25 iteration(s): 0.1136 | Elapsed 10:13:07\n",
      "Epoch: 002/010 | Batch 34876/45709 | Average Loss in last 25 iteration(s): 0.0725 | Elapsed 10:13:31\n",
      "Epoch: 002/010 | Batch 34901/45709 | Average Loss in last 25 iteration(s): 0.0814 | Elapsed 10:13:57\n",
      "Epoch: 002/010 | Batch 34926/45709 | Average Loss in last 25 iteration(s): 0.1017 | Elapsed 10:14:25\n",
      "Epoch: 002/010 | Batch 34951/45709 | Average Loss in last 25 iteration(s): 0.0903 | Elapsed 10:14:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 34976/45709 | Average Loss in last 25 iteration(s): 0.0910 | Elapsed 10:15:20\n",
      "Epoch: 002/010 | Batch 35001/45709 | Average Loss in last 25 iteration(s): 0.0940 | Elapsed 10:15:47\n",
      "Epoch: 002/010 | Batch 35026/45709 | Average Loss in last 25 iteration(s): 0.0704 | Elapsed 10:16:12\n",
      "Epoch: 002/010 | Batch 35051/45709 | Average Loss in last 25 iteration(s): 0.1228 | Elapsed 10:16:37\n",
      "Epoch: 002/010 | Batch 35076/45709 | Average Loss in last 25 iteration(s): 0.0656 | Elapsed 10:17:04\n",
      "Epoch: 002/010 | Batch 35101/45709 | Average Loss in last 25 iteration(s): 0.1087 | Elapsed 10:17:32\n",
      "Epoch: 002/010 | Batch 35126/45709 | Average Loss in last 25 iteration(s): 0.0626 | Elapsed 10:17:58\n",
      "Epoch: 002/010 | Batch 35151/45709 | Average Loss in last 25 iteration(s): 0.0611 | Elapsed 10:18:25\n",
      "Epoch: 002/010 | Batch 35176/45709 | Average Loss in last 25 iteration(s): 0.1079 | Elapsed 10:18:50\n",
      "Epoch: 002/010 | Batch 35201/45709 | Average Loss in last 25 iteration(s): 0.0832 | Elapsed 10:19:15\n",
      "Epoch: 002/010 | Batch 35226/45709 | Average Loss in last 25 iteration(s): 0.0781 | Elapsed 10:19:41\n",
      "Epoch: 002/010 | Batch 35251/45709 | Average Loss in last 25 iteration(s): 0.0674 | Elapsed 10:20:09\n",
      "Epoch: 002/010 | Batch 35276/45709 | Average Loss in last 25 iteration(s): 0.1082 | Elapsed 10:20:37\n",
      "Epoch: 002/010 | Batch 35301/45709 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 10:21:05\n",
      "Epoch: 002/010 | Batch 35326/45709 | Average Loss in last 25 iteration(s): 0.1157 | Elapsed 10:21:30\n",
      "Epoch: 002/010 | Batch 35351/45709 | Average Loss in last 25 iteration(s): 0.0950 | Elapsed 10:21:53\n",
      "Epoch: 002/010 | Batch 35376/45709 | Average Loss in last 25 iteration(s): 0.1149 | Elapsed 10:22:21\n",
      "Epoch: 002/010 | Batch 35401/45709 | Average Loss in last 25 iteration(s): 0.1288 | Elapsed 10:22:49\n",
      "Epoch: 002/010 | Batch 35426/45709 | Average Loss in last 25 iteration(s): 0.1106 | Elapsed 10:23:16\n",
      "Epoch: 002/010 | Batch 35451/45709 | Average Loss in last 25 iteration(s): 0.0782 | Elapsed 10:23:43\n",
      "Epoch: 002/010 | Batch 35476/45709 | Average Loss in last 25 iteration(s): 0.0940 | Elapsed 10:24:09\n",
      "Epoch: 002/010 | Batch 35501/45709 | Average Loss in last 25 iteration(s): 0.0593 | Elapsed 10:24:31\n",
      "Epoch: 002/010 | Batch 35526/45709 | Average Loss in last 25 iteration(s): 0.1074 | Elapsed 10:24:59\n",
      "Epoch: 002/010 | Batch 35551/45709 | Average Loss in last 25 iteration(s): 0.0739 | Elapsed 10:25:28\n",
      "Epoch: 002/010 | Batch 35576/45709 | Average Loss in last 25 iteration(s): 0.1238 | Elapsed 10:25:56\n",
      "Epoch: 002/010 | Batch 35601/45709 | Average Loss in last 25 iteration(s): 0.0979 | Elapsed 10:26:21\n",
      "Epoch: 002/010 | Batch 35626/45709 | Average Loss in last 25 iteration(s): 0.0778 | Elapsed 10:26:48\n",
      "Epoch: 002/010 | Batch 35651/45709 | Average Loss in last 25 iteration(s): 0.0845 | Elapsed 10:27:12\n",
      "Epoch: 002/010 | Batch 35676/45709 | Average Loss in last 25 iteration(s): 0.0766 | Elapsed 10:27:40\n",
      "Epoch: 002/010 | Batch 35701/45709 | Average Loss in last 25 iteration(s): 0.1030 | Elapsed 10:28:08\n",
      "Epoch: 002/010 | Batch 35726/45709 | Average Loss in last 25 iteration(s): 0.0729 | Elapsed 10:28:33\n",
      "Epoch: 002/010 | Batch 35751/45709 | Average Loss in last 25 iteration(s): 0.0898 | Elapsed 10:29:00\n",
      "Epoch: 002/010 | Batch 35776/45709 | Average Loss in last 25 iteration(s): 0.0786 | Elapsed 10:29:26\n",
      "Epoch: 002/010 | Batch 35801/45709 | Average Loss in last 25 iteration(s): 0.0466 | Elapsed 10:29:51\n",
      "Epoch: 002/010 | Batch 35826/45709 | Average Loss in last 25 iteration(s): 0.0774 | Elapsed 10:30:16\n",
      "Epoch: 002/010 | Batch 35851/45709 | Average Loss in last 25 iteration(s): 0.0788 | Elapsed 10:30:44\n",
      "Epoch: 002/010 | Batch 35876/45709 | Average Loss in last 25 iteration(s): 0.0779 | Elapsed 10:31:12\n",
      "Epoch: 002/010 | Batch 35901/45709 | Average Loss in last 25 iteration(s): 0.0905 | Elapsed 10:31:39\n",
      "Epoch: 002/010 | Batch 35926/45709 | Average Loss in last 25 iteration(s): 0.0962 | Elapsed 10:32:06\n",
      "Epoch: 002/010 | Batch 35951/45709 | Average Loss in last 25 iteration(s): 0.0646 | Elapsed 10:32:31\n",
      "Epoch: 002/010 | Batch 35976/45709 | Average Loss in last 25 iteration(s): 0.0760 | Elapsed 10:32:55\n",
      "Epoch: 002/010 | Batch 36001/45709 | Average Loss in last 25 iteration(s): 0.0952 | Elapsed 10:33:23\n",
      "Epoch: 002/010 | Batch 36026/45709 | Average Loss in last 25 iteration(s): 0.0903 | Elapsed 10:33:51\n",
      "Epoch: 002/010 | Batch 36051/45709 | Average Loss in last 25 iteration(s): 0.0972 | Elapsed 10:34:16\n",
      "Epoch: 002/010 | Batch 36076/45709 | Average Loss in last 25 iteration(s): 0.1107 | Elapsed 10:34:41\n",
      "Epoch: 002/010 | Batch 36101/45709 | Average Loss in last 25 iteration(s): 0.0978 | Elapsed 10:35:08\n",
      "Epoch: 002/010 | Batch 36126/45709 | Average Loss in last 25 iteration(s): 0.0664 | Elapsed 10:35:30\n",
      "Epoch: 002/010 | Batch 36151/45709 | Average Loss in last 25 iteration(s): 0.0831 | Elapsed 10:35:59\n",
      "Epoch: 002/010 | Batch 36176/45709 | Average Loss in last 25 iteration(s): 0.0951 | Elapsed 10:36:27\n",
      "Epoch: 002/010 | Batch 36201/45709 | Average Loss in last 25 iteration(s): 0.0960 | Elapsed 10:36:53\n",
      "Epoch: 002/010 | Batch 36226/45709 | Average Loss in last 25 iteration(s): 0.0801 | Elapsed 10:37:21\n",
      "Epoch: 002/010 | Batch 36251/45709 | Average Loss in last 25 iteration(s): 0.0758 | Elapsed 10:37:49\n",
      "Epoch: 002/010 | Batch 36276/45709 | Average Loss in last 25 iteration(s): 0.1072 | Elapsed 10:38:12\n",
      "Epoch: 002/010 | Batch 36301/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 10:38:39\n",
      "Epoch: 002/010 | Batch 36326/45709 | Average Loss in last 25 iteration(s): 0.0972 | Elapsed 10:39:08\n",
      "Epoch: 002/010 | Batch 36351/45709 | Average Loss in last 25 iteration(s): 0.0893 | Elapsed 10:39:36\n",
      "Epoch: 002/010 | Batch 36376/45709 | Average Loss in last 25 iteration(s): 0.0757 | Elapsed 10:40:03\n",
      "Epoch: 002/010 | Batch 36401/45709 | Average Loss in last 25 iteration(s): 0.0851 | Elapsed 10:40:30\n",
      "Epoch: 002/010 | Batch 36426/45709 | Average Loss in last 25 iteration(s): 0.0684 | Elapsed 10:40:53\n",
      "Epoch: 002/010 | Batch 36451/45709 | Average Loss in last 25 iteration(s): 0.0893 | Elapsed 10:41:23\n",
      "Epoch: 002/010 | Batch 36476/45709 | Average Loss in last 25 iteration(s): 0.1032 | Elapsed 10:41:50\n",
      "Epoch: 002/010 | Batch 36501/45709 | Average Loss in last 25 iteration(s): 0.0957 | Elapsed 10:42:15\n",
      "Epoch: 002/010 | Batch 36526/45709 | Average Loss in last 25 iteration(s): 0.1142 | Elapsed 10:42:41\n",
      "Epoch: 002/010 | Batch 36551/45709 | Average Loss in last 25 iteration(s): 0.1197 | Elapsed 10:43:08\n",
      "Epoch: 002/010 | Batch 36576/45709 | Average Loss in last 25 iteration(s): 0.0959 | Elapsed 10:43:32\n",
      "Epoch: 002/010 | Batch 36601/45709 | Average Loss in last 25 iteration(s): 0.0931 | Elapsed 10:43:59\n",
      "Epoch: 002/010 | Batch 36626/45709 | Average Loss in last 25 iteration(s): 0.1094 | Elapsed 10:44:26\n",
      "Epoch: 002/010 | Batch 36651/45709 | Average Loss in last 25 iteration(s): 0.1318 | Elapsed 10:44:54\n",
      "Epoch: 002/010 | Batch 36676/45709 | Average Loss in last 25 iteration(s): 0.0686 | Elapsed 10:45:21\n",
      "Epoch: 002/010 | Batch 36701/45709 | Average Loss in last 25 iteration(s): 0.1228 | Elapsed 10:45:49\n",
      "Epoch: 002/010 | Batch 36726/45709 | Average Loss in last 25 iteration(s): 0.0754 | Elapsed 10:46:12\n",
      "Epoch: 002/010 | Batch 36751/45709 | Average Loss in last 25 iteration(s): 0.0969 | Elapsed 10:46:38\n",
      "Epoch: 002/010 | Batch 36776/45709 | Average Loss in last 25 iteration(s): 0.0947 | Elapsed 10:47:08\n",
      "Epoch: 002/010 | Batch 36801/45709 | Average Loss in last 25 iteration(s): 0.0687 | Elapsed 10:47:36\n",
      "Epoch: 002/010 | Batch 36826/45709 | Average Loss in last 25 iteration(s): 0.1128 | Elapsed 10:48:02\n",
      "Epoch: 002/010 | Batch 36851/45709 | Average Loss in last 25 iteration(s): 0.0937 | Elapsed 10:48:28\n",
      "Epoch: 002/010 | Batch 36876/45709 | Average Loss in last 25 iteration(s): 0.0806 | Elapsed 10:48:53\n",
      "Epoch: 002/010 | Batch 36901/45709 | Average Loss in last 25 iteration(s): 0.1171 | Elapsed 10:49:21\n",
      "Epoch: 002/010 | Batch 36926/45709 | Average Loss in last 25 iteration(s): 0.0873 | Elapsed 10:49:50\n",
      "Epoch: 002/010 | Batch 36951/45709 | Average Loss in last 25 iteration(s): 0.0728 | Elapsed 10:50:15\n",
      "Epoch: 002/010 | Batch 36976/45709 | Average Loss in last 25 iteration(s): 0.1114 | Elapsed 10:50:43\n",
      "Epoch: 002/010 | Batch 37001/45709 | Average Loss in last 25 iteration(s): 0.0971 | Elapsed 10:51:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 37026/45709 | Average Loss in last 25 iteration(s): 0.0579 | Elapsed 10:51:35\n",
      "Epoch: 002/010 | Batch 37051/45709 | Average Loss in last 25 iteration(s): 0.1027 | Elapsed 10:51:59\n",
      "Epoch: 002/010 | Batch 37076/45709 | Average Loss in last 25 iteration(s): 0.1193 | Elapsed 10:52:28\n",
      "Epoch: 002/010 | Batch 37101/45709 | Average Loss in last 25 iteration(s): 0.1052 | Elapsed 10:52:54\n",
      "Epoch: 002/010 | Batch 37126/45709 | Average Loss in last 25 iteration(s): 0.0833 | Elapsed 10:53:20\n",
      "Epoch: 002/010 | Batch 37151/45709 | Average Loss in last 25 iteration(s): 0.1325 | Elapsed 10:53:48\n",
      "Epoch: 002/010 | Batch 37176/45709 | Average Loss in last 25 iteration(s): 0.0821 | Elapsed 10:54:15\n",
      "Epoch: 002/010 | Batch 37201/45709 | Average Loss in last 25 iteration(s): 0.0848 | Elapsed 10:54:38\n",
      "Epoch: 002/010 | Batch 37226/45709 | Average Loss in last 25 iteration(s): 0.0811 | Elapsed 10:55:06\n",
      "Epoch: 002/010 | Batch 37251/45709 | Average Loss in last 25 iteration(s): 0.1224 | Elapsed 10:55:33\n",
      "Epoch: 002/010 | Batch 37276/45709 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 10:55:59\n",
      "Epoch: 002/010 | Batch 37301/45709 | Average Loss in last 25 iteration(s): 0.1095 | Elapsed 10:56:26\n",
      "Epoch: 002/010 | Batch 37326/45709 | Average Loss in last 25 iteration(s): 0.0761 | Elapsed 10:56:53\n",
      "Epoch: 002/010 | Batch 37351/45709 | Average Loss in last 25 iteration(s): 0.1123 | Elapsed 10:57:16\n",
      "Epoch: 002/010 | Batch 37376/45709 | Average Loss in last 25 iteration(s): 0.1012 | Elapsed 10:57:42\n",
      "Epoch: 002/010 | Batch 37401/45709 | Average Loss in last 25 iteration(s): 0.0668 | Elapsed 10:58:08\n",
      "Epoch: 002/010 | Batch 37426/45709 | Average Loss in last 25 iteration(s): 0.0892 | Elapsed 10:58:36\n",
      "Epoch: 002/010 | Batch 37451/45709 | Average Loss in last 25 iteration(s): 0.1092 | Elapsed 10:59:05\n",
      "Epoch: 002/010 | Batch 37476/45709 | Average Loss in last 25 iteration(s): 0.0860 | Elapsed 10:59:32\n",
      "Epoch: 002/010 | Batch 37501/45709 | Average Loss in last 25 iteration(s): 0.0920 | Elapsed 10:59:55\n",
      "Epoch: 002/010 | Batch 37526/45709 | Average Loss in last 25 iteration(s): 0.1031 | Elapsed 11:00:24\n",
      "Epoch: 002/010 | Batch 37551/45709 | Average Loss in last 25 iteration(s): 0.0739 | Elapsed 11:00:53\n",
      "Epoch: 002/010 | Batch 37576/45709 | Average Loss in last 25 iteration(s): 0.0710 | Elapsed 11:01:19\n",
      "Epoch: 002/010 | Batch 37601/45709 | Average Loss in last 25 iteration(s): 0.0740 | Elapsed 11:01:45\n",
      "Epoch: 002/010 | Batch 37626/45709 | Average Loss in last 25 iteration(s): 0.0758 | Elapsed 11:02:11\n",
      "Epoch: 002/010 | Batch 37651/45709 | Average Loss in last 25 iteration(s): 0.0775 | Elapsed 11:02:35\n",
      "Epoch: 002/010 | Batch 37676/45709 | Average Loss in last 25 iteration(s): 0.1201 | Elapsed 11:02:58\n",
      "Epoch: 002/010 | Batch 37701/45709 | Average Loss in last 25 iteration(s): 0.0903 | Elapsed 11:03:28\n",
      "Epoch: 002/010 | Batch 37726/45709 | Average Loss in last 25 iteration(s): 0.1025 | Elapsed 11:03:55\n",
      "Epoch: 002/010 | Batch 37751/45709 | Average Loss in last 25 iteration(s): 0.0761 | Elapsed 11:04:21\n",
      "Epoch: 002/010 | Batch 37776/45709 | Average Loss in last 25 iteration(s): 0.0862 | Elapsed 11:04:47\n",
      "Epoch: 002/010 | Batch 37801/45709 | Average Loss in last 25 iteration(s): 0.0867 | Elapsed 11:05:13\n",
      "Epoch: 002/010 | Batch 37826/45709 | Average Loss in last 25 iteration(s): 0.0975 | Elapsed 11:05:37\n",
      "Epoch: 002/010 | Batch 37851/45709 | Average Loss in last 25 iteration(s): 0.0967 | Elapsed 11:06:03\n",
      "Epoch: 002/010 | Batch 37876/45709 | Average Loss in last 25 iteration(s): 0.1102 | Elapsed 11:06:31\n",
      "Epoch: 002/010 | Batch 37901/45709 | Average Loss in last 25 iteration(s): 0.0892 | Elapsed 11:06:58\n",
      "Epoch: 002/010 | Batch 37926/45709 | Average Loss in last 25 iteration(s): 0.0997 | Elapsed 11:07:23\n",
      "Epoch: 002/010 | Batch 37951/45709 | Average Loss in last 25 iteration(s): 0.0801 | Elapsed 11:07:50\n",
      "Epoch: 002/010 | Batch 37976/45709 | Average Loss in last 25 iteration(s): 0.1247 | Elapsed 11:08:14\n",
      "Epoch: 002/010 | Batch 38001/45709 | Average Loss in last 25 iteration(s): 0.0786 | Elapsed 11:08:40\n",
      "Epoch: 002/010 | Batch 38026/45709 | Average Loss in last 25 iteration(s): 0.0930 | Elapsed 11:09:08\n",
      "Epoch: 002/010 | Batch 38051/45709 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 11:09:35\n",
      "Epoch: 002/010 | Batch 38076/45709 | Average Loss in last 25 iteration(s): 0.0931 | Elapsed 11:10:02\n",
      "Epoch: 002/010 | Batch 38101/45709 | Average Loss in last 25 iteration(s): 0.0809 | Elapsed 11:10:28\n",
      "Epoch: 002/010 | Batch 38126/45709 | Average Loss in last 25 iteration(s): 0.0889 | Elapsed 11:10:53\n",
      "Epoch: 002/010 | Batch 38151/45709 | Average Loss in last 25 iteration(s): 0.0866 | Elapsed 11:11:17\n",
      "Epoch: 002/010 | Batch 38176/45709 | Average Loss in last 25 iteration(s): 0.0868 | Elapsed 11:11:44\n",
      "Epoch: 002/010 | Batch 38201/45709 | Average Loss in last 25 iteration(s): 0.0615 | Elapsed 11:12:09\n",
      "Epoch: 002/010 | Batch 38226/45709 | Average Loss in last 25 iteration(s): 0.1324 | Elapsed 11:12:35\n",
      "Epoch: 002/010 | Batch 38251/45709 | Average Loss in last 25 iteration(s): 0.1007 | Elapsed 11:13:03\n",
      "Epoch: 002/010 | Batch 38276/45709 | Average Loss in last 25 iteration(s): 0.0886 | Elapsed 11:13:28\n",
      "Epoch: 002/010 | Batch 38301/45709 | Average Loss in last 25 iteration(s): 0.1152 | Elapsed 11:13:53\n",
      "Epoch: 002/010 | Batch 38326/45709 | Average Loss in last 25 iteration(s): 0.0737 | Elapsed 11:14:17\n",
      "Epoch: 002/010 | Batch 38351/45709 | Average Loss in last 25 iteration(s): 0.1113 | Elapsed 11:14:46\n",
      "Epoch: 002/010 | Batch 38376/45709 | Average Loss in last 25 iteration(s): 0.0917 | Elapsed 11:15:13\n",
      "Epoch: 002/010 | Batch 38401/45709 | Average Loss in last 25 iteration(s): 0.1295 | Elapsed 11:15:38\n",
      "Epoch: 002/010 | Batch 38426/45709 | Average Loss in last 25 iteration(s): 0.0770 | Elapsed 11:16:04\n",
      "Epoch: 002/010 | Batch 38451/45709 | Average Loss in last 25 iteration(s): 0.0928 | Elapsed 11:16:30\n",
      "Epoch: 002/010 | Batch 38476/45709 | Average Loss in last 25 iteration(s): 0.0883 | Elapsed 11:16:53\n",
      "Epoch: 002/010 | Batch 38501/45709 | Average Loss in last 25 iteration(s): 0.0907 | Elapsed 11:17:23\n",
      "Epoch: 002/010 | Batch 38526/45709 | Average Loss in last 25 iteration(s): 0.0934 | Elapsed 11:17:50\n",
      "Epoch: 002/010 | Batch 38551/45709 | Average Loss in last 25 iteration(s): 0.0881 | Elapsed 11:18:17\n",
      "Epoch: 002/010 | Batch 38576/45709 | Average Loss in last 25 iteration(s): 0.1104 | Elapsed 11:18:45\n",
      "Epoch: 002/010 | Batch 38601/45709 | Average Loss in last 25 iteration(s): 0.0577 | Elapsed 11:19:10\n",
      "Epoch: 002/010 | Batch 38626/45709 | Average Loss in last 25 iteration(s): 0.0767 | Elapsed 11:19:34\n",
      "Epoch: 002/010 | Batch 38651/45709 | Average Loss in last 25 iteration(s): 0.1128 | Elapsed 11:20:01\n",
      "Epoch: 002/010 | Batch 38676/45709 | Average Loss in last 25 iteration(s): 0.1033 | Elapsed 11:20:30\n",
      "Epoch: 002/010 | Batch 38701/45709 | Average Loss in last 25 iteration(s): 0.1018 | Elapsed 11:20:54\n",
      "Epoch: 002/010 | Batch 38726/45709 | Average Loss in last 25 iteration(s): 0.1204 | Elapsed 11:21:21\n",
      "Epoch: 002/010 | Batch 38751/45709 | Average Loss in last 25 iteration(s): 0.1068 | Elapsed 11:21:48\n",
      "Epoch: 002/010 | Batch 38776/45709 | Average Loss in last 25 iteration(s): 0.0629 | Elapsed 11:22:13\n",
      "Epoch: 002/010 | Batch 38801/45709 | Average Loss in last 25 iteration(s): 0.0690 | Elapsed 11:22:37\n",
      "Epoch: 002/010 | Batch 38826/45709 | Average Loss in last 25 iteration(s): 0.0918 | Elapsed 11:23:06\n",
      "Epoch: 002/010 | Batch 38851/45709 | Average Loss in last 25 iteration(s): 0.1039 | Elapsed 11:23:32\n",
      "Epoch: 002/010 | Batch 38876/45709 | Average Loss in last 25 iteration(s): 0.0810 | Elapsed 11:24:00\n",
      "Epoch: 002/010 | Batch 38901/45709 | Average Loss in last 25 iteration(s): 0.0877 | Elapsed 11:24:27\n",
      "Epoch: 002/010 | Batch 38926/45709 | Average Loss in last 25 iteration(s): 0.0973 | Elapsed 11:24:52\n",
      "Epoch: 002/010 | Batch 38951/45709 | Average Loss in last 25 iteration(s): 0.1236 | Elapsed 11:25:14\n",
      "Epoch: 002/010 | Batch 38976/45709 | Average Loss in last 25 iteration(s): 0.1196 | Elapsed 11:25:42\n",
      "Epoch: 002/010 | Batch 39001/45709 | Average Loss in last 25 iteration(s): 0.0882 | Elapsed 11:26:09\n",
      "Epoch: 002/010 | Batch 39026/45709 | Average Loss in last 25 iteration(s): 0.1018 | Elapsed 11:26:35\n",
      "Epoch: 002/010 | Batch 39051/45709 | Average Loss in last 25 iteration(s): 0.0840 | Elapsed 11:27:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 39076/45709 | Average Loss in last 25 iteration(s): 0.0978 | Elapsed 11:27:29\n",
      "Epoch: 002/010 | Batch 39101/45709 | Average Loss in last 25 iteration(s): 0.0785 | Elapsed 11:27:53\n",
      "Epoch: 002/010 | Batch 39126/45709 | Average Loss in last 25 iteration(s): 0.0619 | Elapsed 11:28:18\n",
      "Epoch: 002/010 | Batch 39151/45709 | Average Loss in last 25 iteration(s): 0.0662 | Elapsed 11:28:48\n",
      "Epoch: 002/010 | Batch 39176/45709 | Average Loss in last 25 iteration(s): 0.0849 | Elapsed 11:29:14\n",
      "Epoch: 002/010 | Batch 39201/45709 | Average Loss in last 25 iteration(s): 0.0903 | Elapsed 11:29:43\n",
      "Epoch: 002/010 | Batch 39226/45709 | Average Loss in last 25 iteration(s): 0.0939 | Elapsed 11:30:09\n",
      "Epoch: 002/010 | Batch 39251/45709 | Average Loss in last 25 iteration(s): 0.0899 | Elapsed 11:30:35\n",
      "Epoch: 002/010 | Batch 39276/45709 | Average Loss in last 25 iteration(s): 0.0687 | Elapsed 11:30:58\n",
      "Epoch: 002/010 | Batch 39301/45709 | Average Loss in last 25 iteration(s): 0.0971 | Elapsed 11:31:28\n",
      "Epoch: 002/010 | Batch 39326/45709 | Average Loss in last 25 iteration(s): 0.1182 | Elapsed 11:31:54\n",
      "Epoch: 002/010 | Batch 39351/45709 | Average Loss in last 25 iteration(s): 0.1129 | Elapsed 11:32:19\n",
      "Epoch: 002/010 | Batch 39376/45709 | Average Loss in last 25 iteration(s): 0.0714 | Elapsed 11:32:45\n",
      "Epoch: 002/010 | Batch 39401/45709 | Average Loss in last 25 iteration(s): 0.0625 | Elapsed 11:33:11\n",
      "Epoch: 002/010 | Batch 39426/45709 | Average Loss in last 25 iteration(s): 0.0895 | Elapsed 11:33:35\n",
      "Epoch: 002/010 | Batch 39451/45709 | Average Loss in last 25 iteration(s): 0.0932 | Elapsed 11:34:01\n",
      "Epoch: 002/010 | Batch 39476/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 11:34:30\n",
      "Epoch: 002/010 | Batch 39501/45709 | Average Loss in last 25 iteration(s): 0.0820 | Elapsed 11:34:55\n",
      "Epoch: 002/010 | Batch 39526/45709 | Average Loss in last 25 iteration(s): 0.0969 | Elapsed 11:35:22\n",
      "Epoch: 002/010 | Batch 39551/45709 | Average Loss in last 25 iteration(s): 0.1164 | Elapsed 11:35:48\n",
      "Epoch: 002/010 | Batch 39576/45709 | Average Loss in last 25 iteration(s): 0.1039 | Elapsed 11:36:14\n",
      "Epoch: 002/010 | Batch 39601/45709 | Average Loss in last 25 iteration(s): 0.1233 | Elapsed 11:36:37\n",
      "Epoch: 002/010 | Batch 39626/45709 | Average Loss in last 25 iteration(s): 0.1296 | Elapsed 11:37:04\n",
      "Epoch: 002/010 | Batch 39651/45709 | Average Loss in last 25 iteration(s): 0.0979 | Elapsed 11:37:32\n",
      "Epoch: 002/010 | Batch 39676/45709 | Average Loss in last 25 iteration(s): 0.0969 | Elapsed 11:37:58\n",
      "Epoch: 002/010 | Batch 39701/45709 | Average Loss in last 25 iteration(s): 0.0613 | Elapsed 11:38:27\n",
      "Epoch: 002/010 | Batch 39726/45709 | Average Loss in last 25 iteration(s): 0.0959 | Elapsed 11:38:52\n",
      "Epoch: 002/010 | Batch 39751/45709 | Average Loss in last 25 iteration(s): 0.1013 | Elapsed 11:39:16\n",
      "Epoch: 002/010 | Batch 39776/45709 | Average Loss in last 25 iteration(s): 0.0911 | Elapsed 11:39:41\n",
      "Epoch: 002/010 | Batch 39801/45709 | Average Loss in last 25 iteration(s): 0.0806 | Elapsed 11:40:10\n",
      "Epoch: 002/010 | Batch 39826/45709 | Average Loss in last 25 iteration(s): 0.0699 | Elapsed 11:40:36\n",
      "Epoch: 002/010 | Batch 39851/45709 | Average Loss in last 25 iteration(s): 0.0736 | Elapsed 11:41:02\n",
      "Epoch: 002/010 | Batch 39876/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 11:41:30\n",
      "Epoch: 002/010 | Batch 39901/45709 | Average Loss in last 25 iteration(s): 0.0923 | Elapsed 11:41:56\n",
      "Epoch: 002/010 | Batch 39926/45709 | Average Loss in last 25 iteration(s): 0.0621 | Elapsed 11:42:19\n",
      "Epoch: 002/010 | Batch 39951/45709 | Average Loss in last 25 iteration(s): 0.1019 | Elapsed 11:42:47\n",
      "Epoch: 002/010 | Batch 39976/45709 | Average Loss in last 25 iteration(s): 0.0839 | Elapsed 11:43:12\n",
      "Epoch: 002/010 | Batch 40001/45709 | Average Loss in last 25 iteration(s): 0.0677 | Elapsed 11:43:37\n",
      "Epoch: 002/010 | Batch 40026/45709 | Average Loss in last 25 iteration(s): 0.0868 | Elapsed 11:44:05\n",
      "Epoch: 002/010 | Batch 40051/45709 | Average Loss in last 25 iteration(s): 0.1035 | Elapsed 11:44:31\n",
      "Epoch: 002/010 | Batch 40076/45709 | Average Loss in last 25 iteration(s): 0.0760 | Elapsed 11:44:55\n",
      "Epoch: 002/010 | Batch 40101/45709 | Average Loss in last 25 iteration(s): 0.1027 | Elapsed 11:45:22\n",
      "Epoch: 002/010 | Batch 40126/45709 | Average Loss in last 25 iteration(s): 0.0703 | Elapsed 11:45:50\n",
      "Epoch: 002/010 | Batch 40151/45709 | Average Loss in last 25 iteration(s): 0.0740 | Elapsed 11:46:17\n",
      "Epoch: 002/010 | Batch 40176/45709 | Average Loss in last 25 iteration(s): 0.0904 | Elapsed 11:46:45\n",
      "Epoch: 002/010 | Batch 40201/45709 | Average Loss in last 25 iteration(s): 0.1050 | Elapsed 11:47:13\n",
      "Epoch: 002/010 | Batch 40226/45709 | Average Loss in last 25 iteration(s): 0.1275 | Elapsed 11:47:35\n",
      "Epoch: 002/010 | Batch 40251/45709 | Average Loss in last 25 iteration(s): 0.0953 | Elapsed 11:48:01\n",
      "Epoch: 002/010 | Batch 40276/45709 | Average Loss in last 25 iteration(s): 0.1023 | Elapsed 11:48:29\n",
      "Epoch: 002/010 | Batch 40301/45709 | Average Loss in last 25 iteration(s): 0.0900 | Elapsed 11:48:56\n",
      "Epoch: 002/010 | Batch 40326/45709 | Average Loss in last 25 iteration(s): 0.0875 | Elapsed 11:49:22\n",
      "Epoch: 002/010 | Batch 40351/45709 | Average Loss in last 25 iteration(s): 0.0813 | Elapsed 11:49:48\n",
      "Epoch: 002/010 | Batch 40376/45709 | Average Loss in last 25 iteration(s): 0.0574 | Elapsed 11:50:13\n",
      "Epoch: 002/010 | Batch 40401/45709 | Average Loss in last 25 iteration(s): 0.0889 | Elapsed 11:50:39\n",
      "Epoch: 002/010 | Batch 40426/45709 | Average Loss in last 25 iteration(s): 0.1140 | Elapsed 11:51:09\n",
      "Epoch: 002/010 | Batch 40451/45709 | Average Loss in last 25 iteration(s): 0.0870 | Elapsed 11:51:35\n",
      "Epoch: 002/010 | Batch 40476/45709 | Average Loss in last 25 iteration(s): 0.0908 | Elapsed 11:52:02\n",
      "Epoch: 002/010 | Batch 40501/45709 | Average Loss in last 25 iteration(s): 0.0721 | Elapsed 11:52:27\n",
      "Epoch: 002/010 | Batch 40526/45709 | Average Loss in last 25 iteration(s): 0.0848 | Elapsed 11:52:51\n",
      "Epoch: 002/010 | Batch 40551/45709 | Average Loss in last 25 iteration(s): 0.0669 | Elapsed 11:53:23\n",
      "Epoch: 002/010 | Batch 40576/45709 | Average Loss in last 25 iteration(s): 0.0651 | Elapsed 11:53:51\n",
      "Epoch: 002/010 | Batch 40601/45709 | Average Loss in last 25 iteration(s): 0.0874 | Elapsed 11:54:12\n",
      "Epoch: 002/010 | Batch 40626/45709 | Average Loss in last 25 iteration(s): 0.0999 | Elapsed 11:54:34\n",
      "Epoch: 002/010 | Batch 40651/45709 | Average Loss in last 25 iteration(s): 0.0673 | Elapsed 11:55:01\n",
      "Epoch: 002/010 | Batch 40676/45709 | Average Loss in last 25 iteration(s): 0.0818 | Elapsed 11:55:26\n",
      "Epoch: 002/010 | Batch 40701/45709 | Average Loss in last 25 iteration(s): 0.0907 | Elapsed 11:55:54\n",
      "Epoch: 002/010 | Batch 40726/45709 | Average Loss in last 25 iteration(s): 0.0810 | Elapsed 11:56:21\n",
      "Epoch: 002/010 | Batch 40751/45709 | Average Loss in last 25 iteration(s): 0.0686 | Elapsed 11:56:51\n",
      "Epoch: 002/010 | Batch 40776/45709 | Average Loss in last 25 iteration(s): 0.0522 | Elapsed 11:57:14\n",
      "Epoch: 002/010 | Batch 40801/45709 | Average Loss in last 25 iteration(s): 0.1055 | Elapsed 11:57:42\n",
      "Epoch: 002/010 | Batch 40826/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 11:58:08\n",
      "Epoch: 002/010 | Batch 40851/45709 | Average Loss in last 25 iteration(s): 0.0898 | Elapsed 11:58:34\n",
      "Epoch: 002/010 | Batch 40876/45709 | Average Loss in last 25 iteration(s): 0.0555 | Elapsed 11:58:59\n",
      "Epoch: 002/010 | Batch 40901/45709 | Average Loss in last 25 iteration(s): 0.1068 | Elapsed 11:59:31\n",
      "Epoch: 002/010 | Batch 40926/45709 | Average Loss in last 25 iteration(s): 0.1290 | Elapsed 11:59:59\n",
      "Epoch: 002/010 | Batch 40951/45709 | Average Loss in last 25 iteration(s): 0.0878 | Elapsed 12:00:20\n",
      "Epoch: 002/010 | Batch 40976/45709 | Average Loss in last 25 iteration(s): 0.0798 | Elapsed 12:00:49\n",
      "Epoch: 002/010 | Batch 41001/45709 | Average Loss in last 25 iteration(s): 0.0824 | Elapsed 12:01:16\n",
      "Epoch: 002/010 | Batch 41026/45709 | Average Loss in last 25 iteration(s): 0.0844 | Elapsed 12:01:40\n",
      "Epoch: 002/010 | Batch 41051/45709 | Average Loss in last 25 iteration(s): 0.1000 | Elapsed 12:02:06\n",
      "Epoch: 002/010 | Batch 41076/45709 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 12:02:34\n",
      "Epoch: 002/010 | Batch 41101/45709 | Average Loss in last 25 iteration(s): 0.1008 | Elapsed 12:03:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 41126/45709 | Average Loss in last 25 iteration(s): 0.0735 | Elapsed 12:03:27\n",
      "Epoch: 002/010 | Batch 41151/45709 | Average Loss in last 25 iteration(s): 0.0884 | Elapsed 12:03:51\n",
      "Epoch: 002/010 | Batch 41176/45709 | Average Loss in last 25 iteration(s): 0.0710 | Elapsed 12:04:16\n",
      "Epoch: 002/010 | Batch 41201/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 12:04:48\n",
      "Epoch: 002/010 | Batch 41226/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 12:05:15\n",
      "Epoch: 002/010 | Batch 41251/45709 | Average Loss in last 25 iteration(s): 0.0626 | Elapsed 12:05:41\n",
      "Epoch: 002/010 | Batch 41276/45709 | Average Loss in last 25 iteration(s): 0.0728 | Elapsed 12:06:06\n",
      "Epoch: 002/010 | Batch 41301/45709 | Average Loss in last 25 iteration(s): 0.0687 | Elapsed 12:06:33\n",
      "Epoch: 002/010 | Batch 41326/45709 | Average Loss in last 25 iteration(s): 0.0846 | Elapsed 12:06:59\n",
      "Epoch: 002/010 | Batch 41351/45709 | Average Loss in last 25 iteration(s): 0.1116 | Elapsed 12:07:29\n",
      "Epoch: 002/010 | Batch 41376/45709 | Average Loss in last 25 iteration(s): 0.1154 | Elapsed 12:07:56\n",
      "Epoch: 002/010 | Batch 41401/45709 | Average Loss in last 25 iteration(s): 0.0643 | Elapsed 12:08:17\n",
      "Epoch: 002/010 | Batch 41426/45709 | Average Loss in last 25 iteration(s): 0.0739 | Elapsed 12:08:38\n",
      "Epoch: 002/010 | Batch 41451/45709 | Average Loss in last 25 iteration(s): 0.0666 | Elapsed 12:09:05\n",
      "Epoch: 002/010 | Batch 41476/45709 | Average Loss in last 25 iteration(s): 0.0690 | Elapsed 12:09:34\n",
      "Epoch: 002/010 | Batch 41501/45709 | Average Loss in last 25 iteration(s): 0.0695 | Elapsed 12:09:57\n",
      "Epoch: 002/010 | Batch 41526/45709 | Average Loss in last 25 iteration(s): 0.0805 | Elapsed 12:10:27\n",
      "Epoch: 002/010 | Batch 41551/45709 | Average Loss in last 25 iteration(s): 0.0469 | Elapsed 12:10:55\n",
      "Epoch: 002/010 | Batch 41576/45709 | Average Loss in last 25 iteration(s): 0.0698 | Elapsed 12:11:17\n",
      "Epoch: 002/010 | Batch 41601/45709 | Average Loss in last 25 iteration(s): 0.0953 | Elapsed 12:11:46\n",
      "Epoch: 002/010 | Batch 41626/45709 | Average Loss in last 25 iteration(s): 0.0976 | Elapsed 12:12:15\n",
      "Epoch: 002/010 | Batch 41651/45709 | Average Loss in last 25 iteration(s): 0.0580 | Elapsed 12:12:38\n",
      "Epoch: 002/010 | Batch 41676/45709 | Average Loss in last 25 iteration(s): 0.1021 | Elapsed 12:13:07\n",
      "Epoch: 002/010 | Batch 41701/45709 | Average Loss in last 25 iteration(s): 0.1094 | Elapsed 12:13:34\n",
      "Epoch: 002/010 | Batch 41726/45709 | Average Loss in last 25 iteration(s): 0.0495 | Elapsed 12:13:59\n",
      "Epoch: 002/010 | Batch 41751/45709 | Average Loss in last 25 iteration(s): 0.0830 | Elapsed 12:14:28\n",
      "Epoch: 002/010 | Batch 41776/45709 | Average Loss in last 25 iteration(s): 0.0620 | Elapsed 12:14:54\n",
      "Epoch: 002/010 | Batch 41801/45709 | Average Loss in last 25 iteration(s): 0.0667 | Elapsed 12:15:20\n",
      "Epoch: 002/010 | Batch 41826/45709 | Average Loss in last 25 iteration(s): 0.0838 | Elapsed 12:15:47\n",
      "Epoch: 002/010 | Batch 41851/45709 | Average Loss in last 25 iteration(s): 0.1011 | Elapsed 12:16:12\n",
      "Epoch: 002/010 | Batch 41876/45709 | Average Loss in last 25 iteration(s): 0.0951 | Elapsed 12:16:38\n",
      "Epoch: 002/010 | Batch 41901/45709 | Average Loss in last 25 iteration(s): 0.0611 | Elapsed 12:17:07\n",
      "Epoch: 002/010 | Batch 41926/45709 | Average Loss in last 25 iteration(s): 0.1109 | Elapsed 12:17:34\n",
      "Epoch: 002/010 | Batch 41951/45709 | Average Loss in last 25 iteration(s): 0.0677 | Elapsed 12:17:56\n",
      "Epoch: 002/010 | Batch 41976/45709 | Average Loss in last 25 iteration(s): 0.1008 | Elapsed 12:18:30\n",
      "Epoch: 002/010 | Batch 42001/45709 | Average Loss in last 25 iteration(s): 0.0735 | Elapsed 12:19:02\n",
      "Epoch: 002/010 | Batch 42026/45709 | Average Loss in last 25 iteration(s): 0.1311 | Elapsed 12:19:29\n",
      "Epoch: 002/010 | Batch 42051/45709 | Average Loss in last 25 iteration(s): 0.0929 | Elapsed 12:19:55\n",
      "Epoch: 002/010 | Batch 42076/45709 | Average Loss in last 25 iteration(s): 0.0782 | Elapsed 12:20:16\n",
      "Epoch: 002/010 | Batch 42101/45709 | Average Loss in last 25 iteration(s): 0.0937 | Elapsed 12:20:46\n",
      "Epoch: 002/010 | Batch 42126/45709 | Average Loss in last 25 iteration(s): 0.1028 | Elapsed 12:21:20\n",
      "Epoch: 002/010 | Batch 42151/45709 | Average Loss in last 25 iteration(s): 0.0792 | Elapsed 12:21:48\n",
      "Epoch: 002/010 | Batch 42176/45709 | Average Loss in last 25 iteration(s): 0.0783 | Elapsed 12:22:14\n",
      "Epoch: 002/010 | Batch 42201/45709 | Average Loss in last 25 iteration(s): 0.0757 | Elapsed 12:22:35\n",
      "Epoch: 002/010 | Batch 42226/45709 | Average Loss in last 25 iteration(s): 0.0780 | Elapsed 12:22:57\n",
      "Epoch: 002/010 | Batch 42251/45709 | Average Loss in last 25 iteration(s): 0.0837 | Elapsed 12:23:28\n",
      "Epoch: 002/010 | Batch 42276/45709 | Average Loss in last 25 iteration(s): 0.0889 | Elapsed 12:23:59\n",
      "Epoch: 002/010 | Batch 42301/45709 | Average Loss in last 25 iteration(s): 0.0902 | Elapsed 12:24:26\n",
      "Epoch: 002/010 | Batch 42326/45709 | Average Loss in last 25 iteration(s): 0.0885 | Elapsed 12:24:54\n",
      "Epoch: 002/010 | Batch 42351/45709 | Average Loss in last 25 iteration(s): 0.0926 | Elapsed 12:25:15\n",
      "Epoch: 002/010 | Batch 42376/45709 | Average Loss in last 25 iteration(s): 0.0763 | Elapsed 12:25:37\n",
      "Epoch: 002/010 | Batch 42401/45709 | Average Loss in last 25 iteration(s): 0.0747 | Elapsed 12:26:05\n",
      "Epoch: 002/010 | Batch 42426/45709 | Average Loss in last 25 iteration(s): 0.1082 | Elapsed 12:26:34\n",
      "Epoch: 002/010 | Batch 42451/45709 | Average Loss in last 25 iteration(s): 0.0900 | Elapsed 12:27:00\n",
      "Epoch: 002/010 | Batch 42476/45709 | Average Loss in last 25 iteration(s): 0.0724 | Elapsed 12:27:27\n",
      "Epoch: 002/010 | Batch 42501/45709 | Average Loss in last 25 iteration(s): 0.1195 | Elapsed 12:27:54\n",
      "Epoch: 002/010 | Batch 42526/45709 | Average Loss in last 25 iteration(s): 0.0669 | Elapsed 12:28:17\n",
      "Epoch: 002/010 | Batch 42551/45709 | Average Loss in last 25 iteration(s): 0.1302 | Elapsed 12:28:45\n",
      "Epoch: 002/010 | Batch 42576/45709 | Average Loss in last 25 iteration(s): 0.1033 | Elapsed 12:29:13\n",
      "Epoch: 002/010 | Batch 42601/45709 | Average Loss in last 25 iteration(s): 0.0759 | Elapsed 12:29:39\n",
      "Epoch: 002/010 | Batch 42626/45709 | Average Loss in last 25 iteration(s): 0.0632 | Elapsed 12:30:05\n",
      "Epoch: 002/010 | Batch 42651/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 12:30:33\n",
      "Epoch: 002/010 | Batch 42676/45709 | Average Loss in last 25 iteration(s): 0.1007 | Elapsed 12:30:57\n",
      "Epoch: 002/010 | Batch 42701/45709 | Average Loss in last 25 iteration(s): 0.0834 | Elapsed 12:31:22\n",
      "Epoch: 002/010 | Batch 42726/45709 | Average Loss in last 25 iteration(s): 0.0724 | Elapsed 12:31:49\n",
      "Epoch: 002/010 | Batch 42751/45709 | Average Loss in last 25 iteration(s): 0.0599 | Elapsed 12:32:16\n",
      "Epoch: 002/010 | Batch 42776/45709 | Average Loss in last 25 iteration(s): 0.0905 | Elapsed 12:32:42\n",
      "Epoch: 002/010 | Batch 42801/45709 | Average Loss in last 25 iteration(s): 0.0733 | Elapsed 12:33:09\n",
      "Epoch: 002/010 | Batch 42826/45709 | Average Loss in last 25 iteration(s): 0.1382 | Elapsed 12:33:36\n",
      "Epoch: 002/010 | Batch 42851/45709 | Average Loss in last 25 iteration(s): 0.0741 | Elapsed 12:33:59\n",
      "Epoch: 002/010 | Batch 42876/45709 | Average Loss in last 25 iteration(s): 0.1047 | Elapsed 12:34:27\n",
      "Epoch: 002/010 | Batch 42901/45709 | Average Loss in last 25 iteration(s): 0.0993 | Elapsed 12:34:55\n",
      "Epoch: 002/010 | Batch 42926/45709 | Average Loss in last 25 iteration(s): 0.1067 | Elapsed 12:35:21\n",
      "Epoch: 002/010 | Batch 42951/45709 | Average Loss in last 25 iteration(s): 0.0840 | Elapsed 12:35:48\n",
      "Epoch: 002/010 | Batch 42976/45709 | Average Loss in last 25 iteration(s): 0.0881 | Elapsed 12:36:14\n",
      "Epoch: 002/010 | Batch 43001/45709 | Average Loss in last 25 iteration(s): 0.1054 | Elapsed 12:36:38\n",
      "Epoch: 002/010 | Batch 43026/45709 | Average Loss in last 25 iteration(s): 0.1016 | Elapsed 12:37:05\n",
      "Epoch: 002/010 | Batch 43051/45709 | Average Loss in last 25 iteration(s): 0.0898 | Elapsed 12:37:32\n",
      "Epoch: 002/010 | Batch 43076/45709 | Average Loss in last 25 iteration(s): 0.0808 | Elapsed 12:38:00\n",
      "Epoch: 002/010 | Batch 43101/45709 | Average Loss in last 25 iteration(s): 0.0587 | Elapsed 12:38:25\n",
      "Epoch: 002/010 | Batch 43126/45709 | Average Loss in last 25 iteration(s): 0.0426 | Elapsed 12:38:51\n",
      "Epoch: 002/010 | Batch 43151/45709 | Average Loss in last 25 iteration(s): 0.0889 | Elapsed 12:39:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 43176/45709 | Average Loss in last 25 iteration(s): 0.0827 | Elapsed 12:39:41\n",
      "Epoch: 002/010 | Batch 43201/45709 | Average Loss in last 25 iteration(s): 0.0977 | Elapsed 12:40:08\n",
      "Epoch: 002/010 | Batch 43226/45709 | Average Loss in last 25 iteration(s): 0.0736 | Elapsed 12:40:34\n",
      "Epoch: 002/010 | Batch 43251/45709 | Average Loss in last 25 iteration(s): 0.1153 | Elapsed 12:41:02\n",
      "Epoch: 002/010 | Batch 43276/45709 | Average Loss in last 25 iteration(s): 0.1345 | Elapsed 12:41:29\n",
      "Epoch: 002/010 | Batch 43301/45709 | Average Loss in last 25 iteration(s): 0.0847 | Elapsed 12:41:54\n",
      "Epoch: 002/010 | Batch 43326/45709 | Average Loss in last 25 iteration(s): 0.0726 | Elapsed 12:42:18\n",
      "Epoch: 002/010 | Batch 43351/45709 | Average Loss in last 25 iteration(s): 0.1062 | Elapsed 12:42:46\n",
      "Epoch: 002/010 | Batch 43376/45709 | Average Loss in last 25 iteration(s): 0.0902 | Elapsed 12:43:13\n",
      "Epoch: 002/010 | Batch 43401/45709 | Average Loss in last 25 iteration(s): 0.0769 | Elapsed 12:43:38\n",
      "Epoch: 002/010 | Batch 43426/45709 | Average Loss in last 25 iteration(s): 0.1076 | Elapsed 12:44:05\n",
      "Epoch: 002/010 | Batch 43451/45709 | Average Loss in last 25 iteration(s): 0.0581 | Elapsed 12:44:31\n",
      "Epoch: 002/010 | Batch 43476/45709 | Average Loss in last 25 iteration(s): 0.1142 | Elapsed 12:44:56\n",
      "Epoch: 002/010 | Batch 43501/45709 | Average Loss in last 25 iteration(s): 0.0780 | Elapsed 12:45:21\n",
      "Epoch: 002/010 | Batch 43526/45709 | Average Loss in last 25 iteration(s): 0.0500 | Elapsed 12:45:49\n",
      "Epoch: 002/010 | Batch 43551/45709 | Average Loss in last 25 iteration(s): 0.1206 | Elapsed 12:46:15\n",
      "Epoch: 002/010 | Batch 43576/45709 | Average Loss in last 25 iteration(s): 0.0835 | Elapsed 12:46:41\n",
      "Epoch: 002/010 | Batch 43601/45709 | Average Loss in last 25 iteration(s): 0.0949 | Elapsed 12:47:08\n",
      "Epoch: 002/010 | Batch 43626/45709 | Average Loss in last 25 iteration(s): 0.0649 | Elapsed 12:47:34\n",
      "Epoch: 002/010 | Batch 43651/45709 | Average Loss in last 25 iteration(s): 0.1049 | Elapsed 12:47:56\n",
      "Epoch: 002/010 | Batch 43676/45709 | Average Loss in last 25 iteration(s): 0.0859 | Elapsed 12:48:23\n",
      "Epoch: 002/010 | Batch 43701/45709 | Average Loss in last 25 iteration(s): 0.0588 | Elapsed 12:48:51\n",
      "Epoch: 002/010 | Batch 43726/45709 | Average Loss in last 25 iteration(s): 0.0588 | Elapsed 12:49:18\n",
      "Epoch: 002/010 | Batch 43751/45709 | Average Loss in last 25 iteration(s): 0.1121 | Elapsed 12:49:43\n",
      "Epoch: 002/010 | Batch 43776/45709 | Average Loss in last 25 iteration(s): 0.0763 | Elapsed 12:50:09\n",
      "Epoch: 002/010 | Batch 43801/45709 | Average Loss in last 25 iteration(s): 0.0966 | Elapsed 12:50:34\n",
      "Epoch: 002/010 | Batch 43826/45709 | Average Loss in last 25 iteration(s): 0.1017 | Elapsed 12:51:00\n",
      "Epoch: 002/010 | Batch 43851/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 12:51:27\n",
      "Epoch: 002/010 | Batch 43876/45709 | Average Loss in last 25 iteration(s): 0.1036 | Elapsed 12:51:54\n",
      "Epoch: 002/010 | Batch 43901/45709 | Average Loss in last 25 iteration(s): 0.1175 | Elapsed 12:52:21\n",
      "Epoch: 002/010 | Batch 43926/45709 | Average Loss in last 25 iteration(s): 0.0658 | Elapsed 12:52:46\n",
      "Epoch: 002/010 | Batch 43951/45709 | Average Loss in last 25 iteration(s): 0.0682 | Elapsed 12:53:11\n",
      "Epoch: 002/010 | Batch 43976/45709 | Average Loss in last 25 iteration(s): 0.1209 | Elapsed 12:53:33\n",
      "Epoch: 002/010 | Batch 44001/45709 | Average Loss in last 25 iteration(s): 0.0725 | Elapsed 12:54:02\n",
      "Epoch: 002/010 | Batch 44026/45709 | Average Loss in last 25 iteration(s): 0.1247 | Elapsed 12:54:31\n",
      "Epoch: 002/010 | Batch 44051/45709 | Average Loss in last 25 iteration(s): 0.0836 | Elapsed 12:54:57\n",
      "Epoch: 002/010 | Batch 44076/45709 | Average Loss in last 25 iteration(s): 0.1018 | Elapsed 12:55:24\n",
      "Epoch: 002/010 | Batch 44101/45709 | Average Loss in last 25 iteration(s): 0.0654 | Elapsed 12:55:49\n",
      "Epoch: 002/010 | Batch 44126/45709 | Average Loss in last 25 iteration(s): 0.0523 | Elapsed 12:56:13\n",
      "Epoch: 002/010 | Batch 44151/45709 | Average Loss in last 25 iteration(s): 0.0738 | Elapsed 12:56:40\n",
      "Epoch: 002/010 | Batch 44176/45709 | Average Loss in last 25 iteration(s): 0.0835 | Elapsed 12:57:09\n",
      "Epoch: 002/010 | Batch 44201/45709 | Average Loss in last 25 iteration(s): 0.1030 | Elapsed 12:57:35\n",
      "Epoch: 002/010 | Batch 44226/45709 | Average Loss in last 25 iteration(s): 0.0674 | Elapsed 12:58:02\n",
      "Epoch: 002/010 | Batch 44251/45709 | Average Loss in last 25 iteration(s): 0.0712 | Elapsed 12:58:27\n",
      "Epoch: 002/010 | Batch 44276/45709 | Average Loss in last 25 iteration(s): 0.0931 | Elapsed 12:58:52\n",
      "Epoch: 002/010 | Batch 44301/45709 | Average Loss in last 25 iteration(s): 0.0777 | Elapsed 12:59:15\n",
      "Epoch: 002/010 | Batch 44326/45709 | Average Loss in last 25 iteration(s): 0.0809 | Elapsed 12:59:45\n",
      "Epoch: 002/010 | Batch 44351/45709 | Average Loss in last 25 iteration(s): 0.0916 | Elapsed 13:00:13\n",
      "Epoch: 002/010 | Batch 44376/45709 | Average Loss in last 25 iteration(s): 0.0971 | Elapsed 13:00:39\n",
      "Epoch: 002/010 | Batch 44401/45709 | Average Loss in last 25 iteration(s): 0.0851 | Elapsed 13:01:07\n",
      "Epoch: 002/010 | Batch 44426/45709 | Average Loss in last 25 iteration(s): 0.1198 | Elapsed 13:01:32\n",
      "Epoch: 002/010 | Batch 44451/45709 | Average Loss in last 25 iteration(s): 0.0707 | Elapsed 13:01:55\n",
      "Epoch: 002/010 | Batch 44476/45709 | Average Loss in last 25 iteration(s): 0.0722 | Elapsed 13:02:23\n",
      "Epoch: 002/010 | Batch 44501/45709 | Average Loss in last 25 iteration(s): 0.0721 | Elapsed 13:02:51\n",
      "Epoch: 002/010 | Batch 44526/45709 | Average Loss in last 25 iteration(s): 0.0917 | Elapsed 13:03:16\n",
      "Epoch: 002/010 | Batch 44551/45709 | Average Loss in last 25 iteration(s): 0.1084 | Elapsed 13:03:43\n",
      "Epoch: 002/010 | Batch 44576/45709 | Average Loss in last 25 iteration(s): 0.0904 | Elapsed 13:04:10\n",
      "Epoch: 002/010 | Batch 44601/45709 | Average Loss in last 25 iteration(s): 0.0638 | Elapsed 13:04:32\n",
      "Epoch: 002/010 | Batch 44626/45709 | Average Loss in last 25 iteration(s): 0.0762 | Elapsed 13:04:59\n",
      "Epoch: 002/010 | Batch 44651/45709 | Average Loss in last 25 iteration(s): 0.0806 | Elapsed 13:05:27\n",
      "Epoch: 002/010 | Batch 44676/45709 | Average Loss in last 25 iteration(s): 0.0969 | Elapsed 13:05:54\n",
      "Epoch: 002/010 | Batch 44701/45709 | Average Loss in last 25 iteration(s): 0.0814 | Elapsed 13:06:21\n",
      "Epoch: 002/010 | Batch 44726/45709 | Average Loss in last 25 iteration(s): 0.0856 | Elapsed 13:06:48\n",
      "Epoch: 002/010 | Batch 44751/45709 | Average Loss in last 25 iteration(s): 0.0983 | Elapsed 13:07:12\n",
      "Epoch: 002/010 | Batch 44776/45709 | Average Loss in last 25 iteration(s): 0.0779 | Elapsed 13:07:36\n",
      "Epoch: 002/010 | Batch 44801/45709 | Average Loss in last 25 iteration(s): 0.0969 | Elapsed 13:08:06\n",
      "Epoch: 002/010 | Batch 44826/45709 | Average Loss in last 25 iteration(s): 0.1174 | Elapsed 13:08:33\n",
      "Epoch: 002/010 | Batch 44851/45709 | Average Loss in last 25 iteration(s): 0.0801 | Elapsed 13:08:59\n",
      "Epoch: 002/010 | Batch 44876/45709 | Average Loss in last 25 iteration(s): 0.0867 | Elapsed 13:09:26\n",
      "Epoch: 002/010 | Batch 44901/45709 | Average Loss in last 25 iteration(s): 0.0915 | Elapsed 13:09:51\n",
      "Epoch: 002/010 | Batch 44926/45709 | Average Loss in last 25 iteration(s): 0.0601 | Elapsed 13:10:15\n",
      "Epoch: 002/010 | Batch 44951/45709 | Average Loss in last 25 iteration(s): 0.1065 | Elapsed 13:10:41\n",
      "Epoch: 002/010 | Batch 44976/45709 | Average Loss in last 25 iteration(s): 0.1041 | Elapsed 13:11:10\n",
      "Epoch: 002/010 | Batch 45001/45709 | Average Loss in last 25 iteration(s): 0.0913 | Elapsed 13:11:37\n",
      "Epoch: 002/010 | Batch 45026/45709 | Average Loss in last 25 iteration(s): 0.0987 | Elapsed 13:12:05\n",
      "Epoch: 002/010 | Batch 45051/45709 | Average Loss in last 25 iteration(s): 0.1011 | Elapsed 13:12:31\n",
      "Epoch: 002/010 | Batch 45076/45709 | Average Loss in last 25 iteration(s): 0.0741 | Elapsed 13:12:54\n",
      "Epoch: 002/010 | Batch 45101/45709 | Average Loss in last 25 iteration(s): 0.0832 | Elapsed 13:13:20\n",
      "Epoch: 002/010 | Batch 45126/45709 | Average Loss in last 25 iteration(s): 0.0815 | Elapsed 13:13:47\n",
      "Epoch: 002/010 | Batch 45151/45709 | Average Loss in last 25 iteration(s): 0.1226 | Elapsed 13:14:14\n",
      "Epoch: 002/010 | Batch 45176/45709 | Average Loss in last 25 iteration(s): 0.0706 | Elapsed 13:14:41\n",
      "Epoch: 002/010 | Batch 45201/45709 | Average Loss in last 25 iteration(s): 0.0882 | Elapsed 13:15:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/010 | Batch 45226/45709 | Average Loss in last 25 iteration(s): 0.0908 | Elapsed 13:15:32\n",
      "Epoch: 002/010 | Batch 45251/45709 | Average Loss in last 25 iteration(s): 0.1026 | Elapsed 13:15:56\n",
      "Epoch: 002/010 | Batch 45276/45709 | Average Loss in last 25 iteration(s): 0.0881 | Elapsed 13:16:22\n",
      "Epoch: 002/010 | Batch 45301/45709 | Average Loss in last 25 iteration(s): 0.0696 | Elapsed 13:16:49\n",
      "Epoch: 002/010 | Batch 45326/45709 | Average Loss in last 25 iteration(s): 0.0888 | Elapsed 13:17:14\n",
      "Epoch: 002/010 | Batch 45351/45709 | Average Loss in last 25 iteration(s): 0.0785 | Elapsed 13:17:43\n",
      "Epoch: 002/010 | Batch 45376/45709 | Average Loss in last 25 iteration(s): 0.0845 | Elapsed 13:18:08\n",
      "Epoch: 002/010 | Batch 45401/45709 | Average Loss in last 25 iteration(s): 0.0857 | Elapsed 13:18:32\n",
      "Epoch: 002/010 | Batch 45426/45709 | Average Loss in last 25 iteration(s): 0.0636 | Elapsed 13:18:57\n",
      "Epoch: 002/010 | Batch 45451/45709 | Average Loss in last 25 iteration(s): 0.0837 | Elapsed 13:19:26\n",
      "Epoch: 002/010 | Batch 45476/45709 | Average Loss in last 25 iteration(s): 0.0854 | Elapsed 13:19:53\n",
      "Epoch: 002/010 | Batch 45501/45709 | Average Loss in last 25 iteration(s): 0.0987 | Elapsed 13:20:20\n",
      "Epoch: 002/010 | Batch 45526/45709 | Average Loss in last 25 iteration(s): 0.0796 | Elapsed 13:20:47\n",
      "Epoch: 002/010 | Batch 45551/45709 | Average Loss in last 25 iteration(s): 0.1010 | Elapsed 13:21:12\n",
      "Epoch: 002/010 | Batch 45576/45709 | Average Loss in last 25 iteration(s): 0.1053 | Elapsed 13:21:39\n",
      "Epoch: 002/010 | Batch 45601/45709 | Average Loss in last 25 iteration(s): 0.1003 | Elapsed 13:22:06\n",
      "Epoch: 002/010 | Batch 45626/45709 | Average Loss in last 25 iteration(s): 0.0989 | Elapsed 13:22:33\n",
      "Epoch: 002/010 | Batch 45651/45709 | Average Loss in last 25 iteration(s): 0.0354 | Elapsed 13:22:59\n",
      "Epoch: 002/010 | Batch 45676/45709 | Average Loss in last 25 iteration(s): 0.1210 | Elapsed 13:23:27\n",
      "Epoch: 002/010 | Batch 45701/45709 | Average Loss in last 25 iteration(s): 0.0754 | Elapsed 13:23:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 45709/45709 [2:06:27<00:00,  6.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 97.19%\n",
      "Calculating validation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 2/5079 [00:00<07:41, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss = 0.08135525368020856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5079/5079 [14:03<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation accuracy = 96.27861022949219\n",
      "\n",
      "===== Epoch 3 / 10 =====\n",
      "Training ...\n",
      "Epoch: 003/010 | Batch 001/45709 | Average Loss in last 1 iteration(s): 0.2035 | Elapsed 0:00:01\n",
      "Epoch: 003/010 | Batch 026/45709 | Average Loss in last 25 iteration(s): 0.0720 | Elapsed 0:00:27\n",
      "Epoch: 003/010 | Batch 051/45709 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 0:00:55\n",
      "Epoch: 003/010 | Batch 076/45709 | Average Loss in last 25 iteration(s): 0.0570 | Elapsed 0:01:21\n",
      "Epoch: 003/010 | Batch 101/45709 | Average Loss in last 25 iteration(s): 0.0836 | Elapsed 0:01:45\n",
      "Epoch: 003/010 | Batch 126/45709 | Average Loss in last 25 iteration(s): 0.0631 | Elapsed 0:02:15\n",
      "Epoch: 003/010 | Batch 151/45709 | Average Loss in last 25 iteration(s): 0.0622 | Elapsed 0:02:41\n",
      "Epoch: 003/010 | Batch 176/45709 | Average Loss in last 25 iteration(s): 0.0799 | Elapsed 0:03:08\n",
      "Epoch: 003/010 | Batch 201/45709 | Average Loss in last 25 iteration(s): 0.0712 | Elapsed 0:03:35\n",
      "Epoch: 003/010 | Batch 226/45709 | Average Loss in last 25 iteration(s): 0.0622 | Elapsed 0:04:01\n",
      "Epoch: 003/010 | Batch 251/45709 | Average Loss in last 25 iteration(s): 0.0649 | Elapsed 0:04:24\n",
      "Epoch: 003/010 | Batch 276/45709 | Average Loss in last 25 iteration(s): 0.0546 | Elapsed 0:04:54\n",
      "Epoch: 003/010 | Batch 301/45709 | Average Loss in last 25 iteration(s): 0.0657 | Elapsed 0:05:23\n",
      "Epoch: 003/010 | Batch 326/45709 | Average Loss in last 25 iteration(s): 0.0660 | Elapsed 0:05:50\n",
      "Epoch: 003/010 | Batch 351/45709 | Average Loss in last 25 iteration(s): 0.0743 | Elapsed 0:06:19\n",
      "Epoch: 003/010 | Batch 376/45709 | Average Loss in last 25 iteration(s): 0.0855 | Elapsed 0:06:45\n",
      "Epoch: 003/010 | Batch 401/45709 | Average Loss in last 25 iteration(s): 0.0839 | Elapsed 0:07:09\n",
      "Epoch: 003/010 | Batch 426/45709 | Average Loss in last 25 iteration(s): 0.0519 | Elapsed 0:07:38\n",
      "Epoch: 003/010 | Batch 451/45709 | Average Loss in last 25 iteration(s): 0.0890 | Elapsed 0:08:06\n",
      "Epoch: 003/010 | Batch 476/45709 | Average Loss in last 25 iteration(s): 0.0856 | Elapsed 0:08:32\n",
      "Epoch: 003/010 | Batch 501/45709 | Average Loss in last 25 iteration(s): 0.0614 | Elapsed 0:08:59\n",
      "Epoch: 003/010 | Batch 526/45709 | Average Loss in last 25 iteration(s): 0.0715 | Elapsed 0:09:27\n",
      "Epoch: 003/010 | Batch 551/45709 | Average Loss in last 25 iteration(s): 0.0755 | Elapsed 0:09:51\n",
      "Epoch: 003/010 | Batch 576/45709 | Average Loss in last 25 iteration(s): 0.0727 | Elapsed 0:10:18\n",
      "Epoch: 003/010 | Batch 601/45709 | Average Loss in last 25 iteration(s): 0.1095 | Elapsed 0:10:46\n",
      "Epoch: 003/010 | Batch 626/45709 | Average Loss in last 25 iteration(s): 0.1054 | Elapsed 0:11:13\n",
      "Epoch: 003/010 | Batch 651/45709 | Average Loss in last 25 iteration(s): 0.0530 | Elapsed 0:11:42\n",
      "Epoch: 003/010 | Batch 676/45709 | Average Loss in last 25 iteration(s): 0.0534 | Elapsed 0:12:07\n",
      "Epoch: 003/010 | Batch 701/45709 | Average Loss in last 25 iteration(s): 0.0648 | Elapsed 0:12:31\n",
      "Epoch: 003/010 | Batch 726/45709 | Average Loss in last 25 iteration(s): 0.0893 | Elapsed 0:13:00\n",
      "Epoch: 003/010 | Batch 751/45709 | Average Loss in last 25 iteration(s): 0.0603 | Elapsed 0:13:27\n",
      "Epoch: 003/010 | Batch 776/45709 | Average Loss in last 25 iteration(s): 0.0846 | Elapsed 0:13:55\n",
      "Epoch: 003/010 | Batch 801/45709 | Average Loss in last 25 iteration(s): 0.0901 | Elapsed 0:14:23\n",
      "Epoch: 003/010 | Batch 826/45709 | Average Loss in last 25 iteration(s): 0.0724 | Elapsed 0:14:50\n",
      "Epoch: 003/010 | Batch 851/45709 | Average Loss in last 25 iteration(s): 0.0657 | Elapsed 0:15:13\n",
      "Epoch: 003/010 | Batch 876/45709 | Average Loss in last 25 iteration(s): 0.0545 | Elapsed 0:15:46\n",
      "Epoch: 003/010 | Batch 901/45709 | Average Loss in last 25 iteration(s): 0.0826 | Elapsed 0:16:13\n",
      "Epoch: 003/010 | Batch 926/45709 | Average Loss in last 25 iteration(s): 0.0843 | Elapsed 0:16:35\n",
      "Epoch: 003/010 | Batch 951/45709 | Average Loss in last 25 iteration(s): 0.0633 | Elapsed 0:16:59\n",
      "Epoch: 003/010 | Batch 976/45709 | Average Loss in last 25 iteration(s): 0.0854 | Elapsed 0:17:27\n",
      "Epoch: 003/010 | Batch 1001/45709 | Average Loss in last 25 iteration(s): 0.0612 | Elapsed 0:17:54\n",
      "Epoch: 003/010 | Batch 1026/45709 | Average Loss in last 25 iteration(s): 0.0705 | Elapsed 0:18:19\n",
      "Epoch: 003/010 | Batch 1051/45709 | Average Loss in last 25 iteration(s): 0.0569 | Elapsed 0:18:52\n",
      "Epoch: 003/010 | Batch 1076/45709 | Average Loss in last 25 iteration(s): 0.0979 | Elapsed 0:19:20\n",
      "Epoch: 003/010 | Batch 1101/45709 | Average Loss in last 25 iteration(s): 0.0823 | Elapsed 0:19:41\n",
      "Epoch: 003/010 | Batch 1126/45709 | Average Loss in last 25 iteration(s): 0.0629 | Elapsed 0:20:04\n",
      "Epoch: 003/010 | Batch 1151/45709 | Average Loss in last 25 iteration(s): 0.0823 | Elapsed 0:20:35\n",
      "Epoch: 003/010 | Batch 1176/45709 | Average Loss in last 25 iteration(s): 0.0597 | Elapsed 0:20:59\n",
      "Epoch: 003/010 | Batch 1201/45709 | Average Loss in last 25 iteration(s): 0.0920 | Elapsed 0:21:31\n",
      "Epoch: 003/010 | Batch 1226/45709 | Average Loss in last 25 iteration(s): 0.0645 | Elapsed 0:22:00\n",
      "Epoch: 003/010 | Batch 1251/45709 | Average Loss in last 25 iteration(s): 0.0777 | Elapsed 0:22:24\n",
      "Epoch: 003/010 | Batch 1276/45709 | Average Loss in last 25 iteration(s): 0.0666 | Elapsed 0:22:51\n",
      "Epoch: 003/010 | Batch 1301/45709 | Average Loss in last 25 iteration(s): 0.0631 | Elapsed 0:23:20\n",
      "Epoch: 003/010 | Batch 1326/45709 | Average Loss in last 25 iteration(s): 0.1055 | Elapsed 0:23:45\n",
      "Epoch: 003/010 | Batch 1351/45709 | Average Loss in last 25 iteration(s): 0.0643 | Elapsed 0:24:12\n",
      "Epoch: 003/010 | Batch 1376/45709 | Average Loss in last 25 iteration(s): 0.0767 | Elapsed 0:24:40\n",
      "Epoch: 003/010 | Batch 1401/45709 | Average Loss in last 25 iteration(s): 0.0803 | Elapsed 0:25:11\n",
      "Epoch: 003/010 | Batch 1426/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 0:25:38\n",
      "Epoch: 003/010 | Batch 1451/45709 | Average Loss in last 25 iteration(s): 0.1004 | Elapsed 0:26:02\n",
      "Epoch: 003/010 | Batch 1476/45709 | Average Loss in last 25 iteration(s): 0.0838 | Elapsed 0:26:33\n",
      "Epoch: 003/010 | Batch 1501/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 0:27:02\n",
      "Epoch: 003/010 | Batch 1526/45709 | Average Loss in last 25 iteration(s): 0.0633 | Elapsed 0:27:25\n",
      "Epoch: 003/010 | Batch 1551/45709 | Average Loss in last 25 iteration(s): 0.0899 | Elapsed 0:27:55\n",
      "Epoch: 003/010 | Batch 1576/45709 | Average Loss in last 25 iteration(s): 0.0784 | Elapsed 0:28:22\n",
      "Epoch: 003/010 | Batch 1601/45709 | Average Loss in last 25 iteration(s): 0.0822 | Elapsed 0:28:45\n",
      "Epoch: 003/010 | Batch 1626/45709 | Average Loss in last 25 iteration(s): 0.0789 | Elapsed 0:29:12\n",
      "Epoch: 003/010 | Batch 1651/45709 | Average Loss in last 25 iteration(s): 0.0956 | Elapsed 0:29:40\n",
      "Epoch: 003/010 | Batch 1676/45709 | Average Loss in last 25 iteration(s): 0.0963 | Elapsed 0:30:09\n",
      "Epoch: 003/010 | Batch 1701/45709 | Average Loss in last 25 iteration(s): 0.0679 | Elapsed 0:30:36\n",
      "Epoch: 003/010 | Batch 1726/45709 | Average Loss in last 25 iteration(s): 0.0679 | Elapsed 0:31:01\n",
      "Epoch: 003/010 | Batch 1751/45709 | Average Loss in last 25 iteration(s): 0.0710 | Elapsed 0:31:25\n",
      "Epoch: 003/010 | Batch 1776/45709 | Average Loss in last 25 iteration(s): 0.0572 | Elapsed 0:31:53\n",
      "Epoch: 003/010 | Batch 1801/45709 | Average Loss in last 25 iteration(s): 0.0565 | Elapsed 0:32:24\n",
      "Epoch: 003/010 | Batch 1826/45709 | Average Loss in last 25 iteration(s): 0.0761 | Elapsed 0:32:50\n",
      "Epoch: 003/010 | Batch 1851/45709 | Average Loss in last 25 iteration(s): 0.0458 | Elapsed 0:33:18\n",
      "Epoch: 003/010 | Batch 1876/45709 | Average Loss in last 25 iteration(s): 0.1124 | Elapsed 0:33:44\n",
      "Epoch: 003/010 | Batch 1901/45709 | Average Loss in last 25 iteration(s): 0.0538 | Elapsed 0:34:07\n",
      "Epoch: 003/010 | Batch 1926/45709 | Average Loss in last 25 iteration(s): 0.0831 | Elapsed 0:34:35\n",
      "Epoch: 003/010 | Batch 1951/45709 | Average Loss in last 25 iteration(s): 0.0708 | Elapsed 0:35:04\n",
      "Epoch: 003/010 | Batch 1976/45709 | Average Loss in last 25 iteration(s): 0.0733 | Elapsed 0:35:32\n",
      "Epoch: 003/010 | Batch 2001/45709 | Average Loss in last 25 iteration(s): 0.0735 | Elapsed 0:35:55\n",
      "Epoch: 003/010 | Batch 2026/45709 | Average Loss in last 25 iteration(s): 0.0694 | Elapsed 0:36:21\n",
      "Epoch: 003/010 | Batch 2051/45709 | Average Loss in last 25 iteration(s): 0.0772 | Elapsed 0:36:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 2076/45709 | Average Loss in last 25 iteration(s): 0.0721 | Elapsed 0:37:13\n",
      "Epoch: 003/010 | Batch 2101/45709 | Average Loss in last 25 iteration(s): 0.0734 | Elapsed 0:37:42\n",
      "Epoch: 003/010 | Batch 2126/45709 | Average Loss in last 25 iteration(s): 0.1120 | Elapsed 0:38:08\n",
      "Epoch: 003/010 | Batch 2151/45709 | Average Loss in last 25 iteration(s): 0.0574 | Elapsed 0:38:36\n",
      "Epoch: 003/010 | Batch 2176/45709 | Average Loss in last 25 iteration(s): 0.0711 | Elapsed 0:39:00\n",
      "Epoch: 003/010 | Batch 2201/45709 | Average Loss in last 25 iteration(s): 0.0536 | Elapsed 0:39:28\n",
      "Epoch: 003/010 | Batch 2226/45709 | Average Loss in last 25 iteration(s): 0.0445 | Elapsed 0:39:52\n",
      "Epoch: 003/010 | Batch 2251/45709 | Average Loss in last 25 iteration(s): 0.0474 | Elapsed 0:40:20\n",
      "Epoch: 003/010 | Batch 2276/45709 | Average Loss in last 25 iteration(s): 0.0574 | Elapsed 0:40:46\n",
      "Epoch: 003/010 | Batch 2301/45709 | Average Loss in last 25 iteration(s): 0.0784 | Elapsed 0:41:14\n",
      "Epoch: 003/010 | Batch 2326/45709 | Average Loss in last 25 iteration(s): 0.0667 | Elapsed 0:41:40\n",
      "Epoch: 003/010 | Batch 2351/45709 | Average Loss in last 25 iteration(s): 0.0470 | Elapsed 0:42:03\n",
      "Epoch: 003/010 | Batch 2376/45709 | Average Loss in last 25 iteration(s): 0.0804 | Elapsed 0:42:30\n",
      "Epoch: 003/010 | Batch 2401/45709 | Average Loss in last 25 iteration(s): 0.0842 | Elapsed 0:42:54\n",
      "Epoch: 003/010 | Batch 2426/45709 | Average Loss in last 25 iteration(s): 0.0839 | Elapsed 0:43:22\n",
      "Epoch: 003/010 | Batch 2451/45709 | Average Loss in last 25 iteration(s): 0.0701 | Elapsed 0:43:50\n",
      "Epoch: 003/010 | Batch 2476/45709 | Average Loss in last 25 iteration(s): 0.0907 | Elapsed 0:44:18\n",
      "Epoch: 003/010 | Batch 2501/45709 | Average Loss in last 25 iteration(s): 0.0799 | Elapsed 0:44:44\n",
      "Epoch: 003/010 | Batch 2526/45709 | Average Loss in last 25 iteration(s): 0.0479 | Elapsed 0:45:08\n",
      "Epoch: 003/010 | Batch 2551/45709 | Average Loss in last 25 iteration(s): 0.0822 | Elapsed 0:45:37\n",
      "Epoch: 003/010 | Batch 2576/45709 | Average Loss in last 25 iteration(s): 0.0447 | Elapsed 0:46:01\n",
      "Epoch: 003/010 | Batch 2601/45709 | Average Loss in last 25 iteration(s): 0.0809 | Elapsed 0:46:28\n",
      "Epoch: 003/010 | Batch 2626/45709 | Average Loss in last 25 iteration(s): 0.0524 | Elapsed 0:46:58\n",
      "Epoch: 003/010 | Batch 2651/45709 | Average Loss in last 25 iteration(s): 0.0489 | Elapsed 0:47:25\n",
      "Epoch: 003/010 | Batch 2676/45709 | Average Loss in last 25 iteration(s): 0.0785 | Elapsed 0:47:47\n",
      "Epoch: 003/010 | Batch 2701/45709 | Average Loss in last 25 iteration(s): 0.0759 | Elapsed 0:48:15\n",
      "Epoch: 003/010 | Batch 2726/45709 | Average Loss in last 25 iteration(s): 0.0703 | Elapsed 0:48:39\n",
      "Epoch: 003/010 | Batch 2751/45709 | Average Loss in last 25 iteration(s): 0.0682 | Elapsed 0:49:13\n",
      "Epoch: 003/010 | Batch 2776/45709 | Average Loss in last 25 iteration(s): 0.0842 | Elapsed 0:49:43\n",
      "Epoch: 003/010 | Batch 2801/45709 | Average Loss in last 25 iteration(s): 0.0939 | Elapsed 0:50:12\n",
      "Epoch: 003/010 | Batch 2826/45709 | Average Loss in last 25 iteration(s): 0.0871 | Elapsed 0:50:35\n",
      "Epoch: 003/010 | Batch 2851/45709 | Average Loss in last 25 iteration(s): 0.0489 | Elapsed 0:51:02\n",
      "Epoch: 003/010 | Batch 2876/45709 | Average Loss in last 25 iteration(s): 0.0985 | Elapsed 0:51:30\n",
      "Epoch: 003/010 | Batch 2901/45709 | Average Loss in last 25 iteration(s): 0.0569 | Elapsed 0:52:02\n",
      "Epoch: 003/010 | Batch 2926/45709 | Average Loss in last 25 iteration(s): 0.0789 | Elapsed 0:52:29\n",
      "Epoch: 003/010 | Batch 2951/45709 | Average Loss in last 25 iteration(s): 0.0619 | Elapsed 0:52:50\n",
      "Epoch: 003/010 | Batch 2976/45709 | Average Loss in last 25 iteration(s): 0.0680 | Elapsed 0:53:12\n",
      "Epoch: 003/010 | Batch 3001/45709 | Average Loss in last 25 iteration(s): 0.0663 | Elapsed 0:53:39\n",
      "Epoch: 003/010 | Batch 3026/45709 | Average Loss in last 25 iteration(s): 0.0669 | Elapsed 0:54:05\n",
      "Epoch: 003/010 | Batch 3051/45709 | Average Loss in last 25 iteration(s): 0.0636 | Elapsed 0:54:30\n",
      "Epoch: 003/010 | Batch 3076/45709 | Average Loss in last 25 iteration(s): 0.0686 | Elapsed 0:55:00\n",
      "Epoch: 003/010 | Batch 3101/45709 | Average Loss in last 25 iteration(s): 0.0502 | Elapsed 0:55:29\n",
      "Epoch: 003/010 | Batch 3126/45709 | Average Loss in last 25 iteration(s): 0.0640 | Elapsed 0:55:52\n",
      "Epoch: 003/010 | Batch 3151/45709 | Average Loss in last 25 iteration(s): 0.0654 | Elapsed 0:56:13\n",
      "Epoch: 003/010 | Batch 3176/45709 | Average Loss in last 25 iteration(s): 0.0744 | Elapsed 0:56:37\n",
      "Epoch: 003/010 | Batch 3201/45709 | Average Loss in last 25 iteration(s): 0.0700 | Elapsed 0:57:04\n",
      "Epoch: 003/010 | Batch 3226/45709 | Average Loss in last 25 iteration(s): 0.0715 | Elapsed 0:57:32\n",
      "Epoch: 003/010 | Batch 3251/45709 | Average Loss in last 25 iteration(s): 0.0834 | Elapsed 0:58:00\n",
      "Epoch: 003/010 | Batch 3276/45709 | Average Loss in last 25 iteration(s): 0.0922 | Elapsed 0:58:31\n",
      "Epoch: 003/010 | Batch 3301/45709 | Average Loss in last 25 iteration(s): 0.0478 | Elapsed 0:58:57\n",
      "Epoch: 003/010 | Batch 3326/45709 | Average Loss in last 25 iteration(s): 0.0857 | Elapsed 0:59:18\n",
      "Epoch: 003/010 | Batch 3351/45709 | Average Loss in last 25 iteration(s): 0.0532 | Elapsed 0:59:42\n",
      "Epoch: 003/010 | Batch 3376/45709 | Average Loss in last 25 iteration(s): 0.0698 | Elapsed 1:00:09\n",
      "Epoch: 003/010 | Batch 3401/45709 | Average Loss in last 25 iteration(s): 0.0688 | Elapsed 1:00:35\n",
      "Epoch: 003/010 | Batch 3426/45709 | Average Loss in last 25 iteration(s): 0.0453 | Elapsed 1:01:01\n",
      "Epoch: 003/010 | Batch 3451/45709 | Average Loss in last 25 iteration(s): 0.0843 | Elapsed 1:01:34\n",
      "Epoch: 003/010 | Batch 3476/45709 | Average Loss in last 25 iteration(s): 0.0854 | Elapsed 1:02:02\n",
      "Epoch: 003/010 | Batch 3501/45709 | Average Loss in last 25 iteration(s): 0.0683 | Elapsed 1:02:23\n",
      "Epoch: 003/010 | Batch 3526/45709 | Average Loss in last 25 iteration(s): 0.0752 | Elapsed 1:02:50\n",
      "Epoch: 003/010 | Batch 3551/45709 | Average Loss in last 25 iteration(s): 0.0993 | Elapsed 1:03:17\n",
      "Epoch: 003/010 | Batch 3576/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 1:03:40\n",
      "Epoch: 003/010 | Batch 3601/45709 | Average Loss in last 25 iteration(s): 0.0982 | Elapsed 1:04:10\n",
      "Epoch: 003/010 | Batch 3626/45709 | Average Loss in last 25 iteration(s): 0.0592 | Elapsed 1:04:39\n",
      "Epoch: 003/010 | Batch 3651/45709 | Average Loss in last 25 iteration(s): 0.1067 | Elapsed 1:05:01\n",
      "Epoch: 003/010 | Batch 3676/45709 | Average Loss in last 25 iteration(s): 0.0610 | Elapsed 1:05:29\n",
      "Epoch: 003/010 | Batch 3701/45709 | Average Loss in last 25 iteration(s): 0.0735 | Elapsed 1:05:56\n",
      "Epoch: 003/010 | Batch 3726/45709 | Average Loss in last 25 iteration(s): 0.0652 | Elapsed 1:06:19\n",
      "Epoch: 003/010 | Batch 3751/45709 | Average Loss in last 25 iteration(s): 0.0557 | Elapsed 1:06:46\n",
      "Epoch: 003/010 | Batch 3776/45709 | Average Loss in last 25 iteration(s): 0.0518 | Elapsed 1:07:18\n",
      "Epoch: 003/010 | Batch 3801/45709 | Average Loss in last 25 iteration(s): 0.1005 | Elapsed 1:07:42\n",
      "Epoch: 003/010 | Batch 3826/45709 | Average Loss in last 25 iteration(s): 0.0800 | Elapsed 1:08:04\n",
      "Epoch: 003/010 | Batch 3851/45709 | Average Loss in last 25 iteration(s): 0.0620 | Elapsed 1:08:36\n",
      "Epoch: 003/010 | Batch 3876/45709 | Average Loss in last 25 iteration(s): 0.0816 | Elapsed 1:09:00\n",
      "Epoch: 003/010 | Batch 3901/45709 | Average Loss in last 25 iteration(s): 0.0625 | Elapsed 1:09:26\n",
      "Epoch: 003/010 | Batch 3926/45709 | Average Loss in last 25 iteration(s): 0.0662 | Elapsed 1:10:01\n",
      "Epoch: 003/010 | Batch 3951/45709 | Average Loss in last 25 iteration(s): 0.0552 | Elapsed 1:10:26\n",
      "Epoch: 003/010 | Batch 3976/45709 | Average Loss in last 25 iteration(s): 0.0963 | Elapsed 1:10:47\n",
      "Epoch: 003/010 | Batch 4001/45709 | Average Loss in last 25 iteration(s): 0.0642 | Elapsed 1:11:08\n",
      "Epoch: 003/010 | Batch 4026/45709 | Average Loss in last 25 iteration(s): 0.0604 | Elapsed 1:11:34\n",
      "Epoch: 003/010 | Batch 4051/45709 | Average Loss in last 25 iteration(s): 0.0827 | Elapsed 1:12:03\n",
      "Epoch: 003/010 | Batch 4076/45709 | Average Loss in last 25 iteration(s): 0.0578 | Elapsed 1:12:26\n",
      "Epoch: 003/010 | Batch 4101/45709 | Average Loss in last 25 iteration(s): 0.0770 | Elapsed 1:12:52\n",
      "Epoch: 003/010 | Batch 4126/45709 | Average Loss in last 25 iteration(s): 0.0657 | Elapsed 1:13:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 4151/45709 | Average Loss in last 25 iteration(s): 0.0929 | Elapsed 1:13:50\n",
      "Epoch: 003/010 | Batch 4176/45709 | Average Loss in last 25 iteration(s): 0.0549 | Elapsed 1:14:17\n",
      "Epoch: 003/010 | Batch 4201/45709 | Average Loss in last 25 iteration(s): 0.0364 | Elapsed 1:14:45\n",
      "Epoch: 003/010 | Batch 4226/45709 | Average Loss in last 25 iteration(s): 0.0728 | Elapsed 1:15:10\n",
      "Epoch: 003/010 | Batch 4251/45709 | Average Loss in last 25 iteration(s): 0.0539 | Elapsed 1:15:37\n",
      "Epoch: 003/010 | Batch 4276/45709 | Average Loss in last 25 iteration(s): 0.1237 | Elapsed 1:16:08\n",
      "Epoch: 003/010 | Batch 4301/45709 | Average Loss in last 25 iteration(s): 0.0764 | Elapsed 1:16:32\n",
      "Epoch: 003/010 | Batch 4326/45709 | Average Loss in last 25 iteration(s): 0.0575 | Elapsed 1:17:01\n",
      "Epoch: 003/010 | Batch 4351/45709 | Average Loss in last 25 iteration(s): 0.1050 | Elapsed 1:17:28\n",
      "Epoch: 003/010 | Batch 4376/45709 | Average Loss in last 25 iteration(s): 0.0545 | Elapsed 1:17:51\n",
      "Epoch: 003/010 | Batch 4401/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 1:18:21\n",
      "Epoch: 003/010 | Batch 4426/45709 | Average Loss in last 25 iteration(s): 0.0715 | Elapsed 1:18:51\n",
      "Epoch: 003/010 | Batch 4451/45709 | Average Loss in last 25 iteration(s): 0.0544 | Elapsed 1:19:21\n",
      "Epoch: 003/010 | Batch 4476/45709 | Average Loss in last 25 iteration(s): 0.0882 | Elapsed 1:19:47\n",
      "Epoch: 003/010 | Batch 4501/45709 | Average Loss in last 25 iteration(s): 0.0833 | Elapsed 1:20:13\n",
      "Epoch: 003/010 | Batch 4526/45709 | Average Loss in last 25 iteration(s): 0.0806 | Elapsed 1:20:39\n",
      "Epoch: 003/010 | Batch 4551/45709 | Average Loss in last 25 iteration(s): 0.0604 | Elapsed 1:21:09\n",
      "Epoch: 003/010 | Batch 4576/45709 | Average Loss in last 25 iteration(s): 0.0685 | Elapsed 1:21:31\n",
      "Epoch: 003/010 | Batch 4601/45709 | Average Loss in last 25 iteration(s): 0.0478 | Elapsed 1:21:59\n",
      "Epoch: 003/010 | Batch 4626/45709 | Average Loss in last 25 iteration(s): 0.0419 | Elapsed 1:22:26\n",
      "Epoch: 003/010 | Batch 4651/45709 | Average Loss in last 25 iteration(s): 0.0588 | Elapsed 1:22:53\n",
      "Epoch: 003/010 | Batch 4676/45709 | Average Loss in last 25 iteration(s): 0.0859 | Elapsed 1:23:15\n",
      "Epoch: 003/010 | Batch 4701/45709 | Average Loss in last 25 iteration(s): 0.1136 | Elapsed 1:23:43\n",
      "Epoch: 003/010 | Batch 4726/45709 | Average Loss in last 25 iteration(s): 0.0736 | Elapsed 1:24:10\n",
      "Epoch: 003/010 | Batch 4751/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 1:24:38\n",
      "Epoch: 003/010 | Batch 4776/45709 | Average Loss in last 25 iteration(s): 0.0803 | Elapsed 1:25:05\n",
      "Epoch: 003/010 | Batch 4801/45709 | Average Loss in last 25 iteration(s): 0.0579 | Elapsed 1:25:32\n",
      "Epoch: 003/010 | Batch 4826/45709 | Average Loss in last 25 iteration(s): 0.0849 | Elapsed 1:25:55\n",
      "Epoch: 003/010 | Batch 4851/45709 | Average Loss in last 25 iteration(s): 0.0472 | Elapsed 1:26:23\n",
      "Epoch: 003/010 | Batch 4876/45709 | Average Loss in last 25 iteration(s): 0.0806 | Elapsed 1:26:51\n",
      "Epoch: 003/010 | Batch 4901/45709 | Average Loss in last 25 iteration(s): 0.0648 | Elapsed 1:27:18\n",
      "Epoch: 003/010 | Batch 4926/45709 | Average Loss in last 25 iteration(s): 0.0666 | Elapsed 1:27:46\n",
      "Epoch: 003/010 | Batch 4951/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 1:28:13\n",
      "Epoch: 003/010 | Batch 4976/45709 | Average Loss in last 25 iteration(s): 0.0622 | Elapsed 1:28:38\n",
      "Epoch: 003/010 | Batch 5001/45709 | Average Loss in last 25 iteration(s): 0.0519 | Elapsed 1:29:04\n",
      "Epoch: 003/010 | Batch 5026/45709 | Average Loss in last 25 iteration(s): 0.0740 | Elapsed 1:29:34\n",
      "Epoch: 003/010 | Batch 5051/45709 | Average Loss in last 25 iteration(s): 0.0820 | Elapsed 1:30:00\n",
      "Epoch: 003/010 | Batch 5076/45709 | Average Loss in last 25 iteration(s): 0.0646 | Elapsed 1:30:28\n",
      "Epoch: 003/010 | Batch 5101/45709 | Average Loss in last 25 iteration(s): 0.1130 | Elapsed 1:30:56\n",
      "Epoch: 003/010 | Batch 5126/45709 | Average Loss in last 25 iteration(s): 0.0639 | Elapsed 1:31:22\n",
      "Epoch: 003/010 | Batch 5151/45709 | Average Loss in last 25 iteration(s): 0.0766 | Elapsed 1:31:53\n",
      "Epoch: 003/010 | Batch 5176/45709 | Average Loss in last 25 iteration(s): 0.0606 | Elapsed 1:32:22\n",
      "Epoch: 003/010 | Batch 5201/45709 | Average Loss in last 25 iteration(s): 0.0680 | Elapsed 1:32:51\n",
      "Epoch: 003/010 | Batch 5226/45709 | Average Loss in last 25 iteration(s): 0.1003 | Elapsed 1:33:17\n",
      "Epoch: 003/010 | Batch 5251/45709 | Average Loss in last 25 iteration(s): 0.0881 | Elapsed 1:33:44\n",
      "Epoch: 003/010 | Batch 5276/45709 | Average Loss in last 25 iteration(s): 0.0673 | Elapsed 1:34:13\n",
      "Epoch: 003/010 | Batch 5301/45709 | Average Loss in last 25 iteration(s): 0.0543 | Elapsed 1:34:44\n",
      "Epoch: 003/010 | Batch 5326/45709 | Average Loss in last 25 iteration(s): 0.1001 | Elapsed 1:35:10\n",
      "Epoch: 003/010 | Batch 5351/45709 | Average Loss in last 25 iteration(s): 0.0774 | Elapsed 1:35:34\n",
      "Epoch: 003/010 | Batch 5376/45709 | Average Loss in last 25 iteration(s): 0.0711 | Elapsed 1:36:00\n",
      "Epoch: 003/010 | Batch 5401/45709 | Average Loss in last 25 iteration(s): 0.0752 | Elapsed 1:36:26\n",
      "Epoch: 003/010 | Batch 5426/45709 | Average Loss in last 25 iteration(s): 0.0680 | Elapsed 1:36:56\n",
      "Epoch: 003/010 | Batch 5451/45709 | Average Loss in last 25 iteration(s): 0.0298 | Elapsed 1:37:26\n",
      "Epoch: 003/010 | Batch 5476/45709 | Average Loss in last 25 iteration(s): 0.0681 | Elapsed 1:37:53\n",
      "Epoch: 003/010 | Batch 5501/45709 | Average Loss in last 25 iteration(s): 0.0542 | Elapsed 1:38:22\n",
      "Epoch: 003/010 | Batch 5526/45709 | Average Loss in last 25 iteration(s): 0.0404 | Elapsed 1:38:45\n",
      "Epoch: 003/010 | Batch 5551/45709 | Average Loss in last 25 iteration(s): 0.1014 | Elapsed 1:39:10\n",
      "Epoch: 003/010 | Batch 5576/45709 | Average Loss in last 25 iteration(s): 0.0639 | Elapsed 1:39:37\n",
      "Epoch: 003/010 | Batch 5601/45709 | Average Loss in last 25 iteration(s): 0.0673 | Elapsed 1:40:06\n",
      "Epoch: 003/010 | Batch 5626/45709 | Average Loss in last 25 iteration(s): 0.0629 | Elapsed 1:40:33\n",
      "Epoch: 003/010 | Batch 5651/45709 | Average Loss in last 25 iteration(s): 0.0838 | Elapsed 1:41:00\n",
      "Epoch: 003/010 | Batch 5676/45709 | Average Loss in last 25 iteration(s): 0.0722 | Elapsed 1:41:26\n",
      "Epoch: 003/010 | Batch 5701/45709 | Average Loss in last 25 iteration(s): 0.0932 | Elapsed 1:41:51\n",
      "Epoch: 003/010 | Batch 5726/45709 | Average Loss in last 25 iteration(s): 0.0682 | Elapsed 1:42:15\n",
      "Epoch: 003/010 | Batch 5826/45709 | Average Loss in last 25 iteration(s): 0.0739 | Elapsed 1:44:07\n",
      "Epoch: 003/010 | Batch 5851/45709 | Average Loss in last 25 iteration(s): 0.1164 | Elapsed 1:44:32\n",
      "Epoch: 003/010 | Batch 5876/45709 | Average Loss in last 25 iteration(s): 0.0456 | Elapsed 1:44:56\n",
      "Epoch: 003/010 | Batch 5901/45709 | Average Loss in last 25 iteration(s): 0.0678 | Elapsed 1:45:25\n",
      "Epoch: 003/010 | Batch 5926/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 1:45:52\n",
      "Epoch: 003/010 | Batch 5951/45709 | Average Loss in last 25 iteration(s): 0.0813 | Elapsed 1:46:18\n",
      "Epoch: 003/010 | Batch 5976/45709 | Average Loss in last 25 iteration(s): 0.0416 | Elapsed 1:46:46\n",
      "Epoch: 003/010 | Batch 6001/45709 | Average Loss in last 25 iteration(s): 0.0672 | Elapsed 1:47:10\n",
      "Epoch: 003/010 | Batch 6026/45709 | Average Loss in last 25 iteration(s): 0.0726 | Elapsed 1:47:34\n",
      "Epoch: 003/010 | Batch 6051/45709 | Average Loss in last 25 iteration(s): 0.0692 | Elapsed 1:48:03\n",
      "Epoch: 003/010 | Batch 6076/45709 | Average Loss in last 25 iteration(s): 0.0698 | Elapsed 1:48:31\n",
      "Epoch: 003/010 | Batch 6101/45709 | Average Loss in last 25 iteration(s): 0.0676 | Elapsed 1:48:58\n",
      "Epoch: 003/010 | Batch 6126/45709 | Average Loss in last 25 iteration(s): 0.0524 | Elapsed 1:49:26\n",
      "Epoch: 003/010 | Batch 6151/45709 | Average Loss in last 25 iteration(s): 0.0562 | Elapsed 1:49:52\n",
      "Epoch: 003/010 | Batch 6176/45709 | Average Loss in last 25 iteration(s): 0.0697 | Elapsed 1:50:16\n",
      "Epoch: 003/010 | Batch 6201/45709 | Average Loss in last 25 iteration(s): 0.0629 | Elapsed 1:50:45\n",
      "Epoch: 003/010 | Batch 6226/45709 | Average Loss in last 25 iteration(s): 0.0659 | Elapsed 1:51:17\n",
      "Epoch: 003/010 | Batch 6251/45709 | Average Loss in last 25 iteration(s): 0.0675 | Elapsed 1:51:44\n",
      "Epoch: 003/010 | Batch 6276/45709 | Average Loss in last 25 iteration(s): 0.0617 | Elapsed 1:52:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 6301/45709 | Average Loss in last 25 iteration(s): 0.0560 | Elapsed 1:52:37\n",
      "Epoch: 003/010 | Batch 6326/45709 | Average Loss in last 25 iteration(s): 0.0628 | Elapsed 1:53:05\n",
      "Epoch: 003/010 | Batch 6351/45709 | Average Loss in last 25 iteration(s): 0.0595 | Elapsed 1:53:37\n",
      "Epoch: 003/010 | Batch 6376/45709 | Average Loss in last 25 iteration(s): 0.0680 | Elapsed 1:54:05\n",
      "Epoch: 003/010 | Batch 6401/45709 | Average Loss in last 25 iteration(s): 0.0876 | Elapsed 1:54:32\n",
      "Epoch: 003/010 | Batch 6426/45709 | Average Loss in last 25 iteration(s): 0.0963 | Elapsed 1:54:53\n",
      "Epoch: 003/010 | Batch 6451/45709 | Average Loss in last 25 iteration(s): 0.0955 | Elapsed 1:55:18\n",
      "Epoch: 003/010 | Batch 6476/45709 | Average Loss in last 25 iteration(s): 0.0558 | Elapsed 1:55:49\n",
      "Epoch: 003/010 | Batch 6501/45709 | Average Loss in last 25 iteration(s): 0.0839 | Elapsed 1:56:20\n",
      "Epoch: 003/010 | Batch 6526/45709 | Average Loss in last 25 iteration(s): 0.0727 | Elapsed 1:56:47\n",
      "Epoch: 003/010 | Batch 6551/45709 | Average Loss in last 25 iteration(s): 0.0489 | Elapsed 1:57:14\n",
      "Epoch: 003/010 | Batch 6576/45709 | Average Loss in last 25 iteration(s): 0.0658 | Elapsed 1:57:38\n",
      "Epoch: 003/010 | Batch 6601/45709 | Average Loss in last 25 iteration(s): 0.0831 | Elapsed 1:57:59\n",
      "Epoch: 003/010 | Batch 6626/45709 | Average Loss in last 25 iteration(s): 0.0776 | Elapsed 1:58:30\n",
      "Epoch: 003/010 | Batch 6651/45709 | Average Loss in last 25 iteration(s): 0.0587 | Elapsed 1:58:58\n",
      "Epoch: 003/010 | Batch 6676/45709 | Average Loss in last 25 iteration(s): 0.0472 | Elapsed 1:59:26\n",
      "Epoch: 003/010 | Batch 6701/45709 | Average Loss in last 25 iteration(s): 0.0703 | Elapsed 1:59:55\n",
      "Epoch: 003/010 | Batch 6726/45709 | Average Loss in last 25 iteration(s): 0.0588 | Elapsed 2:00:20\n",
      "Epoch: 003/010 | Batch 6751/45709 | Average Loss in last 25 iteration(s): 0.0761 | Elapsed 2:00:44\n",
      "Epoch: 003/010 | Batch 6776/45709 | Average Loss in last 25 iteration(s): 0.0582 | Elapsed 2:01:12\n",
      "Epoch: 003/010 | Batch 6801/45709 | Average Loss in last 25 iteration(s): 0.0356 | Elapsed 2:01:42\n",
      "Epoch: 003/010 | Batch 6826/45709 | Average Loss in last 25 iteration(s): 0.0910 | Elapsed 2:02:09\n",
      "Epoch: 003/010 | Batch 6851/45709 | Average Loss in last 25 iteration(s): 0.0771 | Elapsed 2:02:38\n",
      "Epoch: 003/010 | Batch 6876/45709 | Average Loss in last 25 iteration(s): 0.0665 | Elapsed 2:03:03\n",
      "Epoch: 003/010 | Batch 6901/45709 | Average Loss in last 25 iteration(s): 0.0344 | Elapsed 2:03:26\n",
      "Epoch: 003/010 | Batch 6926/45709 | Average Loss in last 25 iteration(s): 0.0535 | Elapsed 2:03:53\n",
      "Epoch: 003/010 | Batch 6951/45709 | Average Loss in last 25 iteration(s): 0.0930 | Elapsed 2:04:21\n",
      "Epoch: 003/010 | Batch 6976/45709 | Average Loss in last 25 iteration(s): 0.0616 | Elapsed 2:04:48\n",
      "Epoch: 003/010 | Batch 7001/45709 | Average Loss in last 25 iteration(s): 0.0885 | Elapsed 2:05:15\n",
      "Epoch: 003/010 | Batch 7026/45709 | Average Loss in last 25 iteration(s): 0.0894 | Elapsed 2:05:43\n",
      "Epoch: 003/010 | Batch 7051/45709 | Average Loss in last 25 iteration(s): 0.0716 | Elapsed 2:06:07\n",
      "Epoch: 003/010 | Batch 7076/45709 | Average Loss in last 25 iteration(s): 0.0910 | Elapsed 2:06:33\n",
      "Epoch: 003/010 | Batch 7101/45709 | Average Loss in last 25 iteration(s): 0.0677 | Elapsed 2:07:01\n",
      "Epoch: 003/010 | Batch 7126/45709 | Average Loss in last 25 iteration(s): 0.0820 | Elapsed 2:07:29\n",
      "Epoch: 003/010 | Batch 7151/45709 | Average Loss in last 25 iteration(s): 0.0554 | Elapsed 2:07:56\n",
      "Epoch: 003/010 | Batch 7176/45709 | Average Loss in last 25 iteration(s): 0.0483 | Elapsed 2:08:24\n",
      "Epoch: 003/010 | Batch 7201/45709 | Average Loss in last 25 iteration(s): 0.1112 | Elapsed 2:08:50\n",
      "Epoch: 003/010 | Batch 7226/45709 | Average Loss in last 25 iteration(s): 0.0725 | Elapsed 2:09:14\n",
      "Epoch: 003/010 | Batch 7251/45709 | Average Loss in last 25 iteration(s): 0.0885 | Elapsed 2:09:43\n",
      "Epoch: 003/010 | Batch 7276/45709 | Average Loss in last 25 iteration(s): 0.1008 | Elapsed 2:10:12\n",
      "Epoch: 003/010 | Batch 7301/45709 | Average Loss in last 25 iteration(s): 0.0845 | Elapsed 2:10:43\n",
      "Epoch: 003/010 | Batch 7326/45709 | Average Loss in last 25 iteration(s): 0.0725 | Elapsed 2:11:10\n",
      "Epoch: 003/010 | Batch 7351/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 2:11:34\n",
      "Epoch: 003/010 | Batch 7376/45709 | Average Loss in last 25 iteration(s): 0.0747 | Elapsed 2:12:01\n",
      "Epoch: 003/010 | Batch 7401/45709 | Average Loss in last 25 iteration(s): 0.0579 | Elapsed 2:12:30\n",
      "Epoch: 003/010 | Batch 7426/45709 | Average Loss in last 25 iteration(s): 0.0833 | Elapsed 2:13:02\n",
      "Epoch: 003/010 | Batch 7451/45709 | Average Loss in last 25 iteration(s): 0.0556 | Elapsed 2:13:30\n",
      "Epoch: 003/010 | Batch 7476/45709 | Average Loss in last 25 iteration(s): 0.0814 | Elapsed 2:13:51\n",
      "Epoch: 003/010 | Batch 7501/45709 | Average Loss in last 25 iteration(s): 0.1043 | Elapsed 2:14:15\n",
      "Epoch: 003/010 | Batch 7526/45709 | Average Loss in last 25 iteration(s): 0.0591 | Elapsed 2:14:44\n",
      "Epoch: 003/010 | Batch 7551/45709 | Average Loss in last 25 iteration(s): 0.0744 | Elapsed 2:15:14\n",
      "Epoch: 003/010 | Batch 7576/45709 | Average Loss in last 25 iteration(s): 0.0716 | Elapsed 2:15:40\n",
      "Epoch: 003/010 | Batch 7601/45709 | Average Loss in last 25 iteration(s): 0.0763 | Elapsed 2:16:09\n",
      "Epoch: 003/010 | Batch 7626/45709 | Average Loss in last 25 iteration(s): 0.0631 | Elapsed 2:16:37\n",
      "Epoch: 003/010 | Batch 7651/45709 | Average Loss in last 25 iteration(s): 0.0613 | Elapsed 2:17:00\n",
      "Epoch: 003/010 | Batch 7676/45709 | Average Loss in last 25 iteration(s): 0.0856 | Elapsed 2:17:30\n",
      "Epoch: 003/010 | Batch 7701/45709 | Average Loss in last 25 iteration(s): 0.0847 | Elapsed 2:17:59\n",
      "Epoch: 003/010 | Batch 7726/45709 | Average Loss in last 25 iteration(s): 0.0843 | Elapsed 2:18:27\n",
      "Epoch: 003/010 | Batch 7751/45709 | Average Loss in last 25 iteration(s): 0.0641 | Elapsed 2:18:53\n",
      "Epoch: 003/010 | Batch 7776/45709 | Average Loss in last 25 iteration(s): 0.0809 | Elapsed 2:19:21\n",
      "Epoch: 003/010 | Batch 7801/45709 | Average Loss in last 25 iteration(s): 0.0763 | Elapsed 2:19:53\n",
      "Epoch: 003/010 | Batch 7826/45709 | Average Loss in last 25 iteration(s): 0.1136 | Elapsed 2:20:16\n",
      "Epoch: 003/010 | Batch 7851/45709 | Average Loss in last 25 iteration(s): 0.0652 | Elapsed 2:20:41\n",
      "Epoch: 003/010 | Batch 7876/45709 | Average Loss in last 25 iteration(s): 0.0642 | Elapsed 2:21:09\n",
      "Epoch: 003/010 | Batch 7901/45709 | Average Loss in last 25 iteration(s): 0.0399 | Elapsed 2:21:36\n",
      "Epoch: 003/010 | Batch 7926/45709 | Average Loss in last 25 iteration(s): 0.0422 | Elapsed 2:22:02\n",
      "Epoch: 003/010 | Batch 7951/45709 | Average Loss in last 25 iteration(s): 0.0767 | Elapsed 2:22:26\n",
      "Epoch: 003/010 | Batch 7976/45709 | Average Loss in last 25 iteration(s): 0.0811 | Elapsed 2:22:55\n",
      "Epoch: 003/010 | Batch 8001/45709 | Average Loss in last 25 iteration(s): 0.0822 | Elapsed 2:23:23\n",
      "Epoch: 003/010 | Batch 8026/45709 | Average Loss in last 25 iteration(s): 0.0830 | Elapsed 2:23:48\n",
      "Epoch: 003/010 | Batch 8051/45709 | Average Loss in last 25 iteration(s): 0.0746 | Elapsed 2:24:16\n",
      "Epoch: 003/010 | Batch 8076/45709 | Average Loss in last 25 iteration(s): 0.0693 | Elapsed 2:24:41\n",
      "Epoch: 003/010 | Batch 8101/45709 | Average Loss in last 25 iteration(s): 0.1022 | Elapsed 2:25:05\n",
      "Epoch: 003/010 | Batch 8126/45709 | Average Loss in last 25 iteration(s): 0.0721 | Elapsed 2:25:33\n",
      "Epoch: 003/010 | Batch 8151/45709 | Average Loss in last 25 iteration(s): 0.0625 | Elapsed 2:26:03\n",
      "Epoch: 003/010 | Batch 8176/45709 | Average Loss in last 25 iteration(s): 0.1023 | Elapsed 2:26:32\n",
      "Epoch: 003/010 | Batch 8201/45709 | Average Loss in last 25 iteration(s): 0.0669 | Elapsed 2:26:58\n",
      "Epoch: 003/010 | Batch 8226/45709 | Average Loss in last 25 iteration(s): 0.0853 | Elapsed 2:27:24\n",
      "Epoch: 003/010 | Batch 8251/45709 | Average Loss in last 25 iteration(s): 0.0926 | Elapsed 2:27:48\n",
      "Epoch: 003/010 | Batch 8276/45709 | Average Loss in last 25 iteration(s): 0.0544 | Elapsed 2:28:17\n",
      "Epoch: 003/010 | Batch 8301/45709 | Average Loss in last 25 iteration(s): 0.0964 | Elapsed 2:28:44\n",
      "Epoch: 003/010 | Batch 8326/45709 | Average Loss in last 25 iteration(s): 0.0895 | Elapsed 2:29:13\n",
      "Epoch: 003/010 | Batch 8351/45709 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 2:29:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 8376/45709 | Average Loss in last 25 iteration(s): 0.0671 | Elapsed 2:30:07\n",
      "Epoch: 003/010 | Batch 8401/45709 | Average Loss in last 25 iteration(s): 0.0760 | Elapsed 2:30:31\n",
      "Epoch: 003/010 | Batch 8426/45709 | Average Loss in last 25 iteration(s): 0.0661 | Elapsed 2:30:58\n",
      "Epoch: 003/010 | Batch 8451/45709 | Average Loss in last 25 iteration(s): 0.0865 | Elapsed 2:31:27\n",
      "Epoch: 003/010 | Batch 8476/45709 | Average Loss in last 25 iteration(s): 0.0789 | Elapsed 2:31:54\n",
      "Epoch: 003/010 | Batch 8501/45709 | Average Loss in last 25 iteration(s): 0.0782 | Elapsed 2:32:22\n",
      "Epoch: 003/010 | Batch 8526/45709 | Average Loss in last 25 iteration(s): 0.0921 | Elapsed 2:32:49\n",
      "Epoch: 003/010 | Batch 8551/45709 | Average Loss in last 25 iteration(s): 0.1076 | Elapsed 2:33:12\n",
      "Epoch: 003/010 | Batch 8576/45709 | Average Loss in last 25 iteration(s): 0.0651 | Elapsed 2:33:39\n",
      "Epoch: 003/010 | Batch 8601/45709 | Average Loss in last 25 iteration(s): 0.0851 | Elapsed 2:34:06\n",
      "Epoch: 003/010 | Batch 8626/45709 | Average Loss in last 25 iteration(s): 0.0791 | Elapsed 2:34:36\n",
      "Epoch: 003/010 | Batch 8651/45709 | Average Loss in last 25 iteration(s): 0.0649 | Elapsed 2:35:04\n",
      "Epoch: 003/010 | Batch 8676/45709 | Average Loss in last 25 iteration(s): 0.0631 | Elapsed 2:35:29\n",
      "Epoch: 003/010 | Batch 8701/45709 | Average Loss in last 25 iteration(s): 0.0605 | Elapsed 2:35:54\n",
      "Epoch: 003/010 | Batch 8726/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 2:36:19\n",
      "Epoch: 003/010 | Batch 8751/45709 | Average Loss in last 25 iteration(s): 0.0746 | Elapsed 2:36:47\n",
      "Epoch: 003/010 | Batch 8776/45709 | Average Loss in last 25 iteration(s): 0.0627 | Elapsed 2:37:14\n",
      "Epoch: 003/010 | Batch 8801/45709 | Average Loss in last 25 iteration(s): 0.0672 | Elapsed 2:37:39\n",
      "Epoch: 003/010 | Batch 8826/45709 | Average Loss in last 25 iteration(s): 0.0705 | Elapsed 2:38:07\n",
      "Epoch: 003/010 | Batch 8851/45709 | Average Loss in last 25 iteration(s): 0.0473 | Elapsed 2:38:32\n",
      "Epoch: 003/010 | Batch 8876/45709 | Average Loss in last 25 iteration(s): 0.0506 | Elapsed 2:38:56\n",
      "Epoch: 003/010 | Batch 8901/45709 | Average Loss in last 25 iteration(s): 0.0865 | Elapsed 2:39:25\n",
      "Epoch: 003/010 | Batch 8926/45709 | Average Loss in last 25 iteration(s): 0.0879 | Elapsed 2:39:53\n",
      "Epoch: 003/010 | Batch 8951/45709 | Average Loss in last 25 iteration(s): 0.0505 | Elapsed 2:40:21\n",
      "Epoch: 003/010 | Batch 8976/45709 | Average Loss in last 25 iteration(s): 0.0748 | Elapsed 2:40:49\n",
      "Epoch: 003/010 | Batch 9001/45709 | Average Loss in last 25 iteration(s): 0.0952 | Elapsed 2:41:15\n",
      "Epoch: 003/010 | Batch 9026/45709 | Average Loss in last 25 iteration(s): 0.0649 | Elapsed 2:41:39\n",
      "Epoch: 003/010 | Batch 9051/45709 | Average Loss in last 25 iteration(s): 0.0866 | Elapsed 2:42:04\n",
      "Epoch: 003/010 | Batch 9076/45709 | Average Loss in last 25 iteration(s): 0.0414 | Elapsed 2:42:33\n",
      "Epoch: 003/010 | Batch 9101/45709 | Average Loss in last 25 iteration(s): 0.0675 | Elapsed 2:43:01\n",
      "Epoch: 003/010 | Batch 9126/45709 | Average Loss in last 25 iteration(s): 0.0528 | Elapsed 2:43:29\n",
      "Epoch: 003/010 | Batch 9151/45709 | Average Loss in last 25 iteration(s): 0.0511 | Elapsed 2:43:54\n",
      "Epoch: 003/010 | Batch 9176/45709 | Average Loss in last 25 iteration(s): 0.0818 | Elapsed 2:44:21\n",
      "Epoch: 003/010 | Batch 9201/45709 | Average Loss in last 25 iteration(s): 0.0600 | Elapsed 2:44:45\n",
      "Epoch: 003/010 | Batch 9226/45709 | Average Loss in last 25 iteration(s): 0.0668 | Elapsed 2:45:15\n",
      "Epoch: 003/010 | Batch 9251/45709 | Average Loss in last 25 iteration(s): 0.0571 | Elapsed 2:45:43\n",
      "Epoch: 003/010 | Batch 9276/45709 | Average Loss in last 25 iteration(s): 0.0406 | Elapsed 2:46:10\n",
      "Epoch: 003/010 | Batch 9301/45709 | Average Loss in last 25 iteration(s): 0.0768 | Elapsed 2:46:36\n",
      "Epoch: 003/010 | Batch 9326/45709 | Average Loss in last 25 iteration(s): 0.0691 | Elapsed 2:47:01\n",
      "Epoch: 003/010 | Batch 9351/45709 | Average Loss in last 25 iteration(s): 0.0668 | Elapsed 2:47:24\n",
      "Epoch: 003/010 | Batch 9376/45709 | Average Loss in last 25 iteration(s): 0.0782 | Elapsed 2:47:51\n",
      "Epoch: 003/010 | Batch 9401/45709 | Average Loss in last 25 iteration(s): 0.0768 | Elapsed 2:48:20\n",
      "Epoch: 003/010 | Batch 9426/45709 | Average Loss in last 25 iteration(s): 0.0599 | Elapsed 2:48:47\n",
      "Epoch: 003/010 | Batch 9451/45709 | Average Loss in last 25 iteration(s): 0.0600 | Elapsed 2:49:13\n",
      "Epoch: 003/010 | Batch 9476/45709 | Average Loss in last 25 iteration(s): 0.0899 | Elapsed 2:49:40\n",
      "Epoch: 003/010 | Batch 9501/45709 | Average Loss in last 25 iteration(s): 0.0558 | Elapsed 2:50:06\n",
      "Epoch: 003/010 | Batch 9526/45709 | Average Loss in last 25 iteration(s): 0.0867 | Elapsed 2:50:31\n",
      "Epoch: 003/010 | Batch 9551/45709 | Average Loss in last 25 iteration(s): 0.0755 | Elapsed 2:50:59\n",
      "Epoch: 003/010 | Batch 9576/45709 | Average Loss in last 25 iteration(s): 0.0719 | Elapsed 2:51:27\n",
      "Epoch: 003/010 | Batch 9601/45709 | Average Loss in last 25 iteration(s): 0.0602 | Elapsed 2:51:53\n",
      "Epoch: 003/010 | Batch 9626/45709 | Average Loss in last 25 iteration(s): 0.0679 | Elapsed 2:52:20\n",
      "Epoch: 003/010 | Batch 9651/45709 | Average Loss in last 25 iteration(s): 0.0611 | Elapsed 2:52:46\n",
      "Epoch: 003/010 | Batch 9676/45709 | Average Loss in last 25 iteration(s): 0.0978 | Elapsed 2:53:09\n",
      "Epoch: 003/010 | Batch 9701/45709 | Average Loss in last 25 iteration(s): 0.0904 | Elapsed 2:53:36\n",
      "Epoch: 003/010 | Batch 9726/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 2:54:07\n",
      "Epoch: 003/010 | Batch 9751/45709 | Average Loss in last 25 iteration(s): 0.0683 | Elapsed 2:54:34\n",
      "Epoch: 003/010 | Batch 9776/45709 | Average Loss in last 25 iteration(s): 0.0571 | Elapsed 2:54:59\n",
      "Epoch: 003/010 | Batch 9801/45709 | Average Loss in last 25 iteration(s): 0.1148 | Elapsed 2:55:26\n",
      "Epoch: 003/010 | Batch 9826/45709 | Average Loss in last 25 iteration(s): 0.0663 | Elapsed 2:55:49\n",
      "Epoch: 003/010 | Batch 9851/45709 | Average Loss in last 25 iteration(s): 0.0453 | Elapsed 2:56:18\n",
      "Epoch: 003/010 | Batch 9876/45709 | Average Loss in last 25 iteration(s): 0.0661 | Elapsed 2:56:48\n",
      "Epoch: 003/010 | Batch 9901/45709 | Average Loss in last 25 iteration(s): 0.0783 | Elapsed 2:57:16\n",
      "Epoch: 003/010 | Batch 9926/45709 | Average Loss in last 25 iteration(s): 0.0760 | Elapsed 2:57:41\n",
      "Epoch: 003/010 | Batch 9951/45709 | Average Loss in last 25 iteration(s): 0.0395 | Elapsed 2:58:08\n",
      "Epoch: 003/010 | Batch 9976/45709 | Average Loss in last 25 iteration(s): 0.0605 | Elapsed 2:58:32\n",
      "Epoch: 003/010 | Batch 10001/45709 | Average Loss in last 25 iteration(s): 0.0841 | Elapsed 2:59:01\n",
      "Epoch: 003/010 | Batch 10026/45709 | Average Loss in last 25 iteration(s): 0.0611 | Elapsed 2:59:31\n",
      "Epoch: 003/010 | Batch 10051/45709 | Average Loss in last 25 iteration(s): 0.0965 | Elapsed 2:59:58\n",
      "Epoch: 003/010 | Batch 10076/45709 | Average Loss in last 25 iteration(s): 0.0779 | Elapsed 3:00:25\n",
      "Epoch: 003/010 | Batch 10101/45709 | Average Loss in last 25 iteration(s): 0.0923 | Elapsed 3:00:51\n",
      "Epoch: 003/010 | Batch 10126/45709 | Average Loss in last 25 iteration(s): 0.0824 | Elapsed 3:01:16\n",
      "Epoch: 003/010 | Batch 10151/45709 | Average Loss in last 25 iteration(s): 0.0542 | Elapsed 3:01:42\n",
      "Epoch: 003/010 | Batch 10176/45709 | Average Loss in last 25 iteration(s): 0.0762 | Elapsed 3:02:11\n",
      "Epoch: 003/010 | Batch 10201/45709 | Average Loss in last 25 iteration(s): 0.0909 | Elapsed 3:02:38\n",
      "Epoch: 003/010 | Batch 10226/45709 | Average Loss in last 25 iteration(s): 0.0695 | Elapsed 3:03:06\n",
      "Epoch: 003/010 | Batch 10251/45709 | Average Loss in last 25 iteration(s): 0.0978 | Elapsed 3:03:35\n",
      "Epoch: 003/010 | Batch 10276/45709 | Average Loss in last 25 iteration(s): 0.0567 | Elapsed 3:04:00\n",
      "Epoch: 003/010 | Batch 10301/45709 | Average Loss in last 25 iteration(s): 0.0683 | Elapsed 3:04:25\n",
      "Epoch: 003/010 | Batch 10326/45709 | Average Loss in last 25 iteration(s): 0.0608 | Elapsed 3:04:54\n",
      "Epoch: 003/010 | Batch 10351/45709 | Average Loss in last 25 iteration(s): 0.0850 | Elapsed 3:05:23\n",
      "Epoch: 003/010 | Batch 10376/45709 | Average Loss in last 25 iteration(s): 0.0485 | Elapsed 3:05:48\n",
      "Epoch: 003/010 | Batch 10401/45709 | Average Loss in last 25 iteration(s): 0.0970 | Elapsed 3:06:15\n",
      "Epoch: 003/010 | Batch 10426/45709 | Average Loss in last 25 iteration(s): 0.0415 | Elapsed 3:06:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 10451/45709 | Average Loss in last 25 iteration(s): 0.0500 | Elapsed 3:07:06\n",
      "Epoch: 003/010 | Batch 10476/45709 | Average Loss in last 25 iteration(s): 0.0482 | Elapsed 3:07:36\n",
      "Epoch: 003/010 | Batch 10501/45709 | Average Loss in last 25 iteration(s): 0.0843 | Elapsed 3:08:03\n",
      "Epoch: 003/010 | Batch 10526/45709 | Average Loss in last 25 iteration(s): 0.0692 | Elapsed 3:08:30\n",
      "Epoch: 003/010 | Batch 10551/45709 | Average Loss in last 25 iteration(s): 0.0692 | Elapsed 3:08:58\n",
      "Epoch: 003/010 | Batch 10576/45709 | Average Loss in last 25 iteration(s): 0.0448 | Elapsed 3:09:24\n",
      "Epoch: 003/010 | Batch 10601/45709 | Average Loss in last 25 iteration(s): 0.0631 | Elapsed 3:09:50\n",
      "Epoch: 003/010 | Batch 10626/45709 | Average Loss in last 25 iteration(s): 0.0835 | Elapsed 3:10:21\n",
      "Epoch: 003/010 | Batch 10651/45709 | Average Loss in last 25 iteration(s): 0.0632 | Elapsed 3:10:48\n",
      "Epoch: 003/010 | Batch 10676/45709 | Average Loss in last 25 iteration(s): 0.0604 | Elapsed 3:11:15\n",
      "Epoch: 003/010 | Batch 10701/45709 | Average Loss in last 25 iteration(s): 0.0543 | Elapsed 3:11:43\n",
      "Epoch: 003/010 | Batch 10726/45709 | Average Loss in last 25 iteration(s): 0.0855 | Elapsed 3:12:08\n",
      "Epoch: 003/010 | Batch 10751/45709 | Average Loss in last 25 iteration(s): 0.0507 | Elapsed 3:12:36\n",
      "Epoch: 003/010 | Batch 10776/45709 | Average Loss in last 25 iteration(s): 0.0970 | Elapsed 3:13:04\n",
      "Epoch: 003/010 | Batch 10801/45709 | Average Loss in last 25 iteration(s): 0.0649 | Elapsed 3:13:30\n",
      "Epoch: 003/010 | Batch 10826/45709 | Average Loss in last 25 iteration(s): 0.0775 | Elapsed 3:13:59\n",
      "Epoch: 003/010 | Batch 10851/45709 | Average Loss in last 25 iteration(s): 0.0747 | Elapsed 3:14:26\n",
      "Epoch: 003/010 | Batch 10876/45709 | Average Loss in last 25 iteration(s): 0.0569 | Elapsed 3:14:51\n",
      "Epoch: 003/010 | Batch 10901/45709 | Average Loss in last 25 iteration(s): 0.0779 | Elapsed 3:15:16\n",
      "Epoch: 003/010 | Batch 10926/45709 | Average Loss in last 25 iteration(s): 0.0588 | Elapsed 3:15:46\n",
      "Epoch: 003/010 | Batch 10951/45709 | Average Loss in last 25 iteration(s): 0.0688 | Elapsed 3:16:13\n",
      "Epoch: 003/010 | Batch 10976/45709 | Average Loss in last 25 iteration(s): 0.0325 | Elapsed 3:16:41\n",
      "Epoch: 003/010 | Batch 11001/45709 | Average Loss in last 25 iteration(s): 0.0934 | Elapsed 3:17:08\n",
      "Epoch: 003/010 | Batch 11026/45709 | Average Loss in last 25 iteration(s): 0.0612 | Elapsed 3:17:33\n",
      "Epoch: 003/010 | Batch 11051/45709 | Average Loss in last 25 iteration(s): 0.0548 | Elapsed 3:18:00\n",
      "Epoch: 003/010 | Batch 11076/45709 | Average Loss in last 25 iteration(s): 0.0800 | Elapsed 3:18:29\n",
      "Epoch: 003/010 | Batch 11101/45709 | Average Loss in last 25 iteration(s): 0.0577 | Elapsed 3:18:56\n",
      "Epoch: 003/010 | Batch 11126/45709 | Average Loss in last 25 iteration(s): 0.0565 | Elapsed 3:19:22\n",
      "Epoch: 003/010 | Batch 11151/45709 | Average Loss in last 25 iteration(s): 0.0826 | Elapsed 3:19:49\n",
      "Epoch: 003/010 | Batch 11176/45709 | Average Loss in last 25 iteration(s): 0.0845 | Elapsed 3:20:15\n",
      "Epoch: 003/010 | Batch 11201/45709 | Average Loss in last 25 iteration(s): 0.0828 | Elapsed 3:20:40\n",
      "Epoch: 003/010 | Batch 11226/45709 | Average Loss in last 25 iteration(s): 0.0495 | Elapsed 3:21:09\n",
      "Epoch: 003/010 | Batch 11251/45709 | Average Loss in last 25 iteration(s): 0.0462 | Elapsed 3:21:37\n",
      "Epoch: 003/010 | Batch 11276/45709 | Average Loss in last 25 iteration(s): 0.0695 | Elapsed 3:22:05\n",
      "Epoch: 003/010 | Batch 11301/45709 | Average Loss in last 25 iteration(s): 0.1062 | Elapsed 3:22:33\n",
      "Epoch: 003/010 | Batch 11326/45709 | Average Loss in last 25 iteration(s): 0.0920 | Elapsed 3:22:57\n",
      "Epoch: 003/010 | Batch 11351/45709 | Average Loss in last 25 iteration(s): 0.0641 | Elapsed 3:23:20\n",
      "Epoch: 003/010 | Batch 11376/45709 | Average Loss in last 25 iteration(s): 0.0884 | Elapsed 3:23:51\n",
      "Epoch: 003/010 | Batch 11401/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 3:24:18\n",
      "Epoch: 003/010 | Batch 11426/45709 | Average Loss in last 25 iteration(s): 0.0689 | Elapsed 3:24:45\n",
      "Epoch: 003/010 | Batch 11451/45709 | Average Loss in last 25 iteration(s): 0.0538 | Elapsed 3:25:14\n",
      "Epoch: 003/010 | Batch 11476/45709 | Average Loss in last 25 iteration(s): 0.0619 | Elapsed 3:25:39\n",
      "Epoch: 003/010 | Batch 11501/45709 | Average Loss in last 25 iteration(s): 0.0662 | Elapsed 3:26:03\n",
      "Epoch: 003/010 | Batch 11526/45709 | Average Loss in last 25 iteration(s): 0.0649 | Elapsed 3:26:33\n",
      "Epoch: 003/010 | Batch 11551/45709 | Average Loss in last 25 iteration(s): 0.0641 | Elapsed 3:27:00\n",
      "Epoch: 003/010 | Batch 11576/45709 | Average Loss in last 25 iteration(s): 0.0769 | Elapsed 3:27:28\n",
      "Epoch: 003/010 | Batch 11601/45709 | Average Loss in last 25 iteration(s): 0.0963 | Elapsed 3:27:55\n",
      "Epoch: 003/010 | Batch 11626/45709 | Average Loss in last 25 iteration(s): 0.0989 | Elapsed 3:28:22\n",
      "Epoch: 003/010 | Batch 11651/45709 | Average Loss in last 25 iteration(s): 0.0512 | Elapsed 3:28:45\n",
      "Epoch: 003/010 | Batch 11676/45709 | Average Loss in last 25 iteration(s): 0.0738 | Elapsed 3:29:15\n",
      "Epoch: 003/010 | Batch 11701/45709 | Average Loss in last 25 iteration(s): 0.0952 | Elapsed 3:29:42\n",
      "Epoch: 003/010 | Batch 11726/45709 | Average Loss in last 25 iteration(s): 0.0584 | Elapsed 3:30:08\n",
      "Epoch: 003/010 | Batch 11751/45709 | Average Loss in last 25 iteration(s): 0.0640 | Elapsed 3:30:34\n",
      "Epoch: 003/010 | Batch 11776/45709 | Average Loss in last 25 iteration(s): 0.0566 | Elapsed 3:31:02\n",
      "Epoch: 003/010 | Batch 11801/45709 | Average Loss in last 25 iteration(s): 0.0625 | Elapsed 3:31:25\n",
      "Epoch: 003/010 | Batch 11826/45709 | Average Loss in last 25 iteration(s): 0.0497 | Elapsed 3:31:56\n",
      "Epoch: 003/010 | Batch 11851/45709 | Average Loss in last 25 iteration(s): 0.0501 | Elapsed 3:32:25\n",
      "Epoch: 003/010 | Batch 11876/45709 | Average Loss in last 25 iteration(s): 0.0999 | Elapsed 3:32:51\n",
      "Epoch: 003/010 | Batch 11901/45709 | Average Loss in last 25 iteration(s): 0.0662 | Elapsed 3:33:18\n",
      "Epoch: 003/010 | Batch 11926/45709 | Average Loss in last 25 iteration(s): 0.1114 | Elapsed 3:33:44\n",
      "Epoch: 003/010 | Batch 11951/45709 | Average Loss in last 25 iteration(s): 0.0832 | Elapsed 3:34:09\n",
      "Epoch: 003/010 | Batch 11976/45709 | Average Loss in last 25 iteration(s): 0.0896 | Elapsed 3:34:34\n",
      "Epoch: 003/010 | Batch 12001/45709 | Average Loss in last 25 iteration(s): 0.0538 | Elapsed 3:35:04\n",
      "Epoch: 003/010 | Batch 12026/45709 | Average Loss in last 25 iteration(s): 0.0548 | Elapsed 3:35:31\n",
      "Epoch: 003/010 | Batch 12051/45709 | Average Loss in last 25 iteration(s): 0.0866 | Elapsed 3:35:59\n",
      "Epoch: 003/010 | Batch 12076/45709 | Average Loss in last 25 iteration(s): 0.0686 | Elapsed 3:36:26\n",
      "Epoch: 003/010 | Batch 12101/45709 | Average Loss in last 25 iteration(s): 0.0739 | Elapsed 3:36:50\n",
      "Epoch: 003/010 | Batch 12126/45709 | Average Loss in last 25 iteration(s): 0.0765 | Elapsed 3:37:16\n",
      "Epoch: 003/010 | Batch 12151/45709 | Average Loss in last 25 iteration(s): 0.0894 | Elapsed 3:37:46\n",
      "Epoch: 003/010 | Batch 12176/45709 | Average Loss in last 25 iteration(s): 0.0843 | Elapsed 3:38:13\n",
      "Epoch: 003/010 | Batch 12201/45709 | Average Loss in last 25 iteration(s): 0.0763 | Elapsed 3:38:41\n",
      "Epoch: 003/010 | Batch 12226/45709 | Average Loss in last 25 iteration(s): 0.0696 | Elapsed 3:39:09\n",
      "Epoch: 003/010 | Batch 12251/45709 | Average Loss in last 25 iteration(s): 0.0895 | Elapsed 3:39:33\n",
      "Epoch: 003/010 | Batch 12276/45709 | Average Loss in last 25 iteration(s): 0.0843 | Elapsed 3:40:00\n",
      "Epoch: 003/010 | Batch 12301/45709 | Average Loss in last 25 iteration(s): 0.0525 | Elapsed 3:40:28\n",
      "Epoch: 003/010 | Batch 12326/45709 | Average Loss in last 25 iteration(s): 0.0470 | Elapsed 3:40:54\n",
      "Epoch: 003/010 | Batch 12351/45709 | Average Loss in last 25 iteration(s): 0.0832 | Elapsed 3:41:22\n",
      "Epoch: 003/010 | Batch 12376/45709 | Average Loss in last 25 iteration(s): 0.0802 | Elapsed 3:41:50\n",
      "Epoch: 003/010 | Batch 12401/45709 | Average Loss in last 25 iteration(s): 0.0740 | Elapsed 3:42:15\n",
      "Epoch: 003/010 | Batch 12426/45709 | Average Loss in last 25 iteration(s): 0.0862 | Elapsed 3:42:39\n",
      "Epoch: 003/010 | Batch 12451/45709 | Average Loss in last 25 iteration(s): 0.0739 | Elapsed 3:43:06\n",
      "Epoch: 003/010 | Batch 12476/45709 | Average Loss in last 25 iteration(s): 0.0645 | Elapsed 3:43:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 12501/45709 | Average Loss in last 25 iteration(s): 0.0648 | Elapsed 3:44:00\n",
      "Epoch: 003/010 | Batch 12526/45709 | Average Loss in last 25 iteration(s): 0.0507 | Elapsed 3:44:27\n",
      "Epoch: 003/010 | Batch 12551/45709 | Average Loss in last 25 iteration(s): 0.0565 | Elapsed 3:44:54\n",
      "Epoch: 003/010 | Batch 12576/45709 | Average Loss in last 25 iteration(s): 0.1377 | Elapsed 3:45:18\n",
      "Epoch: 003/010 | Batch 12601/45709 | Average Loss in last 25 iteration(s): 0.0918 | Elapsed 3:45:44\n",
      "Epoch: 003/010 | Batch 12626/45709 | Average Loss in last 25 iteration(s): 0.0655 | Elapsed 3:46:13\n",
      "Epoch: 003/010 | Batch 12651/45709 | Average Loss in last 25 iteration(s): 0.1030 | Elapsed 3:46:40\n",
      "Epoch: 003/010 | Batch 12676/45709 | Average Loss in last 25 iteration(s): 0.1011 | Elapsed 3:47:08\n",
      "Epoch: 003/010 | Batch 12701/45709 | Average Loss in last 25 iteration(s): 0.0951 | Elapsed 3:47:35\n",
      "Epoch: 003/010 | Batch 12726/45709 | Average Loss in last 25 iteration(s): 0.0842 | Elapsed 3:48:00\n",
      "Epoch: 003/010 | Batch 12751/45709 | Average Loss in last 25 iteration(s): 0.0574 | Elapsed 3:48:25\n",
      "Epoch: 003/010 | Batch 12776/45709 | Average Loss in last 25 iteration(s): 0.0936 | Elapsed 3:48:55\n",
      "Epoch: 003/010 | Batch 12801/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 3:49:24\n",
      "Epoch: 003/010 | Batch 12826/45709 | Average Loss in last 25 iteration(s): 0.0567 | Elapsed 3:49:50\n",
      "Epoch: 003/010 | Batch 12851/45709 | Average Loss in last 25 iteration(s): 0.0558 | Elapsed 3:50:19\n",
      "Epoch: 003/010 | Batch 12876/45709 | Average Loss in last 25 iteration(s): 0.0482 | Elapsed 3:50:42\n",
      "Epoch: 003/010 | Batch 12901/45709 | Average Loss in last 25 iteration(s): 0.0833 | Elapsed 3:51:08\n",
      "Epoch: 003/010 | Batch 12926/45709 | Average Loss in last 25 iteration(s): 0.0805 | Elapsed 3:51:37\n",
      "Epoch: 003/010 | Batch 12951/45709 | Average Loss in last 25 iteration(s): 0.1026 | Elapsed 3:52:04\n",
      "Epoch: 003/010 | Batch 12976/45709 | Average Loss in last 25 iteration(s): 0.0745 | Elapsed 3:52:32\n",
      "Epoch: 003/010 | Batch 13001/45709 | Average Loss in last 25 iteration(s): 0.0557 | Elapsed 3:52:59\n",
      "Epoch: 003/010 | Batch 13026/45709 | Average Loss in last 25 iteration(s): 0.0732 | Elapsed 3:53:25\n",
      "Epoch: 003/010 | Batch 13051/45709 | Average Loss in last 25 iteration(s): 0.0590 | Elapsed 3:53:48\n",
      "Epoch: 003/010 | Batch 13076/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 3:54:18\n",
      "Epoch: 003/010 | Batch 13101/45709 | Average Loss in last 25 iteration(s): 0.1073 | Elapsed 3:54:44\n",
      "Epoch: 003/010 | Batch 13126/45709 | Average Loss in last 25 iteration(s): 0.0919 | Elapsed 3:55:11\n",
      "Epoch: 003/010 | Batch 13151/45709 | Average Loss in last 25 iteration(s): 0.0826 | Elapsed 3:55:40\n",
      "Epoch: 003/010 | Batch 13176/45709 | Average Loss in last 25 iteration(s): 0.0699 | Elapsed 3:56:07\n",
      "Epoch: 003/010 | Batch 13201/45709 | Average Loss in last 25 iteration(s): 0.1033 | Elapsed 3:56:32\n",
      "Epoch: 003/010 | Batch 13226/45709 | Average Loss in last 25 iteration(s): 0.0417 | Elapsed 3:57:00\n",
      "Epoch: 003/010 | Batch 13251/45709 | Average Loss in last 25 iteration(s): 0.0608 | Elapsed 3:57:28\n",
      "Epoch: 003/010 | Batch 13276/45709 | Average Loss in last 25 iteration(s): 0.0733 | Elapsed 3:57:56\n",
      "Epoch: 003/010 | Batch 13301/45709 | Average Loss in last 25 iteration(s): 0.0714 | Elapsed 3:58:24\n",
      "Epoch: 003/010 | Batch 13326/45709 | Average Loss in last 25 iteration(s): 0.0905 | Elapsed 3:58:50\n",
      "Epoch: 003/010 | Batch 13351/45709 | Average Loss in last 25 iteration(s): 0.0439 | Elapsed 3:59:14\n",
      "Epoch: 003/010 | Batch 13376/45709 | Average Loss in last 25 iteration(s): 0.0948 | Elapsed 3:59:41\n",
      "Epoch: 003/010 | Batch 13401/45709 | Average Loss in last 25 iteration(s): 0.0575 | Elapsed 4:00:10\n",
      "Epoch: 003/010 | Batch 13426/45709 | Average Loss in last 25 iteration(s): 0.0537 | Elapsed 4:00:37\n",
      "Epoch: 003/010 | Batch 13451/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 4:01:04\n",
      "Epoch: 003/010 | Batch 13476/45709 | Average Loss in last 25 iteration(s): 0.0853 | Elapsed 4:01:31\n",
      "Epoch: 003/010 | Batch 13501/45709 | Average Loss in last 25 iteration(s): 0.0705 | Elapsed 4:01:55\n",
      "Epoch: 003/010 | Batch 13526/45709 | Average Loss in last 25 iteration(s): 0.0955 | Elapsed 4:02:23\n",
      "Epoch: 003/010 | Batch 13551/45709 | Average Loss in last 25 iteration(s): 0.0785 | Elapsed 4:02:51\n",
      "Epoch: 003/010 | Batch 13576/45709 | Average Loss in last 25 iteration(s): 0.0655 | Elapsed 4:03:19\n",
      "Epoch: 003/010 | Batch 13601/45709 | Average Loss in last 25 iteration(s): 0.0610 | Elapsed 4:03:45\n",
      "Epoch: 003/010 | Batch 13626/45709 | Average Loss in last 25 iteration(s): 0.0378 | Elapsed 4:04:13\n",
      "Epoch: 003/010 | Batch 13651/45709 | Average Loss in last 25 iteration(s): 0.0701 | Elapsed 4:04:35\n",
      "Epoch: 003/010 | Batch 13676/45709 | Average Loss in last 25 iteration(s): 0.0636 | Elapsed 4:05:04\n",
      "Epoch: 003/010 | Batch 13701/45709 | Average Loss in last 25 iteration(s): 0.0477 | Elapsed 4:05:32\n",
      "Epoch: 003/010 | Batch 13726/45709 | Average Loss in last 25 iteration(s): 0.0676 | Elapsed 4:06:01\n",
      "Epoch: 003/010 | Batch 13751/45709 | Average Loss in last 25 iteration(s): 0.0921 | Elapsed 4:06:34\n",
      "Epoch: 003/010 | Batch 13776/45709 | Average Loss in last 25 iteration(s): 0.0897 | Elapsed 4:07:00\n",
      "Epoch: 003/010 | Batch 13801/45709 | Average Loss in last 25 iteration(s): 0.0975 | Elapsed 4:07:29\n",
      "Epoch: 003/010 | Batch 13826/45709 | Average Loss in last 25 iteration(s): 0.1165 | Elapsed 4:07:58\n",
      "Epoch: 003/010 | Batch 13851/45709 | Average Loss in last 25 iteration(s): 0.0965 | Elapsed 4:08:31\n",
      "Epoch: 003/010 | Batch 13876/45709 | Average Loss in last 25 iteration(s): 0.0819 | Elapsed 4:08:58\n",
      "Epoch: 003/010 | Batch 13901/45709 | Average Loss in last 25 iteration(s): 0.0728 | Elapsed 4:09:24\n",
      "Epoch: 003/010 | Batch 13926/45709 | Average Loss in last 25 iteration(s): 0.0730 | Elapsed 4:09:52\n",
      "Epoch: 003/010 | Batch 13951/45709 | Average Loss in last 25 iteration(s): 0.0594 | Elapsed 4:10:15\n",
      "Epoch: 003/010 | Batch 13976/45709 | Average Loss in last 25 iteration(s): 0.0907 | Elapsed 4:10:48\n",
      "Epoch: 003/010 | Batch 14001/45709 | Average Loss in last 25 iteration(s): 0.0689 | Elapsed 4:11:19\n",
      "Epoch: 003/010 | Batch 14026/45709 | Average Loss in last 25 iteration(s): 0.0791 | Elapsed 4:11:42\n",
      "Epoch: 003/010 | Batch 14051/45709 | Average Loss in last 25 iteration(s): 0.0824 | Elapsed 4:12:11\n",
      "Epoch: 003/010 | Batch 14076/45709 | Average Loss in last 25 iteration(s): 0.0551 | Elapsed 4:12:41\n",
      "Epoch: 003/010 | Batch 14101/45709 | Average Loss in last 25 iteration(s): 0.0605 | Elapsed 4:13:07\n",
      "Epoch: 003/010 | Batch 14126/45709 | Average Loss in last 25 iteration(s): 0.0750 | Elapsed 4:13:36\n",
      "Epoch: 003/010 | Batch 14151/45709 | Average Loss in last 25 iteration(s): 0.0950 | Elapsed 4:13:58\n",
      "Epoch: 003/010 | Batch 14176/45709 | Average Loss in last 25 iteration(s): 0.0567 | Elapsed 4:14:24\n",
      "Epoch: 003/010 | Batch 14201/45709 | Average Loss in last 25 iteration(s): 0.0624 | Elapsed 4:14:52\n",
      "Epoch: 003/010 | Batch 14226/45709 | Average Loss in last 25 iteration(s): 0.0464 | Elapsed 4:15:22\n",
      "Epoch: 003/010 | Batch 14251/45709 | Average Loss in last 25 iteration(s): 0.0587 | Elapsed 4:15:50\n",
      "Epoch: 003/010 | Batch 14276/45709 | Average Loss in last 25 iteration(s): 0.0798 | Elapsed 4:16:20\n",
      "Epoch: 003/010 | Batch 14301/45709 | Average Loss in last 25 iteration(s): 0.0961 | Elapsed 4:16:45\n",
      "Epoch: 003/010 | Batch 14326/45709 | Average Loss in last 25 iteration(s): 0.0760 | Elapsed 4:17:08\n",
      "Epoch: 003/010 | Batch 14351/45709 | Average Loss in last 25 iteration(s): 0.0845 | Elapsed 4:17:37\n",
      "Epoch: 003/010 | Batch 14376/45709 | Average Loss in last 25 iteration(s): 0.0633 | Elapsed 4:18:06\n",
      "Epoch: 003/010 | Batch 14401/45709 | Average Loss in last 25 iteration(s): 0.0758 | Elapsed 4:18:31\n",
      "Epoch: 003/010 | Batch 14426/45709 | Average Loss in last 25 iteration(s): 0.0628 | Elapsed 4:18:59\n",
      "Epoch: 003/010 | Batch 14451/45709 | Average Loss in last 25 iteration(s): 0.0600 | Elapsed 4:19:26\n",
      "Epoch: 003/010 | Batch 14476/45709 | Average Loss in last 25 iteration(s): 0.0714 | Elapsed 4:19:51\n",
      "Epoch: 003/010 | Batch 14501/45709 | Average Loss in last 25 iteration(s): 0.0458 | Elapsed 4:20:19\n",
      "Epoch: 003/010 | Batch 14526/45709 | Average Loss in last 25 iteration(s): 0.1105 | Elapsed 4:20:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 14551/45709 | Average Loss in last 25 iteration(s): 0.0685 | Elapsed 4:21:14\n",
      "Epoch: 003/010 | Batch 14576/45709 | Average Loss in last 25 iteration(s): 0.0917 | Elapsed 4:21:41\n",
      "Epoch: 003/010 | Batch 14601/45709 | Average Loss in last 25 iteration(s): 0.0555 | Elapsed 4:22:08\n",
      "Epoch: 003/010 | Batch 14626/45709 | Average Loss in last 25 iteration(s): 0.0780 | Elapsed 4:22:32\n",
      "Epoch: 003/010 | Batch 14651/45709 | Average Loss in last 25 iteration(s): 0.0657 | Elapsed 4:23:00\n",
      "Epoch: 003/010 | Batch 14676/45709 | Average Loss in last 25 iteration(s): 0.0580 | Elapsed 4:23:28\n",
      "Epoch: 003/010 | Batch 14701/45709 | Average Loss in last 25 iteration(s): 0.0785 | Elapsed 4:23:55\n",
      "Epoch: 003/010 | Batch 14726/45709 | Average Loss in last 25 iteration(s): 0.0616 | Elapsed 4:24:22\n",
      "Epoch: 003/010 | Batch 14751/45709 | Average Loss in last 25 iteration(s): 0.0684 | Elapsed 4:24:50\n",
      "Epoch: 003/010 | Batch 14776/45709 | Average Loss in last 25 iteration(s): 0.0561 | Elapsed 4:25:12\n",
      "Epoch: 003/010 | Batch 14801/45709 | Average Loss in last 25 iteration(s): 0.0569 | Elapsed 4:25:42\n",
      "Epoch: 003/010 | Batch 14826/45709 | Average Loss in last 25 iteration(s): 0.0809 | Elapsed 4:26:11\n",
      "Epoch: 003/010 | Batch 14851/45709 | Average Loss in last 25 iteration(s): 0.0689 | Elapsed 4:26:38\n",
      "Epoch: 003/010 | Batch 14876/45709 | Average Loss in last 25 iteration(s): 0.0619 | Elapsed 4:27:06\n",
      "Epoch: 003/010 | Batch 14901/45709 | Average Loss in last 25 iteration(s): 0.0650 | Elapsed 4:27:32\n",
      "Epoch: 003/010 | Batch 14926/45709 | Average Loss in last 25 iteration(s): 0.0851 | Elapsed 4:27:56\n",
      "Epoch: 003/010 | Batch 14951/45709 | Average Loss in last 25 iteration(s): 0.0748 | Elapsed 4:28:25\n",
      "Epoch: 003/010 | Batch 14976/45709 | Average Loss in last 25 iteration(s): 0.0587 | Elapsed 4:28:52\n",
      "Epoch: 003/010 | Batch 15001/45709 | Average Loss in last 25 iteration(s): 0.0665 | Elapsed 4:29:19\n",
      "Epoch: 003/010 | Batch 15026/45709 | Average Loss in last 25 iteration(s): 0.1047 | Elapsed 4:29:45\n",
      "Epoch: 003/010 | Batch 15051/45709 | Average Loss in last 25 iteration(s): 0.0701 | Elapsed 4:30:11\n",
      "Epoch: 003/010 | Batch 15076/45709 | Average Loss in last 25 iteration(s): 0.0670 | Elapsed 4:30:35\n",
      "Epoch: 003/010 | Batch 15101/45709 | Average Loss in last 25 iteration(s): 0.0612 | Elapsed 4:31:03\n",
      "Epoch: 003/010 | Batch 15126/45709 | Average Loss in last 25 iteration(s): 0.0461 | Elapsed 4:31:31\n",
      "Epoch: 003/010 | Batch 15151/45709 | Average Loss in last 25 iteration(s): 0.0536 | Elapsed 4:31:58\n",
      "Epoch: 003/010 | Batch 15176/45709 | Average Loss in last 25 iteration(s): 0.0777 | Elapsed 4:32:24\n",
      "Epoch: 003/010 | Batch 15201/45709 | Average Loss in last 25 iteration(s): 0.0760 | Elapsed 4:32:53\n",
      "Epoch: 003/010 | Batch 15226/45709 | Average Loss in last 25 iteration(s): 0.0673 | Elapsed 4:33:17\n",
      "Epoch: 003/010 | Batch 15251/45709 | Average Loss in last 25 iteration(s): 0.0502 | Elapsed 4:33:44\n",
      "Epoch: 003/010 | Batch 15276/45709 | Average Loss in last 25 iteration(s): 0.0524 | Elapsed 4:34:13\n",
      "Epoch: 003/010 | Batch 15301/45709 | Average Loss in last 25 iteration(s): 0.0521 | Elapsed 4:34:40\n",
      "Epoch: 003/010 | Batch 15326/45709 | Average Loss in last 25 iteration(s): 0.0610 | Elapsed 4:35:07\n",
      "Epoch: 003/010 | Batch 15351/45709 | Average Loss in last 25 iteration(s): 0.0544 | Elapsed 4:35:33\n",
      "Epoch: 003/010 | Batch 15376/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 4:35:58\n",
      "Epoch: 003/010 | Batch 15401/45709 | Average Loss in last 25 iteration(s): 0.0874 | Elapsed 4:36:25\n",
      "Epoch: 003/010 | Batch 15426/45709 | Average Loss in last 25 iteration(s): 0.0863 | Elapsed 4:36:54\n",
      "Epoch: 003/010 | Batch 15451/45709 | Average Loss in last 25 iteration(s): 0.0640 | Elapsed 4:37:22\n",
      "Epoch: 003/010 | Batch 15476/45709 | Average Loss in last 25 iteration(s): 0.0771 | Elapsed 4:37:49\n",
      "Epoch: 003/010 | Batch 15501/45709 | Average Loss in last 25 iteration(s): 0.0678 | Elapsed 4:38:17\n",
      "Epoch: 003/010 | Batch 15526/45709 | Average Loss in last 25 iteration(s): 0.0796 | Elapsed 4:38:41\n",
      "Epoch: 003/010 | Batch 15551/45709 | Average Loss in last 25 iteration(s): 0.0639 | Elapsed 4:39:08\n",
      "Epoch: 003/010 | Batch 15576/45709 | Average Loss in last 25 iteration(s): 0.0690 | Elapsed 4:39:36\n",
      "Epoch: 003/010 | Batch 15601/45709 | Average Loss in last 25 iteration(s): 0.1010 | Elapsed 4:40:05\n",
      "Epoch: 003/010 | Batch 15626/45709 | Average Loss in last 25 iteration(s): 0.0793 | Elapsed 4:40:33\n",
      "Epoch: 003/010 | Batch 15651/45709 | Average Loss in last 25 iteration(s): 0.0828 | Elapsed 4:40:59\n",
      "Epoch: 003/010 | Batch 15676/45709 | Average Loss in last 25 iteration(s): 0.0778 | Elapsed 4:41:24\n",
      "Epoch: 003/010 | Batch 15701/45709 | Average Loss in last 25 iteration(s): 0.0708 | Elapsed 4:41:52\n",
      "Epoch: 003/010 | Batch 15726/45709 | Average Loss in last 25 iteration(s): 0.0662 | Elapsed 4:42:20\n",
      "Epoch: 003/010 | Batch 15751/45709 | Average Loss in last 25 iteration(s): 0.0858 | Elapsed 4:42:48\n",
      "Epoch: 003/010 | Batch 15776/45709 | Average Loss in last 25 iteration(s): 0.0588 | Elapsed 4:43:15\n",
      "Epoch: 003/010 | Batch 15801/45709 | Average Loss in last 25 iteration(s): 0.0542 | Elapsed 4:43:43\n",
      "Epoch: 003/010 | Batch 15826/45709 | Average Loss in last 25 iteration(s): 0.0560 | Elapsed 4:44:06\n",
      "Epoch: 003/010 | Batch 15851/45709 | Average Loss in last 25 iteration(s): 0.0704 | Elapsed 4:44:35\n",
      "Epoch: 003/010 | Batch 15876/45709 | Average Loss in last 25 iteration(s): 0.0725 | Elapsed 4:45:05\n",
      "Epoch: 003/010 | Batch 15901/45709 | Average Loss in last 25 iteration(s): 0.0771 | Elapsed 4:45:33\n",
      "Epoch: 003/010 | Batch 15926/45709 | Average Loss in last 25 iteration(s): 0.0904 | Elapsed 4:45:59\n",
      "Epoch: 003/010 | Batch 15951/45709 | Average Loss in last 25 iteration(s): 0.0708 | Elapsed 4:46:27\n",
      "Epoch: 003/010 | Batch 15976/45709 | Average Loss in last 25 iteration(s): 0.0765 | Elapsed 4:46:50\n",
      "Epoch: 003/010 | Batch 16001/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 4:47:18\n",
      "Epoch: 003/010 | Batch 16026/45709 | Average Loss in last 25 iteration(s): 0.0561 | Elapsed 4:47:48\n",
      "Epoch: 003/010 | Batch 16051/45709 | Average Loss in last 25 iteration(s): 0.0883 | Elapsed 4:48:14\n",
      "Epoch: 003/010 | Batch 16076/45709 | Average Loss in last 25 iteration(s): 0.0758 | Elapsed 4:48:43\n",
      "Epoch: 003/010 | Batch 16101/45709 | Average Loss in last 25 iteration(s): 0.0662 | Elapsed 4:49:09\n",
      "Epoch: 003/010 | Batch 16126/45709 | Average Loss in last 25 iteration(s): 0.0906 | Elapsed 4:49:33\n",
      "Epoch: 003/010 | Batch 16151/45709 | Average Loss in last 25 iteration(s): 0.0646 | Elapsed 4:49:59\n",
      "Epoch: 003/010 | Batch 16176/45709 | Average Loss in last 25 iteration(s): 0.0762 | Elapsed 4:50:28\n",
      "Epoch: 003/010 | Batch 16201/45709 | Average Loss in last 25 iteration(s): 0.0617 | Elapsed 4:50:57\n",
      "Epoch: 003/010 | Batch 16226/45709 | Average Loss in last 25 iteration(s): 0.0508 | Elapsed 4:51:24\n",
      "Epoch: 003/010 | Batch 16251/45709 | Average Loss in last 25 iteration(s): 0.0526 | Elapsed 4:51:51\n",
      "Epoch: 003/010 | Batch 16276/45709 | Average Loss in last 25 iteration(s): 0.0825 | Elapsed 4:52:16\n",
      "Epoch: 003/010 | Batch 16301/45709 | Average Loss in last 25 iteration(s): 0.0517 | Elapsed 4:52:42\n",
      "Epoch: 003/010 | Batch 16326/45709 | Average Loss in last 25 iteration(s): 0.0614 | Elapsed 4:53:10\n",
      "Epoch: 003/010 | Batch 16351/45709 | Average Loss in last 25 iteration(s): 0.0918 | Elapsed 4:53:37\n",
      "Epoch: 003/010 | Batch 16376/45709 | Average Loss in last 25 iteration(s): 0.0704 | Elapsed 4:54:06\n",
      "Epoch: 003/010 | Batch 16401/45709 | Average Loss in last 25 iteration(s): 0.0651 | Elapsed 4:54:33\n",
      "Epoch: 003/010 | Batch 16426/45709 | Average Loss in last 25 iteration(s): 0.0632 | Elapsed 4:54:58\n",
      "Epoch: 003/010 | Batch 16451/45709 | Average Loss in last 25 iteration(s): 0.0485 | Elapsed 4:55:23\n",
      "Epoch: 003/010 | Batch 16476/45709 | Average Loss in last 25 iteration(s): 0.0722 | Elapsed 4:55:52\n",
      "Epoch: 003/010 | Batch 16501/45709 | Average Loss in last 25 iteration(s): 0.0772 | Elapsed 4:56:19\n",
      "Epoch: 003/010 | Batch 16526/45709 | Average Loss in last 25 iteration(s): 0.0686 | Elapsed 4:56:46\n",
      "Epoch: 003/010 | Batch 16551/45709 | Average Loss in last 25 iteration(s): 0.0825 | Elapsed 4:57:13\n",
      "Epoch: 003/010 | Batch 16576/45709 | Average Loss in last 25 iteration(s): 0.0792 | Elapsed 4:57:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 16601/45709 | Average Loss in last 25 iteration(s): 0.0831 | Elapsed 4:58:05\n",
      "Epoch: 003/010 | Batch 16626/45709 | Average Loss in last 25 iteration(s): 0.0530 | Elapsed 4:58:33\n",
      "Epoch: 003/010 | Batch 16651/45709 | Average Loss in last 25 iteration(s): 0.0414 | Elapsed 4:59:02\n",
      "Epoch: 003/010 | Batch 16676/45709 | Average Loss in last 25 iteration(s): 0.0677 | Elapsed 4:59:29\n",
      "Epoch: 003/010 | Batch 16701/45709 | Average Loss in last 25 iteration(s): 0.0623 | Elapsed 4:59:58\n",
      "Epoch: 003/010 | Batch 16726/45709 | Average Loss in last 25 iteration(s): 0.0662 | Elapsed 5:00:23\n",
      "Epoch: 003/010 | Batch 16751/45709 | Average Loss in last 25 iteration(s): 0.0456 | Elapsed 5:00:47\n",
      "Epoch: 003/010 | Batch 16776/45709 | Average Loss in last 25 iteration(s): 0.0919 | Elapsed 5:01:17\n",
      "Epoch: 003/010 | Batch 16801/45709 | Average Loss in last 25 iteration(s): 0.0717 | Elapsed 5:01:45\n",
      "Epoch: 003/010 | Batch 16826/45709 | Average Loss in last 25 iteration(s): 0.0720 | Elapsed 5:02:12\n",
      "Epoch: 003/010 | Batch 16851/45709 | Average Loss in last 25 iteration(s): 0.0930 | Elapsed 5:02:39\n",
      "Epoch: 003/010 | Batch 16876/45709 | Average Loss in last 25 iteration(s): 0.0549 | Elapsed 5:03:04\n",
      "Epoch: 003/010 | Batch 16901/45709 | Average Loss in last 25 iteration(s): 0.0837 | Elapsed 5:03:28\n",
      "Epoch: 003/010 | Batch 16926/45709 | Average Loss in last 25 iteration(s): 0.0637 | Elapsed 5:03:55\n",
      "Epoch: 003/010 | Batch 16951/45709 | Average Loss in last 25 iteration(s): 0.0561 | Elapsed 5:04:23\n",
      "Epoch: 003/010 | Batch 16976/45709 | Average Loss in last 25 iteration(s): 0.0527 | Elapsed 5:04:50\n",
      "Epoch: 003/010 | Batch 17001/45709 | Average Loss in last 25 iteration(s): 0.0679 | Elapsed 5:05:18\n",
      "Epoch: 003/010 | Batch 17026/45709 | Average Loss in last 25 iteration(s): 0.0702 | Elapsed 5:05:45\n",
      "Epoch: 003/010 | Batch 17051/45709 | Average Loss in last 25 iteration(s): 0.0749 | Elapsed 5:06:11\n",
      "Epoch: 003/010 | Batch 17076/45709 | Average Loss in last 25 iteration(s): 0.0665 | Elapsed 5:06:36\n",
      "Epoch: 003/010 | Batch 17101/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 5:07:04\n",
      "Epoch: 003/010 | Batch 17126/45709 | Average Loss in last 25 iteration(s): 0.0640 | Elapsed 5:07:31\n",
      "Epoch: 003/010 | Batch 17151/45709 | Average Loss in last 25 iteration(s): 0.0500 | Elapsed 5:07:57\n",
      "Epoch: 003/010 | Batch 17176/45709 | Average Loss in last 25 iteration(s): 0.1156 | Elapsed 5:08:25\n",
      "Epoch: 003/010 | Batch 17201/45709 | Average Loss in last 25 iteration(s): 0.0620 | Elapsed 5:08:52\n",
      "Epoch: 003/010 | Batch 17226/45709 | Average Loss in last 25 iteration(s): 0.0718 | Elapsed 5:09:18\n",
      "Epoch: 003/010 | Batch 17251/45709 | Average Loss in last 25 iteration(s): 0.1200 | Elapsed 5:09:48\n",
      "Epoch: 003/010 | Batch 17276/45709 | Average Loss in last 25 iteration(s): 0.0659 | Elapsed 5:10:17\n",
      "Epoch: 003/010 | Batch 17301/45709 | Average Loss in last 25 iteration(s): 0.0949 | Elapsed 5:10:43\n",
      "Epoch: 003/010 | Batch 17326/45709 | Average Loss in last 25 iteration(s): 0.0571 | Elapsed 5:11:10\n",
      "Epoch: 003/010 | Batch 17351/45709 | Average Loss in last 25 iteration(s): 0.0676 | Elapsed 5:11:37\n",
      "Epoch: 003/010 | Batch 17376/45709 | Average Loss in last 25 iteration(s): 0.0982 | Elapsed 5:12:00\n",
      "Epoch: 003/010 | Batch 17401/45709 | Average Loss in last 25 iteration(s): 0.0833 | Elapsed 5:12:28\n",
      "Epoch: 003/010 | Batch 17426/45709 | Average Loss in last 25 iteration(s): 0.0602 | Elapsed 5:12:56\n",
      "Epoch: 003/010 | Batch 17451/45709 | Average Loss in last 25 iteration(s): 0.0807 | Elapsed 5:13:25\n",
      "Epoch: 003/010 | Batch 17476/45709 | Average Loss in last 25 iteration(s): 0.0572 | Elapsed 5:13:49\n",
      "Epoch: 003/010 | Batch 17501/45709 | Average Loss in last 25 iteration(s): 0.0523 | Elapsed 5:14:17\n",
      "Epoch: 003/010 | Batch 17526/45709 | Average Loss in last 25 iteration(s): 0.0876 | Elapsed 5:14:41\n",
      "Epoch: 003/010 | Batch 17551/45709 | Average Loss in last 25 iteration(s): 0.0601 | Elapsed 5:15:11\n",
      "Epoch: 003/010 | Batch 17576/45709 | Average Loss in last 25 iteration(s): 0.0633 | Elapsed 5:15:38\n",
      "Epoch: 003/010 | Batch 17601/45709 | Average Loss in last 25 iteration(s): 0.0509 | Elapsed 5:16:07\n",
      "Epoch: 003/010 | Batch 17626/45709 | Average Loss in last 25 iteration(s): 0.0439 | Elapsed 5:16:33\n",
      "Epoch: 003/010 | Batch 17651/45709 | Average Loss in last 25 iteration(s): 0.0653 | Elapsed 5:17:00\n",
      "Epoch: 003/010 | Batch 17676/45709 | Average Loss in last 25 iteration(s): 0.0865 | Elapsed 5:17:23\n",
      "Epoch: 003/010 | Batch 17701/45709 | Average Loss in last 25 iteration(s): 0.0548 | Elapsed 5:17:52\n",
      "Epoch: 003/010 | Batch 17726/45709 | Average Loss in last 25 iteration(s): 0.0742 | Elapsed 5:18:22\n",
      "Epoch: 003/010 | Batch 17751/45709 | Average Loss in last 25 iteration(s): 0.0558 | Elapsed 5:18:49\n",
      "Epoch: 003/010 | Batch 17776/45709 | Average Loss in last 25 iteration(s): 0.0946 | Elapsed 5:19:17\n",
      "Epoch: 003/010 | Batch 17801/45709 | Average Loss in last 25 iteration(s): 0.0639 | Elapsed 5:19:42\n",
      "Epoch: 003/010 | Batch 17826/45709 | Average Loss in last 25 iteration(s): 0.1017 | Elapsed 5:20:07\n",
      "Epoch: 003/010 | Batch 17851/45709 | Average Loss in last 25 iteration(s): 0.0517 | Elapsed 5:20:37\n",
      "Epoch: 003/010 | Batch 17876/45709 | Average Loss in last 25 iteration(s): 0.0671 | Elapsed 5:21:06\n",
      "Epoch: 003/010 | Batch 17901/45709 | Average Loss in last 25 iteration(s): 0.0995 | Elapsed 5:21:35\n",
      "Epoch: 003/010 | Batch 17926/45709 | Average Loss in last 25 iteration(s): 0.0609 | Elapsed 5:22:00\n",
      "Epoch: 003/010 | Batch 17951/45709 | Average Loss in last 25 iteration(s): 0.0783 | Elapsed 5:22:25\n",
      "Epoch: 003/010 | Batch 17976/45709 | Average Loss in last 25 iteration(s): 0.0601 | Elapsed 5:22:52\n",
      "Epoch: 003/010 | Batch 18001/45709 | Average Loss in last 25 iteration(s): 0.0704 | Elapsed 5:23:19\n",
      "Epoch: 003/010 | Batch 18026/45709 | Average Loss in last 25 iteration(s): 0.0588 | Elapsed 5:23:46\n",
      "Epoch: 003/010 | Batch 18051/45709 | Average Loss in last 25 iteration(s): 0.0618 | Elapsed 5:24:15\n",
      "Epoch: 003/010 | Batch 18076/45709 | Average Loss in last 25 iteration(s): 0.0418 | Elapsed 5:24:44\n",
      "Epoch: 003/010 | Batch 18101/45709 | Average Loss in last 25 iteration(s): 0.0719 | Elapsed 5:25:09\n",
      "Epoch: 003/010 | Batch 18126/45709 | Average Loss in last 25 iteration(s): 0.0987 | Elapsed 5:25:34\n",
      "Epoch: 003/010 | Batch 18151/45709 | Average Loss in last 25 iteration(s): 0.1070 | Elapsed 5:26:01\n",
      "Epoch: 003/010 | Batch 18176/45709 | Average Loss in last 25 iteration(s): 0.0720 | Elapsed 5:26:31\n",
      "Epoch: 003/010 | Batch 18201/45709 | Average Loss in last 25 iteration(s): 0.0885 | Elapsed 5:26:57\n",
      "Epoch: 003/010 | Batch 18226/45709 | Average Loss in last 25 iteration(s): 0.0820 | Elapsed 5:27:25\n",
      "Epoch: 003/010 | Batch 18251/45709 | Average Loss in last 25 iteration(s): 0.0756 | Elapsed 5:27:51\n",
      "Epoch: 003/010 | Batch 18276/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 5:28:14\n",
      "Epoch: 003/010 | Batch 18301/45709 | Average Loss in last 25 iteration(s): 0.0569 | Elapsed 5:28:41\n",
      "Epoch: 003/010 | Batch 18326/45709 | Average Loss in last 25 iteration(s): 0.1042 | Elapsed 5:29:11\n",
      "Epoch: 003/010 | Batch 18351/45709 | Average Loss in last 25 iteration(s): 0.0541 | Elapsed 5:29:38\n",
      "Epoch: 003/010 | Batch 18376/45709 | Average Loss in last 25 iteration(s): 0.0494 | Elapsed 5:30:03\n",
      "Epoch: 003/010 | Batch 18401/45709 | Average Loss in last 25 iteration(s): 0.0770 | Elapsed 5:30:32\n",
      "Epoch: 003/010 | Batch 18426/45709 | Average Loss in last 25 iteration(s): 0.0846 | Elapsed 5:30:56\n",
      "Epoch: 003/010 | Batch 18451/45709 | Average Loss in last 25 iteration(s): 0.0824 | Elapsed 5:31:23\n",
      "Epoch: 003/010 | Batch 18476/45709 | Average Loss in last 25 iteration(s): 0.0739 | Elapsed 5:31:51\n",
      "Epoch: 003/010 | Batch 18501/45709 | Average Loss in last 25 iteration(s): 0.0774 | Elapsed 5:32:18\n",
      "Epoch: 003/010 | Batch 18526/45709 | Average Loss in last 25 iteration(s): 0.0636 | Elapsed 5:32:46\n",
      "Epoch: 003/010 | Batch 18551/45709 | Average Loss in last 25 iteration(s): 0.0518 | Elapsed 5:33:13\n",
      "Epoch: 003/010 | Batch 18576/45709 | Average Loss in last 25 iteration(s): 0.0696 | Elapsed 5:33:38\n",
      "Epoch: 003/010 | Batch 18601/45709 | Average Loss in last 25 iteration(s): 0.0408 | Elapsed 5:34:03\n",
      "Epoch: 003/010 | Batch 18626/45709 | Average Loss in last 25 iteration(s): 0.1036 | Elapsed 5:34:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 18651/45709 | Average Loss in last 25 iteration(s): 0.1059 | Elapsed 5:35:00\n",
      "Epoch: 003/010 | Batch 18676/45709 | Average Loss in last 25 iteration(s): 0.1069 | Elapsed 5:35:27\n",
      "Epoch: 003/010 | Batch 18701/45709 | Average Loss in last 25 iteration(s): 0.0710 | Elapsed 5:35:55\n",
      "Epoch: 003/010 | Batch 18726/45709 | Average Loss in last 25 iteration(s): 0.0689 | Elapsed 5:36:20\n",
      "Epoch: 003/010 | Batch 18751/45709 | Average Loss in last 25 iteration(s): 0.0613 | Elapsed 5:36:45\n",
      "Epoch: 003/010 | Batch 18776/45709 | Average Loss in last 25 iteration(s): 0.0974 | Elapsed 5:37:17\n",
      "Epoch: 003/010 | Batch 18801/45709 | Average Loss in last 25 iteration(s): 0.0596 | Elapsed 5:37:42\n",
      "Epoch: 003/010 | Batch 18826/45709 | Average Loss in last 25 iteration(s): 0.0537 | Elapsed 5:38:11\n",
      "Epoch: 003/010 | Batch 18851/45709 | Average Loss in last 25 iteration(s): 0.0801 | Elapsed 5:38:37\n",
      "Epoch: 003/010 | Batch 18876/45709 | Average Loss in last 25 iteration(s): 0.0723 | Elapsed 5:39:03\n",
      "Epoch: 003/010 | Batch 18901/45709 | Average Loss in last 25 iteration(s): 0.0802 | Elapsed 5:39:31\n",
      "Epoch: 003/010 | Batch 18926/45709 | Average Loss in last 25 iteration(s): 0.0840 | Elapsed 5:40:00\n",
      "Epoch: 003/010 | Batch 18951/45709 | Average Loss in last 25 iteration(s): 0.0821 | Elapsed 5:40:27\n",
      "Epoch: 003/010 | Batch 18976/45709 | Average Loss in last 25 iteration(s): 0.0777 | Elapsed 5:40:55\n",
      "Epoch: 003/010 | Batch 19001/45709 | Average Loss in last 25 iteration(s): 0.0675 | Elapsed 5:41:22\n",
      "Epoch: 003/010 | Batch 19026/45709 | Average Loss in last 25 iteration(s): 0.0732 | Elapsed 5:41:46\n",
      "Epoch: 003/010 | Batch 19051/45709 | Average Loss in last 25 iteration(s): 0.0555 | Elapsed 5:42:13\n",
      "Epoch: 003/010 | Batch 19076/45709 | Average Loss in last 25 iteration(s): 0.0546 | Elapsed 5:42:43\n",
      "Epoch: 003/010 | Batch 19101/45709 | Average Loss in last 25 iteration(s): 0.0664 | Elapsed 5:43:08\n",
      "Epoch: 003/010 | Batch 19126/45709 | Average Loss in last 25 iteration(s): 0.0634 | Elapsed 5:43:33\n",
      "Epoch: 003/010 | Batch 19151/45709 | Average Loss in last 25 iteration(s): 0.0830 | Elapsed 5:44:00\n",
      "Epoch: 003/010 | Batch 19176/45709 | Average Loss in last 25 iteration(s): 0.0750 | Elapsed 5:44:27\n",
      "Epoch: 003/010 | Batch 19201/45709 | Average Loss in last 25 iteration(s): 0.0670 | Elapsed 5:44:51\n",
      "Epoch: 003/010 | Batch 19226/45709 | Average Loss in last 25 iteration(s): 0.0764 | Elapsed 5:45:18\n",
      "Epoch: 003/010 | Batch 19251/45709 | Average Loss in last 25 iteration(s): 0.0354 | Elapsed 5:45:47\n",
      "Epoch: 003/010 | Batch 19276/45709 | Average Loss in last 25 iteration(s): 0.0949 | Elapsed 5:46:15\n",
      "Epoch: 003/010 | Batch 19301/45709 | Average Loss in last 25 iteration(s): 0.0609 | Elapsed 5:46:44\n",
      "Epoch: 003/010 | Batch 19326/45709 | Average Loss in last 25 iteration(s): 0.1001 | Elapsed 5:47:10\n",
      "Epoch: 003/010 | Batch 19351/45709 | Average Loss in last 25 iteration(s): 0.0666 | Elapsed 5:47:33\n",
      "Epoch: 003/010 | Batch 19376/45709 | Average Loss in last 25 iteration(s): 0.0826 | Elapsed 5:48:02\n",
      "Epoch: 003/010 | Batch 19401/45709 | Average Loss in last 25 iteration(s): 0.0986 | Elapsed 5:48:30\n",
      "Epoch: 003/010 | Batch 19426/45709 | Average Loss in last 25 iteration(s): 0.0627 | Elapsed 5:48:58\n",
      "Epoch: 003/010 | Batch 19451/45709 | Average Loss in last 25 iteration(s): 0.0708 | Elapsed 5:49:26\n",
      "Epoch: 003/010 | Batch 19476/45709 | Average Loss in last 25 iteration(s): 0.0871 | Elapsed 5:49:53\n",
      "Epoch: 003/010 | Batch 19501/45709 | Average Loss in last 25 iteration(s): 0.0771 | Elapsed 5:50:17\n",
      "Epoch: 003/010 | Batch 19526/45709 | Average Loss in last 25 iteration(s): 0.0634 | Elapsed 5:50:44\n",
      "Epoch: 003/010 | Batch 19551/45709 | Average Loss in last 25 iteration(s): 0.0788 | Elapsed 5:51:12\n",
      "Epoch: 003/010 | Batch 19576/45709 | Average Loss in last 25 iteration(s): 0.0675 | Elapsed 5:51:40\n",
      "Epoch: 003/010 | Batch 19601/45709 | Average Loss in last 25 iteration(s): 0.0955 | Elapsed 5:52:07\n",
      "Epoch: 003/010 | Batch 19626/45709 | Average Loss in last 25 iteration(s): 0.0614 | Elapsed 5:52:34\n",
      "Epoch: 003/010 | Batch 19651/45709 | Average Loss in last 25 iteration(s): 0.0498 | Elapsed 5:52:58\n",
      "Epoch: 003/010 | Batch 19676/45709 | Average Loss in last 25 iteration(s): 0.0467 | Elapsed 5:53:23\n",
      "Epoch: 003/010 | Batch 19701/45709 | Average Loss in last 25 iteration(s): 0.0780 | Elapsed 5:53:51\n",
      "Epoch: 003/010 | Batch 19726/45709 | Average Loss in last 25 iteration(s): 0.0549 | Elapsed 5:54:21\n",
      "Epoch: 003/010 | Batch 19751/45709 | Average Loss in last 25 iteration(s): 0.0826 | Elapsed 5:54:49\n",
      "Epoch: 003/010 | Batch 19776/45709 | Average Loss in last 25 iteration(s): 0.0527 | Elapsed 5:55:15\n",
      "Epoch: 003/010 | Batch 19801/45709 | Average Loss in last 25 iteration(s): 0.0608 | Elapsed 5:55:40\n",
      "Epoch: 003/010 | Batch 19826/45709 | Average Loss in last 25 iteration(s): 0.0991 | Elapsed 5:56:05\n",
      "Epoch: 003/010 | Batch 19851/45709 | Average Loss in last 25 iteration(s): 0.0777 | Elapsed 5:56:34\n",
      "Epoch: 003/010 | Batch 19876/45709 | Average Loss in last 25 iteration(s): 0.0476 | Elapsed 5:57:01\n",
      "Epoch: 003/010 | Batch 19901/45709 | Average Loss in last 25 iteration(s): 0.0550 | Elapsed 5:57:28\n",
      "Epoch: 003/010 | Batch 19926/45709 | Average Loss in last 25 iteration(s): 0.0638 | Elapsed 5:57:56\n",
      "Epoch: 003/010 | Batch 19951/45709 | Average Loss in last 25 iteration(s): 0.0371 | Elapsed 5:58:21\n",
      "Epoch: 003/010 | Batch 19976/45709 | Average Loss in last 25 iteration(s): 0.0712 | Elapsed 5:58:45\n",
      "Epoch: 003/010 | Batch 20001/45709 | Average Loss in last 25 iteration(s): 0.0697 | Elapsed 5:59:15\n",
      "Epoch: 003/010 | Batch 20026/45709 | Average Loss in last 25 iteration(s): 0.0584 | Elapsed 5:59:42\n",
      "Epoch: 003/010 | Batch 20051/45709 | Average Loss in last 25 iteration(s): 0.0695 | Elapsed 6:00:09\n",
      "Epoch: 003/010 | Batch 20076/45709 | Average Loss in last 25 iteration(s): 0.0580 | Elapsed 6:00:36\n",
      "Epoch: 003/010 | Batch 20101/45709 | Average Loss in last 25 iteration(s): 0.0511 | Elapsed 6:01:03\n",
      "Epoch: 003/010 | Batch 20126/45709 | Average Loss in last 25 iteration(s): 0.0550 | Elapsed 6:01:26\n",
      "Epoch: 003/010 | Batch 20151/45709 | Average Loss in last 25 iteration(s): 0.0919 | Elapsed 6:01:54\n",
      "Epoch: 003/010 | Batch 20176/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 6:02:24\n",
      "Epoch: 003/010 | Batch 20201/45709 | Average Loss in last 25 iteration(s): 0.0473 | Elapsed 6:02:50\n",
      "Epoch: 003/010 | Batch 20226/45709 | Average Loss in last 25 iteration(s): 0.0726 | Elapsed 6:03:18\n",
      "Epoch: 003/010 | Batch 20251/45709 | Average Loss in last 25 iteration(s): 0.0631 | Elapsed 6:03:44\n",
      "Epoch: 003/010 | Batch 20276/45709 | Average Loss in last 25 iteration(s): 0.0695 | Elapsed 6:04:06\n",
      "Epoch: 003/010 | Batch 20301/45709 | Average Loss in last 25 iteration(s): 0.0716 | Elapsed 6:04:35\n",
      "Epoch: 003/010 | Batch 20326/45709 | Average Loss in last 25 iteration(s): 0.0789 | Elapsed 6:05:04\n",
      "Epoch: 003/010 | Batch 20351/45709 | Average Loss in last 25 iteration(s): 0.0830 | Elapsed 6:05:31\n",
      "Epoch: 003/010 | Batch 20376/45709 | Average Loss in last 25 iteration(s): 0.0959 | Elapsed 6:05:57\n",
      "Epoch: 003/010 | Batch 20401/45709 | Average Loss in last 25 iteration(s): 0.0869 | Elapsed 6:06:24\n",
      "Epoch: 003/010 | Batch 20426/45709 | Average Loss in last 25 iteration(s): 0.0689 | Elapsed 6:06:47\n",
      "Epoch: 003/010 | Batch 20451/45709 | Average Loss in last 25 iteration(s): 0.1096 | Elapsed 6:07:14\n",
      "Epoch: 003/010 | Batch 20476/45709 | Average Loss in last 25 iteration(s): 0.0856 | Elapsed 6:07:42\n",
      "Epoch: 003/010 | Batch 20501/45709 | Average Loss in last 25 iteration(s): 0.0786 | Elapsed 6:08:08\n",
      "Epoch: 003/010 | Batch 20526/45709 | Average Loss in last 25 iteration(s): 0.0537 | Elapsed 6:08:34\n",
      "Epoch: 003/010 | Batch 20551/45709 | Average Loss in last 25 iteration(s): 0.0693 | Elapsed 6:09:02\n",
      "Epoch: 003/010 | Batch 20576/45709 | Average Loss in last 25 iteration(s): 0.1073 | Elapsed 6:09:28\n",
      "Epoch: 003/010 | Batch 20601/45709 | Average Loss in last 25 iteration(s): 0.0765 | Elapsed 6:09:54\n",
      "Epoch: 003/010 | Batch 20626/45709 | Average Loss in last 25 iteration(s): 0.0628 | Elapsed 6:10:23\n",
      "Epoch: 003/010 | Batch 20651/45709 | Average Loss in last 25 iteration(s): 0.0620 | Elapsed 6:10:52\n",
      "Epoch: 003/010 | Batch 20676/45709 | Average Loss in last 25 iteration(s): 0.0431 | Elapsed 6:11:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 20701/45709 | Average Loss in last 25 iteration(s): 0.0928 | Elapsed 6:11:47\n",
      "Epoch: 003/010 | Batch 20726/45709 | Average Loss in last 25 iteration(s): 0.0366 | Elapsed 6:12:12\n",
      "Epoch: 003/010 | Batch 20751/45709 | Average Loss in last 25 iteration(s): 0.0812 | Elapsed 6:12:41\n",
      "Epoch: 003/010 | Batch 20776/45709 | Average Loss in last 25 iteration(s): 0.0766 | Elapsed 6:13:10\n",
      "Epoch: 003/010 | Batch 20801/45709 | Average Loss in last 25 iteration(s): 0.0494 | Elapsed 6:13:35\n",
      "Epoch: 003/010 | Batch 20826/45709 | Average Loss in last 25 iteration(s): 0.0650 | Elapsed 6:14:01\n",
      "Epoch: 003/010 | Batch 20851/45709 | Average Loss in last 25 iteration(s): 0.0671 | Elapsed 6:14:27\n",
      "Epoch: 003/010 | Batch 20876/45709 | Average Loss in last 25 iteration(s): 0.0717 | Elapsed 6:14:52\n",
      "Epoch: 003/010 | Batch 20901/45709 | Average Loss in last 25 iteration(s): 0.0511 | Elapsed 6:15:19\n",
      "Epoch: 003/010 | Batch 20926/45709 | Average Loss in last 25 iteration(s): 0.0624 | Elapsed 6:15:49\n",
      "Epoch: 003/010 | Batch 20951/45709 | Average Loss in last 25 iteration(s): 0.0678 | Elapsed 6:16:17\n",
      "Epoch: 003/010 | Batch 20976/45709 | Average Loss in last 25 iteration(s): 0.0611 | Elapsed 6:16:44\n",
      "Epoch: 003/010 | Batch 21001/45709 | Average Loss in last 25 iteration(s): 0.0688 | Elapsed 6:17:11\n",
      "Epoch: 003/010 | Batch 21026/45709 | Average Loss in last 25 iteration(s): 0.0520 | Elapsed 6:17:35\n",
      "Epoch: 003/010 | Batch 21051/45709 | Average Loss in last 25 iteration(s): 0.0665 | Elapsed 6:18:05\n",
      "Epoch: 003/010 | Batch 21076/45709 | Average Loss in last 25 iteration(s): 0.0338 | Elapsed 6:18:34\n",
      "Epoch: 003/010 | Batch 21101/45709 | Average Loss in last 25 iteration(s): 0.0591 | Elapsed 6:19:01\n",
      "Epoch: 003/010 | Batch 21126/45709 | Average Loss in last 25 iteration(s): 0.0510 | Elapsed 6:19:29\n",
      "Epoch: 003/010 | Batch 21151/45709 | Average Loss in last 25 iteration(s): 0.0557 | Elapsed 6:19:55\n",
      "Epoch: 003/010 | Batch 21176/45709 | Average Loss in last 25 iteration(s): 0.0707 | Elapsed 6:20:19\n",
      "Epoch: 003/010 | Batch 21201/45709 | Average Loss in last 25 iteration(s): 0.0761 | Elapsed 6:20:47\n",
      "Epoch: 003/010 | Batch 21226/45709 | Average Loss in last 25 iteration(s): 0.0858 | Elapsed 6:21:15\n",
      "Epoch: 003/010 | Batch 21251/45709 | Average Loss in last 25 iteration(s): 0.0513 | Elapsed 6:21:42\n",
      "Epoch: 003/010 | Batch 21276/45709 | Average Loss in last 25 iteration(s): 0.0719 | Elapsed 6:22:09\n",
      "Epoch: 003/010 | Batch 21301/45709 | Average Loss in last 25 iteration(s): 0.1017 | Elapsed 6:22:37\n",
      "Epoch: 003/010 | Batch 21326/45709 | Average Loss in last 25 iteration(s): 0.0439 | Elapsed 6:23:01\n",
      "Epoch: 003/010 | Batch 21351/45709 | Average Loss in last 25 iteration(s): 0.0845 | Elapsed 6:23:25\n",
      "Epoch: 003/010 | Batch 21376/45709 | Average Loss in last 25 iteration(s): 0.0933 | Elapsed 6:23:55\n",
      "Epoch: 003/010 | Batch 21401/45709 | Average Loss in last 25 iteration(s): 0.0587 | Elapsed 6:24:22\n",
      "Epoch: 003/010 | Batch 21426/45709 | Average Loss in last 25 iteration(s): 0.0603 | Elapsed 6:24:49\n",
      "Epoch: 003/010 | Batch 21451/45709 | Average Loss in last 25 iteration(s): 0.0776 | Elapsed 6:25:16\n",
      "Epoch: 003/010 | Batch 21476/45709 | Average Loss in last 25 iteration(s): 0.0552 | Elapsed 6:25:43\n",
      "Epoch: 003/010 | Batch 21501/45709 | Average Loss in last 25 iteration(s): 0.0905 | Elapsed 6:26:07\n",
      "Epoch: 003/010 | Batch 21526/45709 | Average Loss in last 25 iteration(s): 0.0625 | Elapsed 6:26:36\n",
      "Epoch: 003/010 | Batch 21551/45709 | Average Loss in last 25 iteration(s): 0.0478 | Elapsed 6:27:04\n",
      "Epoch: 003/010 | Batch 21576/45709 | Average Loss in last 25 iteration(s): 0.0538 | Elapsed 6:27:31\n",
      "Epoch: 003/010 | Batch 21601/45709 | Average Loss in last 25 iteration(s): 0.0980 | Elapsed 6:27:59\n",
      "Epoch: 003/010 | Batch 21626/45709 | Average Loss in last 25 iteration(s): 0.0430 | Elapsed 6:28:24\n",
      "Epoch: 003/010 | Batch 21651/45709 | Average Loss in last 25 iteration(s): 0.0727 | Elapsed 6:28:47\n",
      "Epoch: 003/010 | Batch 21676/45709 | Average Loss in last 25 iteration(s): 0.0379 | Elapsed 6:29:18\n",
      "Epoch: 003/010 | Batch 21701/45709 | Average Loss in last 25 iteration(s): 0.1150 | Elapsed 6:29:45\n",
      "Epoch: 003/010 | Batch 21726/45709 | Average Loss in last 25 iteration(s): 0.0571 | Elapsed 6:30:13\n",
      "Epoch: 003/010 | Batch 21751/45709 | Average Loss in last 25 iteration(s): 0.0635 | Elapsed 6:30:41\n",
      "Epoch: 003/010 | Batch 21776/45709 | Average Loss in last 25 iteration(s): 0.0765 | Elapsed 6:31:07\n",
      "Epoch: 003/010 | Batch 21801/45709 | Average Loss in last 25 iteration(s): 0.0623 | Elapsed 6:31:33\n",
      "Epoch: 003/010 | Batch 21826/45709 | Average Loss in last 25 iteration(s): 0.0666 | Elapsed 6:32:02\n",
      "Epoch: 003/010 | Batch 21851/45709 | Average Loss in last 25 iteration(s): 0.0423 | Elapsed 6:32:30\n",
      "Epoch: 003/010 | Batch 21876/45709 | Average Loss in last 25 iteration(s): 0.0823 | Elapsed 6:32:58\n",
      "Epoch: 003/010 | Batch 21901/45709 | Average Loss in last 25 iteration(s): 0.0817 | Elapsed 6:33:25\n",
      "Epoch: 003/010 | Batch 21926/45709 | Average Loss in last 25 iteration(s): 0.0449 | Elapsed 6:33:50\n",
      "Epoch: 003/010 | Batch 21951/45709 | Average Loss in last 25 iteration(s): 0.1042 | Elapsed 6:34:14\n",
      "Epoch: 003/010 | Batch 21976/45709 | Average Loss in last 25 iteration(s): 0.0853 | Elapsed 6:34:44\n",
      "Epoch: 003/010 | Batch 22001/45709 | Average Loss in last 25 iteration(s): 0.0674 | Elapsed 6:35:10\n",
      "Epoch: 003/010 | Batch 22026/45709 | Average Loss in last 25 iteration(s): 0.0626 | Elapsed 6:35:38\n",
      "Epoch: 003/010 | Batch 22051/45709 | Average Loss in last 25 iteration(s): 0.0600 | Elapsed 6:36:05\n",
      "Epoch: 003/010 | Batch 22076/45709 | Average Loss in last 25 iteration(s): 0.0881 | Elapsed 6:36:30\n",
      "Epoch: 003/010 | Batch 22101/45709 | Average Loss in last 25 iteration(s): 0.0496 | Elapsed 6:36:59\n",
      "Epoch: 003/010 | Batch 22126/45709 | Average Loss in last 25 iteration(s): 0.0602 | Elapsed 6:37:27\n",
      "Epoch: 003/010 | Batch 22151/45709 | Average Loss in last 25 iteration(s): 0.0690 | Elapsed 6:37:53\n",
      "Epoch: 003/010 | Batch 22176/45709 | Average Loss in last 25 iteration(s): 0.1017 | Elapsed 6:38:23\n",
      "Epoch: 003/010 | Batch 22201/45709 | Average Loss in last 25 iteration(s): 0.0696 | Elapsed 6:38:49\n",
      "Epoch: 003/010 | Batch 22226/45709 | Average Loss in last 25 iteration(s): 0.0526 | Elapsed 6:39:13\n",
      "Epoch: 003/010 | Batch 22251/45709 | Average Loss in last 25 iteration(s): 0.0679 | Elapsed 6:39:41\n",
      "Epoch: 003/010 | Batch 22276/45709 | Average Loss in last 25 iteration(s): 0.0684 | Elapsed 6:40:10\n",
      "Epoch: 003/010 | Batch 22301/45709 | Average Loss in last 25 iteration(s): 0.0678 | Elapsed 6:40:38\n",
      "Epoch: 003/010 | Batch 22326/45709 | Average Loss in last 25 iteration(s): 0.0873 | Elapsed 6:41:04\n",
      "Epoch: 003/010 | Batch 22351/45709 | Average Loss in last 25 iteration(s): 0.0571 | Elapsed 6:41:32\n",
      "Epoch: 003/010 | Batch 22376/45709 | Average Loss in last 25 iteration(s): 0.0652 | Elapsed 6:41:55\n",
      "Epoch: 003/010 | Batch 22401/45709 | Average Loss in last 25 iteration(s): 0.0619 | Elapsed 6:42:22\n",
      "Epoch: 003/010 | Batch 22426/45709 | Average Loss in last 25 iteration(s): 0.0435 | Elapsed 6:42:50\n",
      "Epoch: 003/010 | Batch 22451/45709 | Average Loss in last 25 iteration(s): 0.0908 | Elapsed 6:43:17\n",
      "Epoch: 003/010 | Batch 22476/45709 | Average Loss in last 25 iteration(s): 0.0851 | Elapsed 6:43:44\n",
      "Epoch: 003/010 | Batch 22501/45709 | Average Loss in last 25 iteration(s): 0.0607 | Elapsed 6:44:10\n",
      "Epoch: 003/010 | Batch 22526/45709 | Average Loss in last 25 iteration(s): 0.0605 | Elapsed 6:44:37\n",
      "Epoch: 003/010 | Batch 22551/45709 | Average Loss in last 25 iteration(s): 0.1011 | Elapsed 6:45:01\n",
      "Epoch: 003/010 | Batch 22576/45709 | Average Loss in last 25 iteration(s): 0.0668 | Elapsed 6:45:30\n",
      "Epoch: 003/010 | Batch 22601/45709 | Average Loss in last 25 iteration(s): 0.0758 | Elapsed 6:45:58\n",
      "Epoch: 003/010 | Batch 22626/45709 | Average Loss in last 25 iteration(s): 0.0727 | Elapsed 6:46:24\n",
      "Epoch: 003/010 | Batch 22651/45709 | Average Loss in last 25 iteration(s): 0.0641 | Elapsed 6:46:52\n",
      "Epoch: 003/010 | Batch 22676/45709 | Average Loss in last 25 iteration(s): 0.0652 | Elapsed 6:47:18\n",
      "Epoch: 003/010 | Batch 22701/45709 | Average Loss in last 25 iteration(s): 0.0652 | Elapsed 6:47:43\n",
      "Epoch: 003/010 | Batch 22726/45709 | Average Loss in last 25 iteration(s): 0.0658 | Elapsed 6:48:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 22751/45709 | Average Loss in last 25 iteration(s): 0.0885 | Elapsed 6:48:40\n",
      "Epoch: 003/010 | Batch 22776/45709 | Average Loss in last 25 iteration(s): 0.0793 | Elapsed 6:49:06\n",
      "Epoch: 003/010 | Batch 22801/45709 | Average Loss in last 25 iteration(s): 0.0581 | Elapsed 6:49:34\n",
      "Epoch: 003/010 | Batch 22826/45709 | Average Loss in last 25 iteration(s): 0.0697 | Elapsed 6:50:00\n",
      "Epoch: 003/010 | Batch 22851/45709 | Average Loss in last 25 iteration(s): 0.0627 | Elapsed 6:50:24\n",
      "Epoch: 003/010 | Batch 22876/45709 | Average Loss in last 25 iteration(s): 0.0647 | Elapsed 6:50:52\n",
      "Epoch: 003/010 | Batch 22901/45709 | Average Loss in last 25 iteration(s): 0.0666 | Elapsed 6:51:20\n",
      "Epoch: 003/010 | Batch 22926/45709 | Average Loss in last 25 iteration(s): 0.0720 | Elapsed 6:51:48\n",
      "Epoch: 003/010 | Batch 22951/45709 | Average Loss in last 25 iteration(s): 0.0889 | Elapsed 6:52:15\n",
      "Epoch: 003/010 | Batch 22976/45709 | Average Loss in last 25 iteration(s): 0.0703 | Elapsed 6:52:41\n",
      "Epoch: 003/010 | Batch 23001/45709 | Average Loss in last 25 iteration(s): 0.0885 | Elapsed 6:53:05\n",
      "Epoch: 003/010 | Batch 23026/45709 | Average Loss in last 25 iteration(s): 0.0895 | Elapsed 6:53:30\n",
      "Epoch: 003/010 | Batch 23051/45709 | Average Loss in last 25 iteration(s): 0.0797 | Elapsed 6:53:59\n",
      "Epoch: 003/010 | Batch 23076/45709 | Average Loss in last 25 iteration(s): 0.0343 | Elapsed 6:54:26\n",
      "Epoch: 003/010 | Batch 23101/45709 | Average Loss in last 25 iteration(s): 0.0408 | Elapsed 6:54:53\n",
      "Epoch: 003/010 | Batch 23126/45709 | Average Loss in last 25 iteration(s): 0.1023 | Elapsed 6:55:20\n",
      "Epoch: 003/010 | Batch 23151/45709 | Average Loss in last 25 iteration(s): 0.0619 | Elapsed 6:55:45\n",
      "Epoch: 003/010 | Batch 23176/45709 | Average Loss in last 25 iteration(s): 0.0565 | Elapsed 6:56:08\n",
      "Epoch: 003/010 | Batch 23201/45709 | Average Loss in last 25 iteration(s): 0.0663 | Elapsed 6:56:37\n",
      "Epoch: 003/010 | Batch 23226/45709 | Average Loss in last 25 iteration(s): 0.0687 | Elapsed 6:57:05\n",
      "Epoch: 003/010 | Batch 23251/45709 | Average Loss in last 25 iteration(s): 0.0492 | Elapsed 6:57:32\n",
      "Epoch: 003/010 | Batch 23276/45709 | Average Loss in last 25 iteration(s): 0.0733 | Elapsed 6:57:58\n",
      "Epoch: 003/010 | Batch 23301/45709 | Average Loss in last 25 iteration(s): 0.0516 | Elapsed 6:58:27\n",
      "Epoch: 003/010 | Batch 23326/45709 | Average Loss in last 25 iteration(s): 0.0558 | Elapsed 6:58:51\n",
      "Epoch: 003/010 | Batch 23351/45709 | Average Loss in last 25 iteration(s): 0.0710 | Elapsed 6:59:20\n",
      "Epoch: 003/010 | Batch 23376/45709 | Average Loss in last 25 iteration(s): 0.0594 | Elapsed 6:59:49\n",
      "Epoch: 003/010 | Batch 23401/45709 | Average Loss in last 25 iteration(s): 0.0586 | Elapsed 7:00:15\n",
      "Epoch: 003/010 | Batch 23426/45709 | Average Loss in last 25 iteration(s): 0.0728 | Elapsed 7:00:44\n",
      "Epoch: 003/010 | Batch 23451/45709 | Average Loss in last 25 iteration(s): 0.0561 | Elapsed 7:01:09\n",
      "Epoch: 003/010 | Batch 23476/45709 | Average Loss in last 25 iteration(s): 0.0614 | Elapsed 7:01:33\n",
      "Epoch: 003/010 | Batch 23501/45709 | Average Loss in last 25 iteration(s): 0.0630 | Elapsed 7:02:03\n",
      "Epoch: 003/010 | Batch 23526/45709 | Average Loss in last 25 iteration(s): 0.0855 | Elapsed 7:02:31\n",
      "Epoch: 003/010 | Batch 23551/45709 | Average Loss in last 25 iteration(s): 0.0596 | Elapsed 7:03:00\n",
      "Epoch: 003/010 | Batch 23576/45709 | Average Loss in last 25 iteration(s): 0.0623 | Elapsed 7:03:26\n",
      "Epoch: 003/010 | Batch 23601/45709 | Average Loss in last 25 iteration(s): 0.0823 | Elapsed 7:03:53\n",
      "Epoch: 003/010 | Batch 23626/45709 | Average Loss in last 25 iteration(s): 0.0664 | Elapsed 7:04:15\n",
      "Epoch: 003/010 | Batch 23651/45709 | Average Loss in last 25 iteration(s): 0.0822 | Elapsed 7:04:44\n",
      "Epoch: 003/010 | Batch 23676/45709 | Average Loss in last 25 iteration(s): 0.0956 | Elapsed 7:05:13\n",
      "Epoch: 003/010 | Batch 23701/45709 | Average Loss in last 25 iteration(s): 0.0609 | Elapsed 7:05:40\n",
      "Epoch: 003/010 | Batch 23726/45709 | Average Loss in last 25 iteration(s): 0.0584 | Elapsed 7:06:05\n",
      "Epoch: 003/010 | Batch 23751/45709 | Average Loss in last 25 iteration(s): 0.0757 | Elapsed 7:06:31\n",
      "Epoch: 003/010 | Batch 23776/45709 | Average Loss in last 25 iteration(s): 0.0687 | Elapsed 7:06:54\n",
      "Epoch: 003/010 | Batch 23801/45709 | Average Loss in last 25 iteration(s): 0.0741 | Elapsed 7:07:22\n",
      "Epoch: 003/010 | Batch 23826/45709 | Average Loss in last 25 iteration(s): 0.0546 | Elapsed 7:07:52\n",
      "Epoch: 003/010 | Batch 23851/45709 | Average Loss in last 25 iteration(s): 0.0644 | Elapsed 7:08:19\n",
      "Epoch: 003/010 | Batch 23876/45709 | Average Loss in last 25 iteration(s): 0.0590 | Elapsed 7:08:46\n",
      "Epoch: 003/010 | Batch 23901/45709 | Average Loss in last 25 iteration(s): 0.0972 | Elapsed 7:09:14\n",
      "Epoch: 003/010 | Batch 23926/45709 | Average Loss in last 25 iteration(s): 0.0882 | Elapsed 7:09:38\n",
      "Epoch: 003/010 | Batch 23951/45709 | Average Loss in last 25 iteration(s): 0.0793 | Elapsed 7:10:08\n",
      "Epoch: 003/010 | Batch 23976/45709 | Average Loss in last 25 iteration(s): 0.0700 | Elapsed 7:10:35\n",
      "Epoch: 003/010 | Batch 24001/45709 | Average Loss in last 25 iteration(s): 0.0437 | Elapsed 7:11:02\n",
      "Epoch: 003/010 | Batch 24026/45709 | Average Loss in last 25 iteration(s): 0.0494 | Elapsed 7:11:30\n",
      "Epoch: 003/010 | Batch 24051/45709 | Average Loss in last 25 iteration(s): 0.0593 | Elapsed 7:11:56\n",
      "Epoch: 003/010 | Batch 24076/45709 | Average Loss in last 25 iteration(s): 0.0893 | Elapsed 7:12:20\n",
      "Epoch: 003/010 | Batch 24101/45709 | Average Loss in last 25 iteration(s): 0.0773 | Elapsed 7:12:48\n",
      "Epoch: 003/010 | Batch 24126/45709 | Average Loss in last 25 iteration(s): 0.0878 | Elapsed 7:13:17\n",
      "Epoch: 003/010 | Batch 24151/45709 | Average Loss in last 25 iteration(s): 0.0742 | Elapsed 7:13:43\n",
      "Epoch: 003/010 | Batch 24176/45709 | Average Loss in last 25 iteration(s): 0.0642 | Elapsed 7:14:10\n",
      "Epoch: 003/010 | Batch 24201/45709 | Average Loss in last 25 iteration(s): 0.0822 | Elapsed 7:14:37\n",
      "Epoch: 003/010 | Batch 24226/45709 | Average Loss in last 25 iteration(s): 0.0742 | Elapsed 7:15:04\n",
      "Epoch: 003/010 | Batch 24251/45709 | Average Loss in last 25 iteration(s): 0.0871 | Elapsed 7:15:27\n",
      "Epoch: 003/010 | Batch 24276/45709 | Average Loss in last 25 iteration(s): 0.0581 | Elapsed 7:15:59\n",
      "Epoch: 003/010 | Batch 24301/45709 | Average Loss in last 25 iteration(s): 0.0771 | Elapsed 7:16:26\n",
      "Epoch: 003/010 | Batch 24326/45709 | Average Loss in last 25 iteration(s): 0.0798 | Elapsed 7:16:52\n",
      "Epoch: 003/010 | Batch 24351/45709 | Average Loss in last 25 iteration(s): 0.0783 | Elapsed 7:17:21\n",
      "Epoch: 003/010 | Batch 24376/45709 | Average Loss in last 25 iteration(s): 0.0737 | Elapsed 7:17:46\n",
      "Epoch: 003/010 | Batch 24401/45709 | Average Loss in last 25 iteration(s): 0.0529 | Elapsed 7:18:11\n",
      "Epoch: 003/010 | Batch 24426/45709 | Average Loss in last 25 iteration(s): 0.0544 | Elapsed 7:18:42\n",
      "Epoch: 003/010 | Batch 24451/45709 | Average Loss in last 25 iteration(s): 0.0572 | Elapsed 7:19:10\n",
      "Epoch: 003/010 | Batch 24476/45709 | Average Loss in last 25 iteration(s): 0.0540 | Elapsed 7:19:37\n",
      "Epoch: 003/010 | Batch 24501/45709 | Average Loss in last 25 iteration(s): 0.0744 | Elapsed 7:20:03\n",
      "Epoch: 003/010 | Batch 24526/45709 | Average Loss in last 25 iteration(s): 0.0407 | Elapsed 7:20:29\n",
      "Epoch: 003/010 | Batch 24551/45709 | Average Loss in last 25 iteration(s): 0.0970 | Elapsed 7:20:53\n",
      "Epoch: 003/010 | Batch 24576/45709 | Average Loss in last 25 iteration(s): 0.0659 | Elapsed 7:21:21\n",
      "Epoch: 003/010 | Batch 24601/45709 | Average Loss in last 25 iteration(s): 0.0865 | Elapsed 7:21:51\n",
      "Epoch: 003/010 | Batch 24626/45709 | Average Loss in last 25 iteration(s): 0.0672 | Elapsed 7:22:20\n",
      "Epoch: 003/010 | Batch 24651/45709 | Average Loss in last 25 iteration(s): 0.0880 | Elapsed 7:22:47\n",
      "Epoch: 003/010 | Batch 24676/45709 | Average Loss in last 25 iteration(s): 0.0695 | Elapsed 7:23:12\n",
      "Epoch: 003/010 | Batch 24701/45709 | Average Loss in last 25 iteration(s): 0.0628 | Elapsed 7:23:38\n",
      "Epoch: 003/010 | Batch 24726/45709 | Average Loss in last 25 iteration(s): 0.0782 | Elapsed 7:24:10\n",
      "Epoch: 003/010 | Batch 24751/45709 | Average Loss in last 25 iteration(s): 0.0782 | Elapsed 7:24:37\n",
      "Epoch: 003/010 | Batch 24776/45709 | Average Loss in last 25 iteration(s): 0.0962 | Elapsed 7:25:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/010 | Batch 24801/45709 | Average Loss in last 25 iteration(s): 0.0783 | Elapsed 7:25:33\n",
      "Epoch: 003/010 | Batch 24826/45709 | Average Loss in last 25 iteration(s): 0.0502 | Elapsed 7:25:56\n",
      "Epoch: 003/010 | Batch 24851/45709 | Average Loss in last 25 iteration(s): 0.0531 | Elapsed 7:26:22\n",
      "Epoch: 003/010 | Batch 24876/45709 | Average Loss in last 25 iteration(s): 0.0557 | Elapsed 7:26:53\n",
      "Epoch: 003/010 | Batch 24901/45709 | Average Loss in last 25 iteration(s): 0.1004 | Elapsed 7:27:19\n",
      "Epoch: 003/010 | Batch 24926/45709 | Average Loss in last 25 iteration(s): 0.0697 | Elapsed 7:27:47\n",
      "Epoch: 003/010 | Batch 24951/45709 | Average Loss in last 25 iteration(s): 0.0972 | Elapsed 7:28:15\n",
      "Epoch: 003/010 | Batch 24976/45709 | Average Loss in last 25 iteration(s): 0.0731 | Elapsed 7:28:40\n",
      "Epoch: 003/010 | Batch 25001/45709 | Average Loss in last 25 iteration(s): 0.0776 | Elapsed 7:29:08\n",
      "Epoch: 003/010 | Batch 25026/45709 | Average Loss in last 25 iteration(s): 0.0360 | Elapsed 7:29:36\n",
      "Epoch: 003/010 | Batch 25051/45709 | Average Loss in last 25 iteration(s): 0.0577 | Elapsed 7:30:01\n",
      "Epoch: 003/010 | Batch 25076/45709 | Average Loss in last 25 iteration(s): 0.1007 | Elapsed 7:30:29\n",
      "Epoch: 003/010 | Batch 25101/45709 | Average Loss in last 25 iteration(s): 0.0513 | Elapsed 7:30:57\n",
      "Epoch: 003/010 | Batch 25126/45709 | Average Loss in last 25 iteration(s): 0.0285 | Elapsed 7:31:23\n",
      "Epoch: 003/010 | Batch 25151/45709 | Average Loss in last 25 iteration(s): 0.0510 | Elapsed 7:31:48\n",
      "Epoch: 003/010 | Batch 25176/45709 | Average Loss in last 25 iteration(s): 0.0689 | Elapsed 7:32:18\n",
      "Epoch: 003/010 | Batch 25201/45709 | Average Loss in last 25 iteration(s): 0.0480 | Elapsed 7:32:46\n",
      "Epoch: 003/010 | Batch 25226/45709 | Average Loss in last 25 iteration(s): 0.0786 | Elapsed 7:33:14\n",
      "Epoch: 003/010 | Batch 25251/45709 | Average Loss in last 25 iteration(s): 0.0932 | Elapsed 7:33:41\n",
      "Epoch: 003/010 | Batch 25276/45709 | Average Loss in last 25 iteration(s): 0.0350 | Elapsed 7:34:05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-f2a8ffb2ce47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed_val = 8888 \n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8) \n",
    "epochs = 10 # 10 epochs for now. We may transfer learn later \n",
    "total_steps = len(train_dataloader) * epochs \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps) \n",
    "\n",
    "losses = [] \n",
    "val_losses = [] \n",
    "#model.zero_grad() \n",
    "\n",
    "for epoch_i in range(0, epochs): \n",
    "    print(\"\")\n",
    "    print(\"===== Epoch {:} / {:} =====\".format(epoch_i + 1, epochs)) \n",
    "    print(\"Training ...\") \n",
    "    t0 = time.time()\n",
    "    running_loss = 0 \n",
    "    train_accuracy = 0\n",
    "    iteration = 0 \n",
    "    model.train() \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        iteration += 1 \n",
    "        batch = tuple(t.to(device) for t in batch) \n",
    "        b_input_ids, b_input_masks, b_token_type_ids, b_labels = batch \n",
    "        optimizer.zero_grad()\n",
    "        loss, yhat = model(b_input_ids, attention_mask = b_input_masks, \n",
    "                        token_type_ids = b_token_type_ids, labels = b_labels.long()) \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  \n",
    "\n",
    "        running_loss += float(loss.item())\n",
    "        del b_input_ids, b_input_masks, b_token_type_ids, b_labels #memory\n",
    "        \n",
    "        if not step%25:\n",
    "            print(f'Epoch: {epoch_i+1:03d}/{epochs:03d} | '\n",
    "                  f'Batch {step+1:03d}/{len(train_dataloader):03d} | '\n",
    "                  f'Average Loss in last {iteration} iteration(s): {(running_loss/iteration):.4f} | '\n",
    "                  f'Elapsed {format_time(time.time()-t0)}')\n",
    "            running_loss = 0.0\n",
    "            iteration = 0\n",
    "        torch.cuda.empty_cache() #memory\n",
    "        gc.collect() #memory\n",
    "        losses.append(float(loss.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        print(f'\\nTraining Accuracy: ' f'{compute_accuracy(model, train_dataloader, device):.2f}%')\n",
    "        \n",
    "        \n",
    "    print(\"Calculating validation metrics...\")\n",
    "    model.eval() \n",
    "    eval_loss = 0\n",
    "    eval_accuracy = 0\n",
    "    for batch in val_dataloader: \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_masks, b_token_type_ids, b_labels = batch \n",
    "        with torch.no_grad(): \n",
    "            loss, yhat = model(b_input_ids, attention_mask = b_input_masks, \n",
    "                        token_type_ids = b_token_type_ids, labels = b_labels.long())  \n",
    "        eval_loss += float(loss.item())  \n",
    "        del b_input_ids, b_input_masks, b_token_type_ids, b_labels # memory \n",
    "        val_losses.append(float(loss.item())) \n",
    "        \n",
    "    avg_val_loss = eval_loss / len(val_dataloader) \n",
    "    # avg_val_accuracy = eval_accuracy / len(val_dataloader)   \n",
    "    \n",
    "    print(\"Average validation loss = {}\".format(avg_val_loss)) \n",
    "    print(\"Average validation accuracy = {}\".format(compute_accuracy(model, val_dataloader, device)))  \n",
    "    \n",
    "    # saving model \n",
    "    torch.save(model.state_dict(), 'electra_chunked_ver_2_' + str(epoch_i + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
